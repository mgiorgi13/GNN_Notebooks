{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mgiorgi13/GNN_Notebooks/blob/main/Graph%20Matching.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dcRdc8jlu-Jj"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rwL9Jpbyvf5Q"
   },
   "outputs": [],
   "source": [
    "#Colab\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# GNN_PATH = '/content/drive/MyDrive/Colab Notebooks/GNN/'\n",
    "\n",
    "#Local\n",
    "GNN_PATH = './GNN/'\n",
    "import os\n",
    "if not os.path.exists(GNN_PATH):\n",
    "    os.makedirs(GNN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-RiOQYdHgeZl",
    "outputId": "9ed68555-5f33-487f-f504-4cafc00efcdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (2.2.2)\n",
      "Requirement already satisfied: torch-geometric in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (2.6.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (1.3.2)\n",
      "Requirement already satisfied: pandas in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (2.0.3)\n",
      "Requirement already satisfied: shapely in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (2.0.7)\n",
      "Requirement already satisfied: seaborn in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (0.13.2)\n",
      "Requirement already satisfied: pygmtools in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (0.5.3)\n",
      "Requirement already satisfied: numpy in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (1.24.4)\n",
      "Requirement already satisfied: moviepy in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (1.0.3)\n",
      "Requirement already satisfied: matplotlib in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (3.7.5)\n",
      "Requirement already satisfied: optuna in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (4.3.0)\n",
      "Requirement already satisfied: tensorboard in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (2.14.0)\n",
      "Requirement already satisfied: filelock in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: sympy in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: aiohttp in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from torch-geometric) (3.10.11)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from torch-geometric) (7.0.0)\n",
      "Requirement already satisfied: pyparsing in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from torch-geometric) (3.1.4)\n",
      "Requirement already satisfied: requests in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from torch-geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from torch-geometric) (4.67.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: Pillow>=7.2.0 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from pygmtools) (10.4.0)\n",
      "Requirement already satisfied: easydict>=1.7 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from pygmtools) (1.13)\n",
      "Requirement already satisfied: appdirs>=1.4.4 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from pygmtools) (1.4.4)\n",
      "Requirement already satisfied: async-timeout in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from pygmtools) (5.0.1)\n",
      "Requirement already satisfied: decorator<5.0,>=4.0.2 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from moviepy) (4.4.2)\n",
      "Requirement already satisfied: proglog<=1.0.0 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from moviepy) (0.1.11)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from moviepy) (2.35.1)\n",
      "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from moviepy) (0.5.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from matplotlib) (6.4.5)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from optuna) (1.14.1)\n",
      "Requirement already satisfied: colorlog in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from optuna) (2.0.40)\n",
      "Requirement already satisfied: PyYAML in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from optuna) (6.0.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from tensorboard) (2.2.2)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from tensorboard) (1.70.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from tensorboard) (2.40.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from tensorboard) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from tensorboard) (3.7)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from tensorboard) (5.29.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from tensorboard) (49.2.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from tensorboard) (3.0.6)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from tensorboard) (0.45.1)\n",
      "Requirement already satisfied: Mako in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
      "Requirement already satisfied: importlib-metadata in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from alembic>=1.5.0->optuna) (8.5.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard) (2.0.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.20.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from requests->torch-geometric) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from requests->torch-geometric) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from requests->torch-geometric) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from requests->torch-geometric) (2025.4.26)\n",
      "Requirement already satisfied: greenlet>=1 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from aiohttp->torch-geometric) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from aiohttp->torch-geometric) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from aiohttp->torch-geometric) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from aiohttp->torch-geometric) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from aiohttp->torch-geometric) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from aiohttp->torch-geometric) (1.15.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard) (3.2.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages (from yarl<2.0,>=1.12.0->aiohttp->torch-geometric) (0.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/matteogiorgi/Github/GNN_Notebooks/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.2.2\n",
      "CUDA version: None\n",
      "zsh:1: command not found: nvcc\n",
      "zsh:1: command not found: nvidia-smi\n"
     ]
    }
   ],
   "source": [
    "# Install packages\n",
    "%pip install torch torch-geometric scikit-learn pandas shapely seaborn pygmtools numpy moviepy matplotlib optuna tensorboard\n",
    "#check if pygmtools is installed\n",
    "try:\n",
    "    import pygmtools\n",
    "except ImportError:#pygmtools library\n",
    "    %pip install git+https://github.com/Thinklab-SJTU/pygmtools.git\n",
    "\n",
    "# Check pytorch version and make sure you use a GPU Kernel\n",
    "import torch\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "!nvcc --version\n",
    "# Check GPU\n",
    "!nvidia-smi\n",
    "\n",
    "#set device as cuda if available to load model and data on gpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "argo4tyhdsZF"
   },
   "outputs": [],
   "source": [
    "# ─── Standard library ──────────────────────────────────────────────────────────\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict, Any\n",
    "from datetime import datetime\n",
    "\n",
    "# ─── Third-party libraries ─────────────────────────────────────────────────────\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from shapely.affinity import translate\n",
    "from shapely.geometry import Polygon\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.nn import GATv2Conv, GCNConv\n",
    "\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "from typing import Optional, Literal\n",
    "import numpy as np\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "import optuna\n",
    "import json\n",
    "\n",
    "# ─── Local application/library imports ────────────────────────────────────────\n",
    "import pygmtools\n",
    "pygmtools.BACKEND = 'pytorch'\n",
    "\n",
    "destination_dir = os.path.join('AFAT')\n",
    "\n",
    "# Ensure the destination directory is in sys.path\n",
    "if destination_dir not in sys.path:\n",
    "    sys.path.append(destination_dir)\n",
    "\n",
    "# AFA-U inlier predictor and Top-K matching from AFAT\n",
    "from k_pred_net import Encoder as AFAUEncoder\n",
    "from sinkhorn_topk import soft_topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "DrLFFvkZdsZG",
    "outputId": "2c68baad-df49-4dfb-d6cb-9e1586a911c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x126508f70>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set Seed for reproducibility\n",
    "seed = 42\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set the seed once at the beginning\n",
    "set_seed(seed)\n",
    "\n",
    "# For reproducible DataLoader shuffle\n",
    "g = torch.Generator()\n",
    "g.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fLtnXFm_dsZH"
   },
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0lWryOMfdsZI"
   },
   "outputs": [],
   "source": [
    "#----------------------------------------\n",
    "#            DATASET UTILS\n",
    "#----------------------------------------\n",
    "\n",
    "def deserialize_MSD_dataset(data_path, original_path=None, noise_path=None, dimensions_path=None):\n",
    "    dataset_dir = Path(data_path)\n",
    "\n",
    "    dimensions = []\n",
    "    if dimensions_path is not None:\n",
    "        # Load dimensions\n",
    "        dimensions_file = dataset_dir / f\"{dimensions_path}.pickle\"\n",
    "        if not dimensions_file.exists():\n",
    "            raise FileNotFoundError(f\"Dimensions file not found at {dimensions_file}\")\n",
    "        with open(dimensions_file, 'rb') as f:\n",
    "            dimensions = pickle.load(f)\n",
    "\n",
    "    # Clear existing graphs\n",
    "    original = []\n",
    "    noise = []\n",
    "\n",
    "    if original_path is not None:\n",
    "        original_dir = dataset_dir / original_path\n",
    "        original_files = sorted(original_dir.glob(\"*.pt\"), key=lambda f: int(f.stem))\n",
    "        print(f\"Loading {len(original_files)} original graphs...\")\n",
    "        for file in tqdm(original_files, desc=\"Original graphs\"):\n",
    "            with open(str(file), \"rb\") as f:\n",
    "                graph = pickle.load(f)\n",
    "                graph.graph['name'] = file.stem\n",
    "            original.append(graph)\n",
    "\n",
    "    if noise_path is not None:\n",
    "        def extract_numeric_key(file):\n",
    "            \"\"\"Extracts (X, Y) from filenames like 'X_Y.pt' for proper numeric sorting.\"\"\"\n",
    "            name_parts = file.stem.split(\"_\")\n",
    "            return int(name_parts[0]), int(name_parts[1])\n",
    "\n",
    "        noise_dir = dataset_dir / noise_path\n",
    "        noise_files = sorted(noise_dir.glob(\"*.pt\"), key=extract_numeric_key)\n",
    "        print(f\"Loading {len(noise_files)} noise graphs...\")\n",
    "        for file in tqdm(noise_files, desc=\"Noise graphs\"):\n",
    "            with open(str(file), \"rb\") as f:\n",
    "                graph = pickle.load(f)\n",
    "                graph.graph['name'] = file.stem\n",
    "            noise.append(graph)\n",
    "\n",
    "    return original, noise, dimensions\n",
    "\n",
    "def serialize_graph_matching_dataset(pairs: List[Tuple[Data, Data, torch.Tensor]], path: str, filename: str = \"train_dataset.pkl\"):\n",
    "    \"\"\"\n",
    "    Serialize a list of (Data1, Data2, PermutationMatrix) tuples to a file.\n",
    "    \"\"\"\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    full_path = os.path.join(path, filename)\n",
    "\n",
    "    with open(full_path, 'wb') as f:\n",
    "        pickle.dump(pairs, f)\n",
    "\n",
    "    print(f\"Serialized {len(pairs)} pairs to {full_path}\")\n",
    "\n",
    "def deserialize_graph_matching_dataset(path: str, filename: str = \"train_dataset.pkl\") -> List[Tuple[Data, Data, torch.Tensor]]:\n",
    "    \"\"\"\n",
    "    Deserialize a dataset of (Data1, Data2, PermutationMatrix) tuples from a file.\n",
    "    \"\"\"\n",
    "    full_path = os.path.join(path, filename)\n",
    "\n",
    "    if not os.path.exists(full_path):\n",
    "        raise FileNotFoundError(f\"File not found: {full_path}\")\n",
    "\n",
    "    with open(full_path, 'rb') as f:\n",
    "        pairs = pickle.load(f)\n",
    "\n",
    "    print(f\"Loaded {len(pairs)} pairs from {full_path}\")\n",
    "    return pairs\n",
    "\n",
    "def plot_a_graph(graphs_list, path=None, viz_rooms=True, viz_ws=True, viz_openings=False, viz_room_connection=True, viz_normals=False, viz_room_normals=False, viz_walls=True):\n",
    "    \"\"\"\n",
    "    Visualizes geometries, wall segments, and graph edges for multiple apartments in 2D.\n",
    "\n",
    "    Parameters:\n",
    "    graphs_list (list of networkx.Graph): List of graphs with nodes ('type', 'center', 'normal') and edges for the apartments.\n",
    "    viz_normals (bool): If True, plots wall segment normals.\n",
    "    viz_rooms (bool): If True, displays room polygons.\n",
    "    viz_ws (bool): If True, displays wall segments.\n",
    "    viz_openings (bool): If True, displays openings (doors and windows).\n",
    "    viz_wall_edges (bool): If True, displays edges between wall segments.\n",
    "    viz_connection_edges (bool): If True, displays edges connecting rooms via openings.\n",
    "    viz_walls (bool): If True, displays wall nodes and their edges.\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "    legend_added = False  # Flag to ensure the legend is added only once\n",
    "    normal_added = False  # Flag to ensure the \"Normal\" label is added only once\n",
    "\n",
    "    for graphs in graphs_list:\n",
    "        # Visualize room polygons\n",
    "        if viz_rooms:\n",
    "            room_nodes = [n for n, d in graphs.nodes(data=True) if d['type'] == 'room']\n",
    "            for idx, room_node in enumerate(room_nodes):\n",
    "                room_data = graphs.nodes[room_node]\n",
    "                # Plot the polygon\n",
    "                room_polygon = Polygon(room_data['polygon'])\n",
    "                x, y = room_polygon.exterior.xy\n",
    "                ax.plot(x, y, color='black', alpha=0.2, label='Room polygon' if not legend_added and idx == 0 else \"\")\n",
    "                # Draw room centroids\n",
    "                ax.scatter(room_data['center'][0], room_data['center'][1], color='blue', s=100, label='Room centroid' if not legend_added and idx == 0 else \"\")\n",
    "\n",
    "        # Visualize wall nodes and edges\n",
    "        if viz_walls:\n",
    "            wall_nodes = [n for n, d in graphs.nodes(data=True) if d['type'] == 'wall']\n",
    "            for idx, wn in enumerate(wall_nodes):\n",
    "                wall_data = graphs.nodes[wn]\n",
    "                # Plot the polygon of the wall\n",
    "                wall_polygon = Polygon(wall_data['polygon'])\n",
    "                x, y = wall_polygon.exterior.xy\n",
    "                ax.plot(x, y, color='purple', linestyle='-', label='Wall polygon' if not legend_added and idx == 0 else \"\")\n",
    "                ax.scatter(wall_data['center'][0], wall_data['center'][1], color='purple', s=50, label='Wall centroid' if not legend_added and idx == 0 else \"\")\n",
    "\n",
    "            if viz_normals:\n",
    "                wall_ws = [n for n, d in graphs.nodes(data=True) if d['type'] == 'wall_ws']\n",
    "                for idx, wn in enumerate(wall_ws):\n",
    "                    ws_data = graphs.nodes[wn]\n",
    "                    ax.scatter(ws_data['center'][0], ws_data['center'][1], color='purple', s=20, label='Wall ws' if not legend_added and idx == 0 else \"\")\n",
    "                    ax.arrow(ws_data['center'][0], ws_data['center'][1],\n",
    "                             ws_data['normal'][0], ws_data['normal'][1],\n",
    "                             head_width=0.1, head_length=0.1, fc='green', ec='green', label='Normal' if not normal_added else \"\")\n",
    "                    normal_added = True\n",
    "\n",
    "            wall_edges = [(u, v) for u, v, d in graphs.edges(data=True) if 'wall' in u or 'wall' in v]\n",
    "            for idx, edge in enumerate(wall_edges):\n",
    "                start_node = graphs.nodes[edge[0]]\n",
    "                end_node = graphs.nodes[edge[1]]\n",
    "                ax.plot([start_node['center'][0], end_node['center'][0]],\n",
    "                        [start_node['center'][1], end_node['center'][1]],\n",
    "                        color='purple', linestyle='--', label='Wall edge' if not legend_added and idx == 0 else \"\")\n",
    "\n",
    "        # Visualize openings\n",
    "        if viz_openings:\n",
    "            opening_nodes = [n for n, d in graphs.nodes(data=True) if 'door' in d['type'] or 'window' in d['type']]\n",
    "            for idx, on in enumerate(opening_nodes):\n",
    "                opening_data = graphs.nodes[on]\n",
    "                opening_polygon = Polygon(opening_data['polygon'])\n",
    "                x, y = opening_polygon.exterior.xy\n",
    "                ax.plot(x, y, color='orange', label='Opening polygon' if not legend_added and idx == 0 else \"\")\n",
    "                # Draw opening centroids\n",
    "                ax.scatter(opening_data['center'][0], opening_data['center'][1], color='orange', s=10, label='Opening centroid' if not legend_added and idx == 0 else \"\")\n",
    "\n",
    "            if viz_normals:\n",
    "                opening_ws = [n for n, d in graphs.nodes(data=True) if d['type'] == 'door_ws' or d['type'] == 'window_ws']\n",
    "                for idx, wn in enumerate(opening_ws):\n",
    "                    ws_data = graphs.nodes[wn]\n",
    "                    ax.scatter(ws_data['center'][0], ws_data['center'][1], color='orange', s=10, label='Opening ws' if not legend_added and idx == 0 else \"\")\n",
    "                    ax.arrow(ws_data['center'][0], ws_data['center'][1],\n",
    "                             ws_data['normal'][0], ws_data['normal'][1],\n",
    "                             head_width=0.1, head_length=0.1, fc='green', ec='green', label='Normal' if not normal_added else \"\")\n",
    "                    normal_added = True\n",
    "\n",
    "            # Draw opening edges\n",
    "            open_edges = [(u, v) for u, v, d in graphs.edges(data=True) if 'door' in u or 'window' in v or 'door' in v or 'window' in u]\n",
    "            for idx, edge in enumerate(open_edges):\n",
    "                start_node = graphs.nodes[edge[0]]\n",
    "                end_node = graphs.nodes[edge[1]]\n",
    "                ax.plot([start_node['center'][0], end_node['center'][0]],\n",
    "                        [start_node['center'][1], end_node['center'][1]],\n",
    "                        color='orange', linestyle='--', label='Opening edge' if not legend_added and idx == 0 else \"\")\n",
    "\n",
    "        # Visualize ws room\n",
    "        if viz_ws:\n",
    "            ws_nodes = [n for n, d in graphs.nodes(data=True) if d['type'] == 'ws']\n",
    "            for idx, wn in enumerate(ws_nodes):\n",
    "                ws_data = graphs.nodes[wn]\n",
    "                ax.scatter(ws_data['center'][0], ws_data['center'][1], color='red', s=20, label='Ws segment' if not legend_added and idx == 0 else \"\")\n",
    "                if viz_room_normals:\n",
    "                    ax.arrow(ws_data['center'][0], ws_data['center'][1],\n",
    "                             ws_data['normal'][0], ws_data['normal'][1],\n",
    "                             head_width=0.1, head_length=0.1, fc='green', ec='green', label='Normal' if not normal_added else \"\")\n",
    "                    normal_added = True\n",
    "                if 'limits' in ws_data:\n",
    "                    limit_1, limit_2 = ws_data['limits']\n",
    "                    ax.plot([limit_1[0], limit_2[0]],\n",
    "                            [limit_1[1], limit_2[1]],\n",
    "                            color='black', linewidth=1.0,\n",
    "                            label='Ws limits' if idx == 0 else \"\")\n",
    "            ws_edges = [(u, v) for u, v, d in graphs.edges(data=True) if 'ws_same_room' in d['type'] or 'ws_belongs_room' in d['type']]\n",
    "            for idx, edge in enumerate(ws_edges):\n",
    "                start_node = graphs.nodes[edge[0]]\n",
    "                end_node = graphs.nodes[edge[1]]\n",
    "                ax.plot([start_node['center'][0], end_node['center'][0]],\n",
    "                    [start_node['center'][1], end_node['center'][1]],\n",
    "                    color='gray', linestyle='--', label='Ws edge' if not legend_added and idx == 0 else \"\")\n",
    "\n",
    "        # Visualize connection edges\n",
    "        if viz_room_connection:\n",
    "            connection_edges = [(u, v) for u, v, d in graphs.edges(data=True) if 'connected' in d['type']]\n",
    "            for idx, edge in enumerate(connection_edges):\n",
    "                start_node = graphs.nodes[edge[0]]\n",
    "                end_node = graphs.nodes[edge[1]]\n",
    "                ax.plot([start_node['center'][0], end_node['center'][0]],\n",
    "                        [start_node['center'][1], end_node['center'][1]],\n",
    "                        color='blue', linestyle='-', label='Connection edge' if not legend_added and idx == 0 else \"\")\n",
    "\n",
    "        legend_added = True  # Set the flag to True after processing the first graph\n",
    "\n",
    "    plt.title(\"Apartment Graph Visualization\")\n",
    "    plt.legend()\n",
    "    if path is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(path)\n",
    "        plt.close()\n",
    "\n",
    "node_type_mapping = {\"room\": [1, 0], \"ws\": [0, 1]}\n",
    "\n",
    "def pyg_data_to_nx_digraph(data: Data, graph_list: List[nx.DiGraph]) -> nx.DiGraph:\n",
    "    \"\"\"\n",
    "    Convert a PyTorch Geometric Data object back to a NetworkX DiGraph,\n",
    "    restoring original node IDs using data.node_names and data.permutation,\n",
    "    matching with the graph in graph_list that has the same name.\n",
    "    \"\"\"\n",
    "    assert hasattr(data, 'node_names'), \\\n",
    "        \"Data object must contain 'node_names' to restore original node IDs.\"\n",
    "    assert hasattr(data, 'permutation'), \\\n",
    "        \"Data object must contain 'permutation' to reorder nodes.\"\n",
    "    assert hasattr(data, 'name'), \\\n",
    "        \"Data object must contain 'name' to match with graph_list.\"\n",
    "\n",
    "    matching_graph = next((g for g in graph_list if g.graph.get('name') == data.name), None)\n",
    "    if matching_graph is None:\n",
    "        raise ValueError(f\"No graph with name {data.name} found in graph_list.\")\n",
    "\n",
    "    orig_names = data.node_names\n",
    "    perm = data.permutation.tolist()\n",
    "    node_ids = [orig_names[idx] for idx in perm]\n",
    "\n",
    "    G = nx.DiGraph()\n",
    "    for node_id in node_ids:\n",
    "        if node_id in matching_graph.nodes:\n",
    "            G.add_node(node_id, **matching_graph.nodes[node_id])\n",
    "\n",
    "    for u_idx, v_idx in data.edge_index.t().tolist():\n",
    "        u = node_ids[u_idx]\n",
    "        v = node_ids[v_idx]\n",
    "        if matching_graph.has_edge(u, v):\n",
    "            G.add_edge(u, v, **matching_graph.edges[u, v])\n",
    "\n",
    "    G.graph['name'] = data.name\n",
    "    return G\n",
    "\n",
    "\n",
    "def nx_to_pyg_data_preserve_order(graph: nx.DiGraph) -> Data:\n",
    "    \"\"\"\n",
    "    Convert a NetworkX DiGraph to a PyTorch Geometric Data object,\n",
    "    preserving node insertion order, storing 'node_names' and an identity 'permutation'.\n",
    "    \"\"\"\n",
    "    node_ids = list(graph.nodes())\n",
    "    id_map = {nid: i for i, nid in enumerate(node_ids)}\n",
    "\n",
    "    x = torch.stack([\n",
    "        torch.tensor(\n",
    "            node_type_mapping[graph.nodes[n]['type']] +\n",
    "            graph.nodes[n]['center'] +\n",
    "            graph.nodes[n]['normal'] +\n",
    "            [graph.nodes[n].get('length', -1)],\n",
    "            dtype=torch.float32\n",
    "        )\n",
    "        for n in node_ids\n",
    "    ])\n",
    "\n",
    "    edge_index = torch.tensor(\n",
    "        [[id_map[u], id_map[v]] for u, v in graph.edges()],\n",
    "        dtype=torch.long\n",
    "    ).t().contiguous() if graph.edges else torch.empty((2, 0), dtype=torch.long)\n",
    "\n",
    "    data = Data(x=x, edge_index=edge_index)\n",
    "    data.name = graph.graph.get('name')\n",
    "    data.node_names = node_ids\n",
    "    data.permutation = torch.arange(len(node_ids), dtype=torch.long)\n",
    "    return data\n",
    "\n",
    "def split_graphs_stratified(\n",
    "    pairs: List[Tuple[Data, Data, torch.Tensor]],\n",
    "    train_frac: float = 0.7,\n",
    "    val_frac: float   = 0.15,\n",
    "    test_frac: float  = 0.15,\n",
    "    n_bins: int       = 5,\n",
    "    seed: int         = seed,\n",
    "    stratify_on: str  = \"g2\"     # \"g1\" oppure \"g2\"\n",
    ") -> Tuple[\n",
    "    List[Tuple[Data,Data,torch.Tensor]],\n",
    "    List[Tuple[Data,Data,torch.Tensor]],\n",
    "    List[Tuple[Data,Data,torch.Tensor]]\n",
    "]:\n",
    "    \"\"\"\n",
    "    Stratified split of graph-matching pairs into train/val/test.\n",
    "    Puoi stratificare sulla dimensione di g1 o di g2.\n",
    "    \"\"\"\n",
    "    assert stratify_on in (\"g1\",\"g2\"), \"stratify_on must be 'g1' or 'g2'\"\n",
    "    total = train_frac + val_frac + test_frac\n",
    "    assert abs(total - 1.0) < 1e-6, \"train+val+test fractions must sum to 1.0\"\n",
    "\n",
    "    # scegli la dimensione su cui stratificare\n",
    "    if stratify_on == \"g1\":\n",
    "        sizes = np.array([g1.num_nodes for g1, g2, P in pairs])\n",
    "    else:\n",
    "        sizes = np.array([g2.num_nodes for g1, g2, P in pairs])\n",
    "\n",
    "    # quantile‑binning per equal‑frequency\n",
    "    while n_bins > 1:\n",
    "        try:\n",
    "            size_bins = pd.qcut(sizes, q=n_bins, labels=False, duplicates=\"drop\")\n",
    "        except ValueError:\n",
    "            n_bins -= 1\n",
    "            continue\n",
    "        counts = np.bincount(size_bins, minlength=n_bins)\n",
    "        if np.all(counts >= 2):\n",
    "            break\n",
    "        n_bins -= 1\n",
    "\n",
    "    idx = np.arange(len(pairs))\n",
    "    if n_bins <= 1:\n",
    "        # fallback random split\n",
    "        train_idx, temp_idx = train_test_split(idx, test_size=1-train_frac, random_state=seed)\n",
    "        rel_val = val_frac/(val_frac+test_frac)\n",
    "        val_idx, test_idx = train_test_split(temp_idx, test_size=1-rel_val, random_state=seed)\n",
    "    else:\n",
    "        train_idx, temp_idx = train_test_split(\n",
    "            idx, test_size=(1.0-train_frac),\n",
    "            random_state=seed, stratify=size_bins\n",
    "        )\n",
    "        rel_val = val_frac/(val_frac+test_frac)\n",
    "        temp_bins = size_bins[temp_idx]\n",
    "        val_idx, test_idx = train_test_split(\n",
    "            temp_idx, test_size=(1.0-rel_val),\n",
    "            random_state=seed, stratify=temp_bins\n",
    "        )\n",
    "\n",
    "    train = [pairs[i] for i in train_idx]\n",
    "    val   = [pairs[i] for i in val_idx]\n",
    "    test  = [pairs[i] for i in test_idx]\n",
    "    return train, val, test\n",
    "\n",
    "# Controllo rapido delle distribuzioni\n",
    "def describe(split, name):\n",
    "    sz = [g1.num_nodes for g1, _, _ in split]\n",
    "    print(f\"{name}: count={len(split)}, nodes min={min(sz)}, max={max(sz)}, mean={np.mean(sz):.1f}\")\n",
    "\n",
    "def generate_matching_pair_as_data(\n",
    "    g1: nx.DiGraph,\n",
    "    g2: nx.DiGraph,\n",
    "    pairs_list: List[Tuple[Data, Data, torch.Tensor]]\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Generate a matching pair for partial graph matching:\n",
    "    - g1: complete graph (reference)\n",
    "    - g2: partial graph to be permuted\n",
    "    Stores (Data_g1, Data_g2_permuted, P) in pairs_list, where P is ground truth of shape [|g1|, |g2|].\n",
    "    \"\"\"\n",
    "    # Convert reference graph\n",
    "    pyg_g1 = nx_to_pyg_data_preserve_order(g1)\n",
    "\n",
    "    # Prepare original names and permutation for g2\n",
    "    orig_names = list(g2.nodes())\n",
    "    num_g1 = g1.number_of_nodes()\n",
    "    num_g2 = len(orig_names)\n",
    "    perm_indices = torch.randperm(num_g2)\n",
    "\n",
    "    # Build permuted g2\n",
    "    g2_perm = nx.DiGraph()\n",
    "    g2_perm.graph['name'] = g2.graph.get('name', '')\n",
    "    for new_idx, orig_idx in enumerate(perm_indices.tolist()):\n",
    "        orig_id = orig_names[orig_idx]\n",
    "        g2_perm.add_node(new_idx, **g2.nodes[orig_id])\n",
    "    # Remap edges\n",
    "    orig_to_new = {orig_names[idx]: new for new, idx in enumerate(perm_indices.tolist())}\n",
    "    for u, v, data_edge in g2.edges(data=True):\n",
    "        if u in orig_to_new and v in orig_to_new:\n",
    "            g2_perm.add_edge(orig_to_new[u], orig_to_new[v], **data_edge)\n",
    "\n",
    "    # Convert permuted graph and attach metadata\n",
    "    pyg_g2 = nx_to_pyg_data_preserve_order(g2_perm)\n",
    "    pyg_g2.permutation = perm_indices\n",
    "    pyg_g2.node_names = orig_names\n",
    "\n",
    "    # Build partial assignment ground truth P [|g1| x |g2|]\n",
    "    P = torch.zeros((num_g1, num_g2), dtype=torch.float32)\n",
    "    g1_ids = list(g1.nodes())\n",
    "    # For each permuted node in g2, find matching index in g1\n",
    "    for j, orig_idx in enumerate(perm_indices.tolist()):\n",
    "        orig_id = orig_names[orig_idx]\n",
    "        if orig_id in g1_ids:\n",
    "            i = g1_ids.index(orig_id)\n",
    "            P[i, j] = 1.0\n",
    "\n",
    "    # Append without transpose to keep shape [|g1|, |g2|]\n",
    "    pairs_list.append((pyg_g1, pyg_g2, P))\n",
    "\n",
    "\n",
    "def plot_two_graphs_with_matching(graphs_list, gt_perm, original_graphs, path=None, noise_graphs=None, pred_perm=None,\n",
    "                                  viz_rooms=True, viz_ws=True,\n",
    "                                  viz_room_connection=True,\n",
    "                                  viz_normals=False, viz_room_normals=False,\n",
    "                                  match_display=\"all\"):\n",
    "    assert match_display in {\"all\", \"correct\", \"wrong\"}, \"match_display must be one of: 'all', 'correct', 'wrong'\"\n",
    "    assert len(graphs_list) == 2, \"graphs_list must contain exactly two graphs.\"\n",
    "    if noise_graphs is None:\n",
    "        noise_graphs = original_graphs\n",
    "\n",
    "    # Extract tensors and original node order\n",
    "    g1tensor, g2tensor = copy.deepcopy(graphs_list[0]), copy.deepcopy(graphs_list[1])\n",
    "    # Node names for g1 in original order\n",
    "    node_names1 = list(g1tensor.node_names)\n",
    "    # Reconstruct node names for g2 according to its permutation\n",
    "    orig_names2 = list(g2tensor.node_names)\n",
    "    perm = g2tensor.permutation.tolist()\n",
    "    node_names2 = [orig_names2[p] for p in perm]\n",
    "\n",
    "    # Convert to NetworkX\n",
    "    g1 = copy.deepcopy(pyg_data_to_nx_digraph(g1tensor, original_graphs))\n",
    "    g2_original = copy.deepcopy(pyg_data_to_nx_digraph(g2tensor, noise_graphs))\n",
    "    g2 = g2_original.copy()\n",
    "\n",
    "    # Translate g2 for side-by-side plot\n",
    "    max_x_g1 = max(data['center'][0] for _, data in g1.nodes(data=True))\n",
    "    min_x_g2 = min(data['center'][0] for _, data in g2.nodes(data=True))\n",
    "    translation_x = (max_x_g1 - min_x_g2) + 10.0\n",
    "    for _, data in g2.nodes(data=True):\n",
    "        data['center'][0] += translation_x\n",
    "        if 'polygon' in data:\n",
    "            poly = data['polygon']\n",
    "            if isinstance(poly, Polygon):\n",
    "                data['polygon'] = translate(poly, xoff=translation_x)\n",
    "            else:\n",
    "                data['polygon'] = Polygon([(x + translation_x, y) for x, y in poly])\n",
    "        if 'limits' in data:\n",
    "            data['limits'] = [[x + translation_x, y] for x, y in data['limits']]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(16, 10))\n",
    "    legend_added = set()\n",
    "\n",
    "    def plot_graph(g, is_g1):\n",
    "        color_room = 'lightblue' if is_g1 else 'navajowhite'\n",
    "        color_ws = 'red' if is_g1 else 'purple'\n",
    "        prefix = \"(G1)\" if is_g1 else \"(G2)\"\n",
    "\n",
    "        if viz_rooms:\n",
    "            for n, d in g.nodes(data=True):\n",
    "                if d['type'] == 'room' and 'polygon' in d:\n",
    "                    poly = Polygon(d['polygon']) if not isinstance(d['polygon'], Polygon) else d['polygon']\n",
    "                    x, y = poly.exterior.xy\n",
    "                    ax.fill(x, y, color=color_room, alpha=0.3,\n",
    "                            label=f\"Room polygon {prefix}\" if f\"room-poly-{prefix}\" not in legend_added else \"\")\n",
    "                    ax.scatter(d['center'][0], d['center'][1], color='blue', s=80,\n",
    "                               label=f\"Centroid {prefix}\" if f\"room-pt-{prefix}\" not in legend_added else \"\")\n",
    "                    legend_added.update({f\"room-poly-{prefix}\", f\"room-pt-{prefix}\"})\n",
    "\n",
    "        if viz_ws:\n",
    "            for n, d in g.nodes(data=True):\n",
    "                if d['type'] == 'ws':\n",
    "                    ax.scatter(d['center'][0], d['center'][1], color=color_ws, s=20,\n",
    "                               label=f\"WS {prefix}\" if f\"ws-{prefix}\" not in legend_added else \"\")\n",
    "                    legend_added.add(f\"ws-{prefix}\")\n",
    "                    if 'limits' in d:\n",
    "                        limit1, limit2 = d['limits']\n",
    "                        ax.plot([limit1[0], limit2[0]], [limit1[1], limit2[1]],\n",
    "                                color='black', linewidth=1.0,\n",
    "                                label=f\"WS limits {prefix}\" if f\"limits-{prefix}\" not in legend_added else \"\")\n",
    "                        legend_added.add(f\"limits-{prefix}\")\n",
    "\n",
    "    plot_graph(g1, is_g1=True)\n",
    "    plot_graph(g2, is_g1=False)\n",
    "\n",
    "    # Plot matching lines with partial-match and ID presence checks\n",
    "    if pred_perm is not None:\n",
    "        for i in range(pred_perm.shape[0]):  # for each row\n",
    "            # skip if ground truth has no assignment for this node\n",
    "            if gt_perm[i].sum().item() == 0:\n",
    "                continue\n",
    "            row = pred_perm[i]\n",
    "            # determine if prediction exists\n",
    "            if row.sum().item() == 0:\n",
    "                # missing prediction: draw based on ground truth\n",
    "                j_gt = gt_perm[i].argmax().item()\n",
    "                # map indices to node IDs\n",
    "                id1 = node_names1[i]\n",
    "                if id1 not in g1.nodes:\n",
    "                    continue\n",
    "                if j_gt < len(node_names2):\n",
    "                    id2 = node_names2[j_gt]\n",
    "                else:\n",
    "                    continue\n",
    "                if id2 not in g2.nodes:\n",
    "                    continue\n",
    "                pt1 = g1.nodes[id1]['center']\n",
    "                pt2 = g2.nodes[id2]['center']\n",
    "                # skip if match_display filters out missing\n",
    "                if match_display in {\"correct\", \"wrong\"}:\n",
    "                    continue\n",
    "                color = 'yellow'\n",
    "                label = None\n",
    "                if 'missing' not in legend_added:\n",
    "                    label = 'Missing match'\n",
    "                    legend_added.add('missing')\n",
    "                ax.plot([pt1[0], pt2[0]], [pt1[1], pt2[1]],\n",
    "                        color=color, linestyle='--', alpha=0.6, linewidth=1, label=label)\n",
    "                continue\n",
    "            # has prediction: handle correct/wrong\n",
    "            j = row.argmax().item()\n",
    "            # map indices to node IDs\n",
    "            id1 = node_names1[i]\n",
    "            if id1 not in g1.nodes:\n",
    "                continue\n",
    "            if j < len(node_names2):\n",
    "                id2 = node_names2[j]\n",
    "            else:\n",
    "                continue\n",
    "            if id2 not in g2.nodes:\n",
    "                continue\n",
    "            pt1 = g1.nodes[id1]['center']\n",
    "            pt2 = g2.nodes[id2]['center']\n",
    "            is_correct = (j < gt_perm.shape[1] and gt_perm[i, j] == 1)\n",
    "            if match_display == \"correct\" and not is_correct:\n",
    "                continue\n",
    "            if match_display == \"wrong\" and is_correct:\n",
    "                continue\n",
    "            color = 'green' if is_correct else 'red'\n",
    "            label = None\n",
    "            if color == 'green' and 'correct' not in legend_added:\n",
    "                label = 'Correct match'\n",
    "                legend_added.add('correct')\n",
    "            elif color == 'red' and 'wrong' not in legend_added:\n",
    "                label = 'Wrong match'\n",
    "                legend_added.add('wrong')\n",
    "            ax.plot([pt1[0], pt2[0]], [pt1[1], pt2[1]],\n",
    "                    color=color, linestyle='-', alpha=0.6, linewidth=1, label=label)\n",
    "\n",
    "    ax.set_title(\"Graph Matching: Green = Correct, Red = Wrong\")\n",
    "    ax.axis(\"equal\")\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    if path is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(path)\n",
    "        plt.close()\n",
    "\n",
    "def normalize_data_pairs(\n",
    "    pairs: List[Tuple[Data, Data, torch.Tensor]],\n",
    "    mean: torch.Tensor,\n",
    "    std: torch.Tensor\n",
    ") -> List[Tuple[Data, Data, torch.Tensor]]:\n",
    "    \"\"\"\n",
    "    Normalizza per-feature i tensori x in ciascun Data object all'interno delle tuple.\n",
    "\n",
    "    Args:\n",
    "        pairs: Lista di tuple (Data1, Data2, P)\n",
    "        mean: Tensor di media per-feature (shape: [num_features])\n",
    "        std: Tensor di deviazione standard per-feature (shape: [num_features])\n",
    "\n",
    "    Returns:\n",
    "        Lista di tuple con i Data normalizzati.\n",
    "    \"\"\"\n",
    "    normalized_pairs = []\n",
    "    for data1, data2, P in pairs:\n",
    "        data1.x = (data1.x - mean) / (std + 1e-8)\n",
    "        data2.x = (data2.x - mean) / (std + 1e-8)\n",
    "        normalized_pairs.append((data1, data2, P))\n",
    "    return normalized_pairs\n",
    "\n",
    "def compute_mean_std(pairs: List[Tuple[Data, Data, torch.Tensor]]) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Calcola la media e la deviazione standard per-feature dai Data objects nel training set.\n",
    "\n",
    "    Args:\n",
    "        pairs: Lista di tuple (Data1, Data2, P) del training set\n",
    "\n",
    "    Returns:\n",
    "        Tuple contenente (mean, std) per-feature\n",
    "    \"\"\"\n",
    "    x_list = []\n",
    "    for data1, data2, _ in pairs:\n",
    "        x_list.append(data1.x)\n",
    "        x_list.append(data2.x)\n",
    "    x_all = torch.cat(x_list, dim=0)\n",
    "    mean = x_all.mean(dim=0)\n",
    "    std = x_all.std(dim=0)\n",
    "    return mean, std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------\n",
    "#            LOGGING\n",
    "#----------------------------------------\n",
    "\n",
    "# Generic logger setup for any model/dataset\n",
    "def setup_tb_logger(\n",
    "    base_dir: str = \"runs\",\n",
    "    model_name: str = None,\n",
    "    dataset_name: str = None,\n",
    "    experiment_name: str = None\n",
    ") -> SummaryWriter:\n",
    "    \"\"\"\n",
    "    Create a TensorBoard SummaryWriter with a structured log directory.\n",
    "\n",
    "    Args:\n",
    "        base_dir: root directory for all runs.\n",
    "        model_name: identifier for the model (e.g. \"GATv2\", \"MyModel\").\n",
    "        dataset_name: identifier for the dataset (e.g. \"CIFAR10\").\n",
    "        experiment_name: optional extra tag (e.g. \"dropout0.3\").\n",
    "\n",
    "    Returns:\n",
    "        writer: a SummaryWriter instance logging to runs/... directory.\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "    if model_name:\n",
    "        parts.append(model_name)\n",
    "    if dataset_name:\n",
    "        parts.append(dataset_name)\n",
    "    if experiment_name:\n",
    "        parts.append(experiment_name)\n",
    "    # timestamp for uniqueness\n",
    "    parts.append(datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
    "    log_dir = os.path.join(base_dir, \"__\".join(parts))\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "    return writer\n",
    "\n",
    "\n",
    "def log_gradients(\n",
    "    writer: SummaryWriter,\n",
    "    model: torch.nn.Module,\n",
    "    epoch: int,\n",
    "    prefix: str = \"grad_norms\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Log the L2 norm of gradients of all parameters in the model.\n",
    "\n",
    "    Args:\n",
    "        writer: SummaryWriter returned by setup_tb_logger.\n",
    "        model: the neural network model whose gradients to log.\n",
    "        epoch: current epoch or step index.\n",
    "        prefix: prefix for the TensorBoard tags.\n",
    "    \"\"\"\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.grad is not None:\n",
    "            writer.add_scalar(f\"{prefix}/{name}\", param.grad.norm().item(), epoch)\n",
    "\n",
    "\n",
    "def log_metrics(\n",
    "    writer: SummaryWriter,\n",
    "    metrics: Dict[str, float],\n",
    "    epoch: int,\n",
    "    prefix: str = \"\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Log arbitrary metrics (e.g. losses, accuracies) to TensorBoard.\n",
    "\n",
    "    Args:\n",
    "        writer: SummaryWriter returned by setup_tb_logger.\n",
    "        metrics: dict of metric_name -> value.\n",
    "        epoch: current epoch or step index.\n",
    "        prefix: optional prefix for tags (e.g. \"train\", \"val\").\n",
    "    \"\"\"\n",
    "    for key, value in metrics.items():\n",
    "        tag = f\"{prefix}/{key}\" if prefix else key\n",
    "        writer.add_scalar(tag, value, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------\n",
    "#            TRAINING UTILS\n",
    "#----------------------------------------\n",
    "\n",
    "# Create the plot\n",
    "def plot_losses(train_losses, val_losses, output_path=None):\n",
    "    epochs = list(range(len(train_losses)))\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.lineplot(x=epochs, y=train_losses, label=\"Training Loss\")\n",
    "    sns.lineplot(x=epochs, y=val_losses, label=\"Validation Loss\")\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training vs Validation Loss\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if output_path is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        # Save the plot to the specified path\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()\n",
    "\n",
    "class GraphMatchingDataset(Dataset):\n",
    "    def __init__(self, pairs):  # lista di (Data, Data, P)\n",
    "        self.pairs = pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.pairs[idx]  # data1, data2, P\n",
    "\n",
    "def collate_pyg_matching(batch):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    data1_list, data2_list, perm_list = zip(*batch)\n",
    "    \n",
    "    # Sposta ogni grafo sul device corretto\n",
    "    data1_list = [d.to(device) for d in data1_list]\n",
    "    data2_list = [d.to(device) for d in data2_list]\n",
    "    \n",
    "    batch1 = Batch.from_data_list(data1_list)\n",
    "    batch2 = Batch.from_data_list(data2_list)\n",
    "    \n",
    "    return batch1, batch2, perm_list\n",
    "\n",
    "### FUNCTIONS WITH COLUMN-WISE CE\n",
    "# def train_epoch_sinkhorn(model, loader, optimizer, writer, epoch, eps: float = 1e-9):\n",
    "#     \"\"\"\n",
    "#     Trains one epoch of a Sinkhorn-based graph matching model using column-wise cross-entropy loss.\n",
    "#     Returns:\n",
    "#         avg_loss (float): average column CE loss per batch.\n",
    "#         all_embeddings (list): collected embeddings from the model.\n",
    "#     \"\"\"\n",
    "#     model.train()\n",
    "#     total_loss = 0.0\n",
    "#     all_embeddings = []\n",
    "#     device = next(model.parameters()).device\n",
    "\n",
    "#     for batch1, batch2, perm_list in loader:\n",
    "#         batch1 = batch1.to(device)\n",
    "#         batch2 = batch2.to(device)\n",
    "#         perm_list = [p.to(device) for p in perm_list]\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         batch_idx1 = batch1.batch\n",
    "#         batch_idx2 = batch2.batch\n",
    "#         pred_perm_list, batch_embeddings = model(batch1, batch2, batch_idx1, batch_idx2)\n",
    "\n",
    "#         # column-wise cross-entropy\n",
    "#         batch_loss = 0.0\n",
    "#         for P, P_gt in zip(pred_perm_list, perm_list):\n",
    "#             # For each column j: -sum_i P_gt[i,j] * log(P[i,j])\n",
    "#             ce_per_col = -torch.sum(P_gt * torch.log(P + eps), dim=0)\n",
    "#             batch_loss += ce_per_col.mean()\n",
    "#         batch_loss = batch_loss / len(pred_perm_list)\n",
    "\n",
    "#         batch_loss.backward()\n",
    "#         # Log gradients\n",
    "#         log_gradients(writer, model, epoch)\n",
    "#         optimizer.step()\n",
    "\n",
    "#         total_loss += batch_loss.item()\n",
    "#         all_embeddings.extend(batch_embeddings)\n",
    "\n",
    "#     avg_loss = total_loss / len(loader)\n",
    "#     return avg_loss, all_embeddings\n",
    "\n",
    "\n",
    "# def evaluate_sinkhorn(model, loader, eps: float = 1e-9):\n",
    "#     \"\"\"\n",
    "#     Evaluates a Sinkhorn-based graph matching model using column-wise cross-entropy\n",
    "#     and permutation accuracy.\n",
    "#     Returns:\n",
    "#         avg_acc (float): permutation accuracy over all columns.\n",
    "#         avg_loss (float): average column CE loss per example.\n",
    "#         all_embeddings (list): collected embeddings from the model.\n",
    "#     \"\"\"\n",
    "#     model.eval()\n",
    "#     correct = 0\n",
    "#     total_cols = 0\n",
    "#     total_loss = 0.0\n",
    "#     num_graphs = 0\n",
    "#     all_embeddings = []\n",
    "\n",
    "#     device = next(model.parameters()).device\n",
    "#     with torch.no_grad():\n",
    "#         for batch1, batch2, perm_list in loader:\n",
    "#             batch1 = batch1.to(device)\n",
    "#             batch2 = batch2.to(device)\n",
    "#             perm_list = [p.to(device) for p in perm_list]\n",
    "\n",
    "#             batch_idx1 = batch1.batch\n",
    "#             batch_idx2 = batch2.batch\n",
    "#             pred_perm_list, batch_embeddings = model(batch1, batch2, batch_idx1, batch_idx2)\n",
    "\n",
    "#             for P, P_gt in zip(pred_perm_list, perm_list):\n",
    "#                 # permutation accuracy: column-wise argmax compare\n",
    "#                 pred_idx = P.argmax(dim=0)\n",
    "#                 target_idx = P_gt.argmax(dim=0)\n",
    "#                 correct += (pred_idx == target_idx).sum().item()\n",
    "#                 total_cols += P.shape[1]\n",
    "\n",
    "#                 # column-wise CE loss\n",
    "#                 ce_per_col = -torch.sum(P_gt * torch.log(P + eps), dim=0)\n",
    "#                 total_loss += ce_per_col.mean().item()\n",
    "#                 num_graphs += 1\n",
    "\n",
    "#             all_embeddings.extend(batch_embeddings)\n",
    "\n",
    "#     avg_acc = correct / total_cols if total_cols > 0 else 0.0\n",
    "#     avg_loss = total_loss / num_graphs if num_graphs > 0 else 0.0\n",
    "#     return avg_acc, avg_loss, all_embeddings\n",
    "\n",
    "### FUNCTIONS WITH BCE\n",
    "def bce_permutation_loss(P, P_gt, eps: float = 1e-9):\n",
    "    \"\"\"Element-wise Binary Cross Entropy loss between prediction and ground truth.\"\"\"\n",
    "    return - (P_gt * torch.log(P + eps) + (1 - P_gt) * torch.log(1 - P + eps)).mean()\n",
    "\n",
    "def train_epoch_sinkhorn(model, loader, optimizer, writer, epoch, eps: float = 1e-9):\n",
    "    \"\"\"\n",
    "    Trains one epoch of a Sinkhorn-based graph matching model using Binary Cross Entropy (BCE) loss.\n",
    "    Returns:\n",
    "        avg_loss (float): average BCE loss per graph.\n",
    "        all_embeddings (list): collected embeddings from the model.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    num_graphs = 0\n",
    "    all_embeddings = []\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    for batch1, batch2, perm_list in loader:\n",
    "        batch1 = batch1.to(device)\n",
    "        batch2 = batch2.to(device)\n",
    "        perm_list = [p.to(device) for p in perm_list]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        batch_idx1 = batch1.batch\n",
    "        batch_idx2 = batch2.batch\n",
    "        pred_perm_list, batch_embeddings = model(batch1, batch2, perm_list, batch_idx1, batch_idx2)\n",
    "\n",
    "        # accumulo loss per grafo\n",
    "        batch_loss = 0.0\n",
    "        for P, P_gt in zip(pred_perm_list, perm_list):\n",
    "            loss = bce_permutation_loss(P, P_gt, eps)  # assume reduction='mean'\n",
    "            batch_loss += loss\n",
    "            total_loss += loss.item()\n",
    "            num_graphs += 1\n",
    "\n",
    "        batch_loss = batch_loss / len(pred_perm_list)  # per logging/grad\n",
    "        batch_loss.backward()\n",
    "        log_gradients(writer, model, epoch)\n",
    "        optimizer.step()\n",
    "\n",
    "        all_embeddings.extend(batch_embeddings)\n",
    "\n",
    "    avg_loss = total_loss / num_graphs if num_graphs > 0 else 0.0\n",
    "    return avg_loss, all_embeddings\n",
    "\n",
    "\n",
    "def evaluate_sinkhorn(model, loader, eps: float = 1e-9):\n",
    "    \"\"\"\n",
    "    Evaluates a Sinkhorn-based graph matching model using Binary Cross Entropy\n",
    "    and permutation accuracy.\n",
    "    Returns:\n",
    "        avg_acc (float): permutation accuracy over all columns.\n",
    "        avg_loss (float): average BCE loss per graph.\n",
    "        all_embeddings (list): collected embeddings from the model.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total_cols = 0\n",
    "    total_loss = 0.0\n",
    "    num_graphs = 0\n",
    "    all_embeddings = []\n",
    "\n",
    "    device = next(model.parameters()).device\n",
    "    with torch.no_grad():\n",
    "        for batch1, batch2, perm_list in loader:\n",
    "            batch1 = batch1.to(device)\n",
    "            batch2 = batch2.to(device)\n",
    "            perm_list = [p.to(device) for p in perm_list]\n",
    "\n",
    "            batch_idx1 = batch1.batch\n",
    "            batch_idx2 = batch2.batch\n",
    "            pred_perm_list, batch_embeddings = model(batch1, batch2, perm_list, batch_idx1, batch_idx2)\n",
    "\n",
    "            for P, P_gt in zip(pred_perm_list, perm_list):\n",
    "                # accuracy\n",
    "                pred_idx = P.argmax(dim=0)\n",
    "                target_idx = P_gt.argmax(dim=0)\n",
    "                correct += (pred_idx == target_idx).sum().item()\n",
    "                total_cols += P.shape[1]\n",
    "\n",
    "                # loss per grafo\n",
    "                loss = bce_permutation_loss(P, P_gt, eps)\n",
    "                total_loss += loss.item()\n",
    "                num_graphs += 1\n",
    "\n",
    "            all_embeddings.extend(batch_embeddings)\n",
    "\n",
    "    avg_acc = correct / total_cols if total_cols > 0 else 0.0\n",
    "    avg_loss = total_loss / num_graphs if num_graphs > 0 else 0.0\n",
    "    return avg_acc, avg_loss, all_embeddings\n",
    "\n",
    "\n",
    "def predict_matching_matrix(model, data1, data2, use_hungarian: bool = True):\n",
    "    \"\"\"\n",
    "    Produces a matching matrix between data1 and data2.\n",
    "    If use_hungarian=True, applies the Hungarian algorithm to the similarity scores.\n",
    "    Otherwise returns the raw similarity matrix.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    with torch.no_grad():\n",
    "        data1 = data1.to(device)\n",
    "        data2 = data2.to(device)\n",
    "        batch_idx1 = torch.zeros(data1.num_nodes, dtype=torch.long, device=device)\n",
    "        batch_idx2 = torch.zeros(data2.num_nodes, dtype=torch.long, device=device)\n",
    "\n",
    "        sim_matrix_list, _ = model(data1, data2, batch_idx1, batch_idx2, inference=True)\n",
    "        sim = sim_matrix_list[0].unsqueeze(0)  # [1, N1, N2]\n",
    "\n",
    "        n1 = torch.tensor([sim.shape[1]], dtype=torch.int32, device=device)\n",
    "        n2 = torch.tensor([sim.shape[2]], dtype=torch.int32, device=device)\n",
    "\n",
    "        if use_hungarian:\n",
    "            # returns a hard assignment matrix [N1, N2]\n",
    "            return pygmtools.hungarian(sim, n1=n1, n2=n2).squeeze(0)\n",
    "        else:\n",
    "            # return soft scores [N1, N2]\n",
    "            return sim.squeeze(0)\n",
    "\n",
    "\n",
    "def train_loop(model, optimizer, train_loader, val_loader, num_epochs, writer,\n",
    "               best_model_path='checkpoint.pt', final_model_path='final_model.pt',\n",
    "               patience=10, resume=False):\n",
    "    best_val_loss = float('inf')\n",
    "    best_epoch = -1\n",
    "    patience_counter = 0\n",
    "    start_epoch = 0\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_embeddings_history = []\n",
    "\n",
    "    # Resume from checkpoint if requested\n",
    "    if resume and os.path.exists(best_model_path):\n",
    "        print(f\"Loading checkpoint from {best_model_path}\")\n",
    "        checkpoint = torch.load(best_model_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        best_val_loss = checkpoint['best_val_loss']\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        best_epoch = checkpoint['best_epoch']\n",
    "        print(f\"Resumed from epoch {start_epoch}\")\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "\n",
    "    try:\n",
    "        for epoch in range(start_epoch, num_epochs):\n",
    "            # Train\n",
    "            train_loss, _ = train_epoch_sinkhorn(model, train_loader, optimizer, writer, epoch)\n",
    "            # Evaluate\n",
    "            val_acc, val_loss, val_embeddings = evaluate_sinkhorn(model, val_loader)\n",
    "            \n",
    "            log_metrics(writer, {\"loss\": train_loss}, epoch, prefix=\"train\")\n",
    "            log_metrics(writer, {\"loss\": val_loss, \"acc\": val_acc}, epoch, prefix=\"val\")\n",
    "\n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            val_embeddings_history.append(val_embeddings)\n",
    "\n",
    "            # Save best model\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_epoch = epoch\n",
    "                patience_counter = 0\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'best_val_loss': best_val_loss,\n",
    "                    'best_epoch': best_epoch\n",
    "                }, best_model_path)\n",
    "                print(f\"[Epoch {epoch}] Saved new best model.\")\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "\n",
    "            print(f\"Epoch {epoch:03} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch}. Best was {best_epoch}.\")\n",
    "                break\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Training interrupted manually (Ctrl+C).\")\n",
    "\n",
    "    log_metrics(writer, {\"best_val_loss\": best_val_loss, \"best_epoch\": best_epoch}, epoch, prefix=\"best\")\n",
    "    writer.close()\n",
    "\n",
    "    # Save final model\n",
    "    torch.save({\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'best_val_loss': best_val_loss,\n",
    "    'best_epoch': best_epoch\n",
    "    }, final_model_path)\n",
    "    print(\"Final model saved.\")\n",
    "\n",
    "    return train_losses, val_losses, val_embeddings_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------\n",
    "#            MODELS\n",
    "#----------------------------------------\n",
    "\n",
    "# SG-pgm model adaptation\n",
    "# class MatchingModel_GATv2SinkhornTopK(nn.Module):\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         in_dim: int,\n",
    "#         hidden_dim: int,\n",
    "#         out_dim: int,\n",
    "#         sinkhorn_max_iter: int = 20,\n",
    "#         sinkhorn_tau: float = 5e-2,\n",
    "#     ):\n",
    "#         super().__init__()\n",
    "#         # ─── 1) GNN backbone: two-layer GATv2\n",
    "#         # First GATv2Conv projects in_dim → hidden_dim, apply ReLU\n",
    "#         # Second GATv2Conv projects hidden_dim → out_dim, no activation afterwards\n",
    "#         self.gnn = nn.ModuleList([\n",
    "#             GATv2Conv(in_dim, hidden_dim),\n",
    "#             GATv2Conv(hidden_dim, out_dim),\n",
    "#         ])\n",
    "#         # InstanceNorm to normalize each [N1×N2] similarity map\n",
    "#         self.inst_norm = nn.InstanceNorm2d(1, affine=True)\n",
    "\n",
    "#         # ─── 2) AFA-U “unified” module to predict number of inliers K\n",
    "#         #  univ_size = maximum graph size, used to pad all embeddings to fixed length\n",
    "#         self.k_top_encoder = AFAUEncoder()\n",
    "\n",
    "#         # Two small MLPs to reduce pooled embedding → scalar in [0,1]\n",
    "#         self.final_row = nn.Sequential(\n",
    "#             nn.Linear(out_dim, 8),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(8, 1),\n",
    "#             nn.Sigmoid()\n",
    "#         )\n",
    "#         self.final_col = nn.Sequential(\n",
    "#             nn.Linear(out_dim, 8),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(8, 1),\n",
    "#             nn.Sigmoid()\n",
    "#         )\n",
    "\n",
    "#         # Sinkhorn-TopK hyperparams\n",
    "#         self.sinkhorn_max_iter = sinkhorn_max_iter\n",
    "#         self.sinkhorn_tau      = sinkhorn_tau\n",
    "\n",
    "#     def encode(self, x, edge_index):\n",
    "#         \"\"\"\n",
    "#         Pass input features x through the two GATv2Conv layers.\n",
    "#         Apply ReLU after the first, but not after the last.\n",
    "#         \"\"\"\n",
    "#         for i, conv in enumerate(self.gnn):\n",
    "#             x = conv(x, edge_index)\n",
    "#             if i < len(self.gnn) - 1:\n",
    "#                 x = F.relu(x)\n",
    "#         return x\n",
    "\n",
    "#     def forward(self, batch1, batch2, batch_idx1=None, batch_idx2=None):\n",
    "#         \"\"\"\n",
    "#         batch1, batch2: PyG Data objects for the two graphs in each pair.\n",
    "#         batch_idx1, batch_idx2: optional precomputed batch assignments.\n",
    "#         Returns a list of final hard match matrices (perm_pred_list) and\n",
    "#         the raw embeddings for each graph pair (all_embeddings).\n",
    "#         \"\"\"\n",
    "#         # device = next(self.parameters()).device\n",
    "\n",
    "#         # ─── 1) Unpack node features & edge indices, move to GPU/CPU\n",
    "#         x1, edge1 = batch1.x.to(device), batch1.edge_index.to(device)\n",
    "#         x2, edge2 = batch2.x.to(device), batch2.edge_index.to(device)\n",
    "\n",
    "#         # ─── 2) Determine which node belongs to which graph in the batch\n",
    "#         #    If not supplied, read from Data.batch\n",
    "#         batch_idx1 = batch1.batch.to(device) if batch_idx1 is None else batch_idx1.to(device)\n",
    "#         batch_idx2 = batch2.batch.to(device) if batch_idx2 is None else batch_idx2.to(device)\n",
    "\n",
    "#         # ─── 3) Encode both sets of nodes via the GNN\n",
    "#         h1 = self.encode(x1, edge1)  # [total_nodes1, out_dim]\n",
    "#         h2 = self.encode(x2, edge2)  # [total_nodes2, out_dim]\n",
    "\n",
    "#         # How many graph pairs in this minibatch?\n",
    "#         B = batch_idx1.max().item() + 1\n",
    "\n",
    "#         perm_pred_list = []\n",
    "#         all_embeddings = []\n",
    "\n",
    "#         for b in range(B):\n",
    "#             # Isolate embeddings for the b-th graph pair\n",
    "#             h1_i = h1[batch_idx1 == b]  # shape [N1, d]\n",
    "#             h2_i = h2[batch_idx2 == b]  # shape [N2, d]\n",
    "#             N1, N2 = h1_i.size(0), h2_i.size(0)\n",
    "\n",
    "#             # ─── 4) Compute raw similarity: dot product between all node pairs\n",
    "#             sim = torch.matmul(h1_i, h2_i.T)    # [N1, N2]\n",
    "#             # Normalize per-instance so Sinkhorn is stable\n",
    "#             sim_b = sim.unsqueeze(0).unsqueeze(1)   # [1,1,N1,N2]\n",
    "#             sim_n = self.inst_norm(sim_b).squeeze(1)  # [1,N1,N2]\n",
    "\n",
    "#             # Prepare row/col sizes for pygmtools\n",
    "#             n1_t = torch.tensor([N1], dtype=torch.int32, device=device)\n",
    "#             n2_t = torch.tensor([N2], dtype=torch.int32, device=device)\n",
    "\n",
    "#             # Soft Sinkhorn → soft_match [N1,N2]\n",
    "#             soft_S = pygmtools.sinkhorn(sim_n, n1=n1_t, n2=n2_t, dummy_row=False)[0]\n",
    "\n",
    "#             # ─── 5) AFA-U predicts inlier count K from soft matching\n",
    "#             #   a) Expand dims to batch form\n",
    "#             row_emb = h1_i.unsqueeze(0)      # [1, N1, d]\n",
    "#             col_emb = h2_i.unsqueeze(0)      # [1, N2, d]\n",
    "#             cost_mat = sim_n                 # [1, N1, N2]\n",
    "\n",
    "#             #   b) Run the bipartite-attention encoder\n",
    "#             out_r, out_c = self.k_top_encoder(row_emb, col_emb, cost_mat) # [1, N1, d], [1, N2, d]\n",
    "            \n",
    "#             #   c) Dynamic max over nodes\n",
    "#             g_r = out_r.max(dim=1).values     # [1, d]\n",
    "#             g_c = out_c.max(dim=1).values     # [1, d]\n",
    "\n",
    "#             #   d) Small MLPs → fraction in [0,1]\n",
    "#             k_r = self.final_row(g_r).squeeze(-1)  # [1]\n",
    "#             k_c = self.final_col(g_c).squeeze(-1)  # [1]\n",
    "#             ks  = (k_r + k_c) / 2                  # [1] average of row/col predictions\n",
    "\n",
    "#             # ─── 6) Top-K matching\n",
    "\n",
    "#             if self.training:\n",
    "#                 # use ground-truth K\n",
    "#                 ks_gt = torch.tensor([N2], dtype=torch.long, device=device)\n",
    "#                 hard_S, soft_S = soft_topk(\n",
    "#                     sim_n, ks_gt,\n",
    "#                     max_iter=self.sinkhorn_max_iter,\n",
    "#                     tau=self.sinkhorn_tau,\n",
    "#                     nrows=n1_t, ncols=n2_t,\n",
    "#                     return_prob=True\n",
    "#                 )\n",
    "#                 perm_pred_list.append(soft_S[0])\n",
    "#             else:\n",
    "#                 ks_eff = (ks * N2).long()\n",
    "#                 hard_S = soft_topk(\n",
    "#                     sim_n, ks_eff,\n",
    "#                     max_iter=self.sinkhorn_max_iter,\n",
    "#                     tau=self.sinkhorn_tau,\n",
    "#                     nrows=n1_t, ncols=n2_t,\n",
    "#                     return_prob=False\n",
    "#                 )\n",
    "#                 perm_pred_list.append(hard_S[0])\n",
    "\n",
    "\n",
    "#             # ─── 7) Collect outputs for this pair\n",
    "#             all_embeddings.append((h1_i, h2_i))   # store embeddings for any downstream use\n",
    "\n",
    "#         return perm_pred_list, all_embeddings\n",
    "\n",
    "# Iperparametri\n",
    "\n",
    "in_dim = 7\n",
    "hidden_dim = 64\n",
    "out_dim = 32\n",
    "num_epochs = 200\n",
    "learning_rate = 1e-3\n",
    "batch_size = 16\n",
    "weight_decay = 5e-5\n",
    "patience = 30\n",
    "\n",
    "###     GRAPH MATCHING MODEL\n",
    "class MatchingModel_GATv2Sinkhorn(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim, attention_dropout=0.1, dropout_emb=0.1, temperature: float = 1.0, max_iter: int = 10, tau: float = 1):\n",
    "        super().__init__()\n",
    "        self.gnn = nn.ModuleList([\n",
    "            GATv2Conv(in_dim, hidden_dim, dropout=attention_dropout),\n",
    "            GATv2Conv(hidden_dim, out_dim, dropout=attention_dropout)\n",
    "        ])\n",
    "        self.dropout = nn.Dropout(p=dropout_emb)\n",
    "        # # bilinear weight matrix A per affinity\n",
    "        # std = 1.0 / math.sqrt(out_dim)\n",
    "        # self.A = nn.Parameter(torch.randn(out_dim, out_dim) * std)\n",
    "        # self.temperature = temperature\n",
    "        # InstanceNorm per-sample\n",
    "        self.inst_norm = nn.InstanceNorm2d(1, affine=True)\n",
    "        # Sinkhorn hyperparams\n",
    "        self.max_iter = max_iter\n",
    "        self.tau = tau\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        for i, conv in enumerate(self.gnn):\n",
    "            x = conv(x, edge_index)\n",
    "            if i < len(self.gnn) - 1:\n",
    "                x = F.relu(x)\n",
    "                x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, batch1, batch2, perm_list, batch_idx1=None, batch_idx2=None, inference=False):\n",
    "        device = next(self.parameters()).device\n",
    "\n",
    "        x1, edge1 = batch1.x.to(device), batch1.edge_index.to(device)\n",
    "        x2, edge2 = batch2.x.to(device), batch2.edge_index.to(device)\n",
    "        perm_list = [p.to(device) for p in perm_list]\n",
    "\n",
    "        batch_idx1 = batch1.batch.to(device) if batch_idx1 is None else batch_idx1.to(device)\n",
    "        batch_idx2 = batch2.batch.to(device) if batch_idx2 is None else batch_idx2.to(device)\n",
    "\n",
    "        h1 = self.encode(x1, edge1)\n",
    "        h2 = self.encode(x2, edge2)\n",
    "\n",
    "        B = batch_idx1.max().item() + 1\n",
    "        perm_pred_list = []\n",
    "        all_embeddings = []\n",
    "\n",
    "        for b in range(B):\n",
    "            h1_b = h1[batch_idx1 == b]   # [n1, d]\n",
    "            h2_b = h2[batch_idx2 == b]   # [n2, d]\n",
    "\n",
    "            # # ---- bilinear affinity ----\n",
    "            # # scores_{ij} = (h1_b @ A @ h2_b.T) / temperature\n",
    "            # scores = (h1_b @ self.A) @ h2_b.T\n",
    "            # M = torch.exp(scores / self.temperature)  # [n1, n2]\n",
    "            # # normalize and sinkhorn\n",
    "            # M_batched = M.unsqueeze(0).unsqueeze(1)  # [1,1,n1,n2]\n",
    "            # M_normed = self.inst_norm(M_batched).squeeze(1)  # [1,n1,n2] -> [n1,n2]\n",
    "\n",
    "            # affinity matrix + normalization + sinkhorn\n",
    "            sim = torch.matmul(h1_b, h2_b.T) # [n1, n2]\n",
    "            sim_batched = sim.unsqueeze(0).unsqueeze(1) # [1,1,n1,n2]\n",
    "            sim_normed = self.inst_norm(sim_batched).squeeze(1) # [1,n1,n2] -> [n1,n2]\n",
    "\n",
    "            S = pygmtools.sinkhorn(sim_normed, max_iter=self.max_iter, tau=self.tau)[0]\n",
    "            perm_pred_list.append(S)\n",
    "            all_embeddings.append((h1_b, h2_b))\n",
    "\n",
    "        return perm_pred_list, all_embeddings\n",
    "\n",
    "###     PARTIAL GRAPH MATCHING MODEL with MLP\n",
    "class MatchingModel_GATv2SinkhornTopK(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim, sinkhorn_max_iter, sinkhorn_tau,\n",
    "                attention_dropout, dropout_emb, num_layers, heads):\n",
    "        super().__init__()\n",
    "        # MLP for initial node feature transformation\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_emb),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_emb)\n",
    "        )\n",
    "        self.gnn = nn.ModuleList()\n",
    "        dims = [hidden_dim] * num_layers + [out_dim]\n",
    "        for i in range(num_layers):\n",
    "            # Always average the heads so the feature-dim stays dims[i+1]\n",
    "            self.gnn.append(\n",
    "                GATv2Conv(dims[i], dims[i+1],\n",
    "                            heads=heads, concat=False,\n",
    "                            dropout=attention_dropout)\n",
    "            )\n",
    "        self.dropout = nn.Dropout(p=dropout_emb)\n",
    "        # # bilinear weight matrix A per affinity\n",
    "        # std = 1.0 / math.sqrt(out_dim)\n",
    "        # self.A = nn.Parameter(torch.randn(out_dim, out_dim) * std)\n",
    "        # self.temperature = temperature\n",
    "        # InstanceNorm per-sample\n",
    "        self.inst_norm = nn.InstanceNorm2d(1, affine=True)\n",
    "        self.sinkhorn_max_iter = sinkhorn_max_iter\n",
    "        self.sinkhorn_tau = sinkhorn_tau\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        for i, conv in enumerate(self.gnn):\n",
    "            x = conv(x, edge_index)\n",
    "            if i < len(self.gnn) - 1:\n",
    "                x = F.relu(x)\n",
    "                x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, batch1, batch2, perm_list, batch_idx1=None, batch_idx2=None, inference=False):\n",
    "        device = next(self.parameters()).device\n",
    "        x1, edge1 = batch1.x.to(device), batch1.edge_index.to(device)\n",
    "        x2, edge2 = batch2.x.to(device), batch2.edge_index.to(device)\n",
    "        perm_list = [p.to(device) for p in perm_list]\n",
    "\n",
    "        batch_idx1 = batch1.batch.to(device) if batch_idx1 is None else batch_idx1.to(device)\n",
    "        batch_idx2 = batch2.batch.to(device) if batch_idx2 is None else batch_idx2.to(device)\n",
    "        \n",
    "        # Apply MLP before GNN\n",
    "        h1 = self.mlp(x1)\n",
    "        h2 = self.mlp(x2)\n",
    "        h1 = self.encode(h1, edge1)\n",
    "        h2 = self.encode(h2, edge2)\n",
    "\n",
    "        B = batch_idx1.max().item() + 1\n",
    "        perm_pred_list = []\n",
    "        all_embeddings = []\n",
    "\n",
    "        for b in range(B):\n",
    "            h1_b = h1[batch_idx1 == b]   # [n1, d]\n",
    "            h2_b = h2[batch_idx2 == b]   # [n2, d]\n",
    "            N1, N2 = h1_b.size(0), h2_b.size(0)\n",
    "\n",
    "            # # ---- bilinear affinity ----\n",
    "            # # scores_{ij} = (h1_b @ A @ h2_b.T) / temperature\n",
    "            # scores = (h1_b @ self.A) @ h2_b.T\n",
    "            # M = torch.exp(scores / self.temperature)  # [n1, n2]\n",
    "            # # normalize and sinkhorn\n",
    "            # M_batched = M.unsqueeze(0).unsqueeze(1)  # [1,1,n1,n2]\n",
    "            # M_normed = self.inst_norm(M_batched).squeeze(1)  # [1,n1,n2] -> [n1,n2]\n",
    "\n",
    "            # affinity matrix + normalization + sinkhorn\n",
    "            sim = torch.matmul(h1_b, h2_b.T) # [n1, n2]\n",
    "            sim_batched = sim.unsqueeze(0).unsqueeze(1) # [1,1,n1,n2]\n",
    "            sim_normed = self.inst_norm(sim_batched).squeeze(1) # [1,n1,n2] -> [n1,n2]\n",
    "\n",
    "            n1_t = torch.tensor([N1], dtype=torch.int32, device=device)\n",
    "            n2_t = torch.tensor([N2], dtype=torch.int32, device=device)\n",
    "            S = pygmtools.sinkhorn(sim_normed, n1=n1_t, n2=n2_t, max_iter=self.sinkhorn_max_iter, tau=self.sinkhorn_tau)\n",
    "            \n",
    "            ks_gt = torch.tensor([N2], dtype=torch.long, device=device)\n",
    "            \n",
    "            hard_S, soft_S = soft_topk(\n",
    "                S, ks_gt,\n",
    "                max_iter=self.sinkhorn_max_iter,\n",
    "                tau=self.sinkhorn_tau,\n",
    "                nrows=n1_t, ncols=n2_t,\n",
    "                return_prob=True\n",
    "            )\n",
    "\n",
    "            if inference:\n",
    "                perm_pred_list.append(hard_S[0])\n",
    "            else:\n",
    "                perm_pred_list.append(soft_S[0])\n",
    "\n",
    "            all_embeddings.append((h1_b, h2_b))\n",
    "\n",
    "        return perm_pred_list, all_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------\n",
    "#            PARAMETERS OPTIMIZATION\n",
    "#----------------------------------------\n",
    "\n",
    "def objective_gm(trial, train_dataset, val_dataset, path):\n",
    "    # iperparametri da esplorare\n",
    "    lr           = trial.suggest_loguniform(\"lr\", 1e-4, 1e-2)\n",
    "    weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-6, 1e-3)\n",
    "    dropout      = trial.suggest_uniform(\"dropout\", 0.0, 0.6)\n",
    "    hidden_dim   = trial.suggest_categorical(\"hidden_dim\", [32, 64, 128])\n",
    "    out_dim      = trial.suggest_categorical(\"out_dim\",    [16, 32, 64])\n",
    "    batch_size   = trial.suggest_categorical(\"batch_size\", [2, 4, 8])\n",
    "    heads        = trial.suggest_int(\"heads\",           1,   4)\n",
    "    attn_dropout = trial.suggest_uniform(\"attn_dropout\", 0.0, 0.6)\n",
    "    num_layers   = trial.suggest_int(\"num_layers\",       1,   3)\n",
    "    sinkhorn_tau = trial.suggest_loguniform(\"tau\",      1e-3, 1e-1)\n",
    "    max_iter     = trial.suggest_int(\"max_iter\",        10, 100)\n",
    "\n",
    "    # dataloader\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_pyg_matching)\n",
    "    val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False, collate_fn=collate_pyg_matching)\n",
    "\n",
    "    # modello\n",
    "    class MatchingModel(nn.Module):\n",
    "        def __init__(self,dropout, hidden_dim, out_dim, heads, attn_dropout, num_layers, sinkhorn_tau, max_iter):\n",
    "            super().__init__()\n",
    "            self.gnn = nn.ModuleList()\n",
    "            dims = [in_dim] + [hidden_dim] * (num_layers - 1) + [out_dim]\n",
    "            for i in range(num_layers):\n",
    "                # new: always average the heads so the feature‐dim stays dims[i+1]\n",
    "                self.gnn.append(\n",
    "                GATv2Conv(dims[i], dims[i+1],\n",
    "                            heads=heads, concat=False,\n",
    "                            dropout=attn_dropout))\n",
    "            self.dropout = dropout\n",
    "            # # bilinear weight matrix A per affinity\n",
    "            # std = 1.0 / math.sqrt(out_dim)\n",
    "            # self.A = nn.Parameter(torch.randn(out_dim, out_dim) * std)\n",
    "            # self.temperature = temperature\n",
    "            # InstanceNorm per-sample\n",
    "            self.inst_norm = nn.InstanceNorm2d(1, affine=True)\n",
    "            self.tau = sinkhorn_tau\n",
    "            self.max_iter = max_iter\n",
    "\n",
    "        def encode(self, x, edge_index):\n",
    "            for i, conv in enumerate(self.gnn):\n",
    "                x = conv(x, edge_index)\n",
    "                if i < len(self.gnn)-1:\n",
    "                    x = F.relu(x)\n",
    "                    x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            return x\n",
    "\n",
    "        def forward(self, batch1, batch2, perm_list, batch_idx1=None, batch_idx2=None, inference=False):\n",
    "            device = next(self.parameters()).device\n",
    "            x1, e1 = batch1.x.to(device), batch1.edge_index.to(device)\n",
    "            x2, e2 = batch2.x.to(device), batch2.edge_index.to(device)\n",
    "            perm_list = [p.to(device) for p in perm_list]\n",
    "            \n",
    "            if batch_idx1 is None:\n",
    "                batch_idx1 = batch1.batch.to(device)\n",
    "                batch_idx2 = batch2.batch.to(device)\n",
    "            h1 = self.encode(x1, e1)\n",
    "            h2 = self.encode(x2, e2)\n",
    "            B = batch_idx1.max().item()+1\n",
    "            loss = 0\n",
    "            for b in range(B):\n",
    "                h1_b = h1[batch_idx1==b]\n",
    "                h2_b = h2[batch_idx2==b]\n",
    "\n",
    "                # affinity matrix + normalization + sinkhorn\n",
    "                sim = torch.matmul(h1_b, h2_b.T) # [n1, n2]\n",
    "                sim_batched = sim.unsqueeze(0).unsqueeze(1) # [1,1,n1,n2]\n",
    "                sim_normed = self.inst_norm(sim_batched).squeeze(1) # [1,n1,n2] -> [n1,n2]\n",
    "\n",
    "                S = pygmtools.sinkhorn(sim_normed, tau=self.tau, max_iter=self.max_iter)[0]\n",
    "                loss = loss + bce_permutation_loss(S, perm_list[b])\n",
    "            return loss / B\n",
    "\n",
    "    model = MatchingModel(\n",
    "        dropout=dropout,\n",
    "        hidden_dim=hidden_dim,\n",
    "        out_dim=out_dim,\n",
    "        heads=heads,\n",
    "        attn_dropout=attn_dropout,\n",
    "        num_layers=num_layers,\n",
    "        sinkhorn_tau=sinkhorn_tau,\n",
    "        max_iter=max_iter\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    # training rapido con early stopping\n",
    "    best_val = float('inf')\n",
    "    counter = 0\n",
    "    for epoch in range(30):\n",
    "        # train\n",
    "        model.train()\n",
    "        for b1, b2, perm in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = model(b1, b2, perm)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        # validate\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for b1, b2, perm in val_loader:\n",
    "                val_loss += model(b1, b2, perm).item()\n",
    "        val_loss /= len(val_loader)\n",
    "        trial.report(val_loss, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "        if val_loss < best_val:\n",
    "            best_val = val_loss\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= 5:\n",
    "                break\n",
    "    \n",
    "    # save best trial info\n",
    "    if trial.number == 0 or best_val <= trial.study.best_value:\n",
    "        result = {\n",
    "            \"val_loss\": best_val,\n",
    "            \"params\": trial.params\n",
    "        }\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        with open(os.path.join(path, \"best_trial_results.json\"), \"w\") as f:\n",
    "            json.dump(result, f, indent=2)\n",
    "\n",
    "    return best_val\n",
    "\n",
    "def objective_pgm(trial, train_dataset, val_dataset, path):\n",
    "    lr           = trial.suggest_loguniform(\"lr\", 1e-4, 1e-2)\n",
    "    weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-6, 1e-3)\n",
    "    dropout_emb  = trial.suggest_uniform(\"dropout\", 0.0, 0.6)\n",
    "    hidden_dim   = trial.suggest_categorical(\"hidden_dim\", [32, 64, 128])\n",
    "    out_dim      = trial.suggest_categorical(\"out_dim\",    [16, 32, 64])\n",
    "    batch_size   = trial.suggest_categorical(\"batch_size\", [2, 4, 8])\n",
    "    attn_dropout = trial.suggest_uniform(\"attn_dropout\", 0.0, 0.6)\n",
    "    max_iter     = trial.suggest_int(\"max_iter\",        10, 100)\n",
    "    tau          = trial.suggest_loguniform(\"tau\",      1e-3, 1e-1)\n",
    "    num_layers   = trial.suggest_int(\"num_layers\",       1, 3)\n",
    "    heads        = trial.suggest_int(\"heads\",           1,   4)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_pyg_matching)\n",
    "    val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_pyg_matching)\n",
    "\n",
    "    # Flexible model for partial matching\n",
    "    class MatchingModel_GATv2SinkhornTopK_OPT(nn.Module):\n",
    "        def __init__(self, in_dim, hidden_dim, out_dim, sinkhorn_max_iter, sinkhorn_tau,\n",
    "                    attention_dropout, dropout_emb, num_layers, heads):\n",
    "            super().__init__()\n",
    "            self.gnn = nn.ModuleList()\n",
    "            dims = [in_dim] + [hidden_dim] * (num_layers - 1) + [out_dim]\n",
    "            for i in range(num_layers):\n",
    "                # new: always average the heads so the feature‐dim stays dims[i+1]\n",
    "                self.gnn.append(\n",
    "                GATv2Conv(dims[i], dims[i+1],\n",
    "                            heads=heads, concat=False,\n",
    "                            dropout=attention_dropout))\n",
    "            self.dropout = nn.Dropout(p=dropout_emb)\n",
    "            # # bilinear weight matrix A per affinity\n",
    "            # std = 1.0 / math.sqrt(out_dim)\n",
    "            # self.A = nn.Parameter(torch.randn(out_dim, out_dim) * std)\n",
    "            # self.temperature = temperature\n",
    "            # InstanceNorm per-sample\n",
    "            self.inst_norm = nn.InstanceNorm2d(1, affine=True)\n",
    "            self.sinkhorn_max_iter = sinkhorn_max_iter\n",
    "            self.sinkhorn_tau = sinkhorn_tau\n",
    "\n",
    "        def encode(self, x, edge_index):\n",
    "            for i, conv in enumerate(self.gnn):\n",
    "                x = conv(x, edge_index)\n",
    "                if i < len(self.gnn) - 1:\n",
    "                    x = F.relu(x)\n",
    "                    x = self.dropout(x)\n",
    "            return x\n",
    "\n",
    "        def forward(self, batch1, batch2, perm_list, batch_idx1=None, batch_idx2=None, inference=False):\n",
    "            device = next(self.parameters()).device\n",
    "            x1, edge1 = batch1.x.to(device), batch1.edge_index.to(device)\n",
    "            x2, edge2 = batch2.x.to(device), batch2.edge_index.to(device)\n",
    "            perm_list = [p.to(device) for p in perm_list]\n",
    "\n",
    "            batch_idx1 = batch1.batch.to(device) if batch_idx1 is None else batch_idx1.to(device)\n",
    "            batch_idx2 = batch2.batch.to(device) if batch_idx2 is None else batch_idx2.to(device)\n",
    "\n",
    "            h1 = self.encode(x1, edge1)\n",
    "            h2 = self.encode(x2, edge2)\n",
    "\n",
    "            B = batch_idx1.max().item() + 1\n",
    "            loss = 0.0\n",
    "            for b in range(B):\n",
    "                h1_b = h1[batch_idx1 == b]\n",
    "                h2_b = h2[batch_idx2 == b]\n",
    "\n",
    "                # affinity matrix + normalization + sinkhorn\n",
    "                sim = torch.matmul(h1_b, h2_b.T) # [n1, n2]\n",
    "                sim_batched = sim.unsqueeze(0).unsqueeze(1) # [1,1,n1,n2]\n",
    "                sim_normed = self.inst_norm(sim_batched).squeeze(1) # [1,n1,n2] -> [n1,n2]\n",
    "\n",
    "                n1 = torch.tensor([h1_b.size(0)], dtype=torch.int32, device=device)\n",
    "                n2 = torch.tensor([h2_b.size(0)], dtype=torch.int32, device=device)\n",
    "                S = pygmtools.sinkhorn(sim_normed, n1=n1, n2=n2, max_iter=self.sinkhorn_max_iter, tau=self.sinkhorn_tau)\n",
    "\n",
    "                ks_gt = torch.tensor([h2_b.size(0)], dtype=torch.long, device=device)\n",
    "\n",
    "                _, soft_S = soft_topk(S, ks_gt, max_iter=self.sinkhorn_max_iter,\n",
    "                                    tau=self.sinkhorn_tau, nrows=n1, ncols=n2,\n",
    "                                    return_prob=True)\n",
    "\n",
    "                loss += bce_permutation_loss(soft_S[0], perm_list[b])\n",
    "            return loss / B\n",
    "\n",
    "    model = MatchingModel_GATv2SinkhornTopK_OPT(\n",
    "        in_dim=train_dataset[0][0].x.size(1),\n",
    "        hidden_dim=hidden_dim,\n",
    "        out_dim=out_dim,\n",
    "        sinkhorn_max_iter=max_iter,\n",
    "        sinkhorn_tau=tau,\n",
    "        attention_dropout=attn_dropout,\n",
    "        dropout_emb=dropout_emb,\n",
    "        num_layers=num_layers,\n",
    "        heads=heads\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    best_val = float('inf')\n",
    "    counter = 0\n",
    "    for epoch in range(30):\n",
    "        model.train()\n",
    "        for b1, b2, perm in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = model(b1, b2, perm)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for b1, b2, perm in val_loader:\n",
    "                val_loss += model(b1, b2, perm).item()\n",
    "        val_loss /= len(val_loader)\n",
    "        trial.report(val_loss, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "        if val_loss < best_val:\n",
    "            best_val = val_loss\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= 5:\n",
    "                break\n",
    "\n",
    "    # save best trial info\n",
    "    if trial.number == 0 or best_val <= trial.study.best_value:\n",
    "        result = {\n",
    "            \"val_loss\": best_val,\n",
    "            \"params\": trial.params\n",
    "        }\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        with open(os.path.join(path, \"best_trial_results.json\"), \"w\") as f:\n",
    "            json.dump(result, f, indent=2)\n",
    "\n",
    "    return best_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------\n",
    "#            XAI UTILS\n",
    "#----------------------------------------\n",
    "def plt2arr(fig):\n",
    "    \"\"\"\n",
    "    Converts a matplotlib figure to a NumPy RGB array.\n",
    "    Ensures the canvas is drawn before reading pixel data.\n",
    "    \"\"\"\n",
    "    # Attach a canvas if not already present\n",
    "    if fig.canvas is None or not isinstance(fig.canvas, FigureCanvas):\n",
    "        FigureCanvas(fig)\n",
    "\n",
    "    # Force the figure to render\n",
    "    fig.canvas.draw()\n",
    "\n",
    "    # Get the image from the buffer\n",
    "    buf = fig.canvas.buffer_rgba()\n",
    "    img = np.asarray(buf)\n",
    "\n",
    "    # Remove the alpha channel (RGBA -> RGB)\n",
    "    img_rgb = img[..., :3].copy()\n",
    "\n",
    "    return img_rgb\n",
    "\n",
    "def get_node_type_labels(h):\n",
    "    if h.shape[1] < 2:\n",
    "        raise ValueError(\"The embedding must have at least two dimensions to distinguish types.\")\n",
    "    return torch.argmax(h[:, :2], dim=1)  # 0 = room, 1 = ws\n",
    "\n",
    "def visualize(h, node_type_labels, graph_labels, epoch, node_type_filter: Optional[Literal[\"room\", \"ws\", \"all\"]] = \"all\"):\n",
    "    fig, ax = plt.subplots(figsize=(10, 10), frameon=False)\n",
    "    fig.suptitle(f'Epoch index = {epoch}')\n",
    "    z = TSNE(2, random_state=42, init='pca').fit_transform(h.cpu().numpy())\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "\n",
    "    appearance = {\n",
    "        (0, 0): ('tab:blue', 'o'),    # G1 - room\n",
    "        (0, 1): ('tab:green', 's'),   # G1 - ws\n",
    "        (1, 0): ('tab:orange', '^'),  # G2 - room\n",
    "        (1, 1): ('tab:red', 'D'),     # G2 - ws\n",
    "    }\n",
    "\n",
    "    for g in [0, 1]:\n",
    "        for t in [0, 1]:\n",
    "            if node_type_filter == \"room\" and t != 0:\n",
    "                continue\n",
    "            if node_type_filter == \"ws\" and t != 1:\n",
    "                continue\n",
    "            mask = ((graph_labels == g) & (node_type_labels == t)).cpu().numpy()\n",
    "            if np.any(mask):\n",
    "                z_sub = z[mask]\n",
    "                color, marker = appearance[(g, t)]\n",
    "                label = f\"{'G1' if g==0 else 'G2'} - {'room' if t==0 else 'ws'}\"\n",
    "                ax.scatter(z_sub[:, 0], z_sub[:, 1],\n",
    "                           s=50, c=color, marker=marker,\n",
    "                           edgecolors='k', linewidths=0.5,\n",
    "                           alpha=0.4, label=label)\n",
    "\n",
    "    ax.legend(loc='best', frameon=True)\n",
    "    fig.canvas.draw()\n",
    "    arr = plt2arr(fig)\n",
    "    plt.close(fig)\n",
    "    return arr\n",
    "\n",
    "def create_embedding_gif_stride(history, output_path, embedding_type, pair=0, fps=1, step=5, node_type_filter: Optional[Literal[\"room\", \"ws\", \"all\"]] = \"all\"):\n",
    "    plt.close('all')\n",
    "    images = []\n",
    "\n",
    "    for epoch in range(0, len(history), step):\n",
    "        h1, h2 = history[epoch][pair]\n",
    "        h = torch.cat([h1, h2], dim=0)\n",
    "\n",
    "        node_types = embedding_type\n",
    "        graph_labels = torch.cat([\n",
    "            torch.zeros(h1.size(0), dtype=torch.long),\n",
    "            torch.ones(h2.size(0), dtype=torch.long)\n",
    "        ], dim=0)\n",
    "\n",
    "        graph_labels = graph_labels.to(device)\n",
    "        node_types = node_types.to(device)\n",
    "        \n",
    "        images.append(visualize(h, node_types, graph_labels, epoch, node_type_filter=node_type_filter))\n",
    "\n",
    "    clip = ImageSequenceClip(images, fps=fps)\n",
    "    clip.write_gif(output_path, fps=fps)\n",
    "    print(f\"GIF saved at: {output_path}\")\n",
    "\n",
    "def visualize_initial_embeddings(h1, h2, output_path, node_type_filter: Optional[Literal[\"room\", \"ws\", \"all\"]] = \"all\"):\n",
    "    h = torch.cat([h1, h2], dim=0)\n",
    "    node_types = get_node_type_labels(h)\n",
    "    graph_labels = torch.cat([\n",
    "        torch.zeros(h1.size(0), dtype=torch.long),\n",
    "        torch.ones(h2.size(0), dtype=torch.long)\n",
    "    ], dim=0)\n",
    "\n",
    "    graph_labels = graph_labels.to(device)\n",
    "    node_types = node_types.to(device)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 10), frameon=False)\n",
    "    z = TSNE(2, random_state=42, init='pca').fit_transform(h.cpu().numpy())\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "\n",
    "    appearance = {\n",
    "        (0, 0): ('tab:blue', 'o'),\n",
    "        (0, 1): ('tab:green', 's'),\n",
    "        (1, 0): ('tab:orange', '^'),\n",
    "        (1, 1): ('tab:red', 'D'),\n",
    "    }\n",
    "\n",
    "    for g in [0, 1]:\n",
    "        for t in [0, 1]:\n",
    "            if node_type_filter == \"room\" and t != 0:\n",
    "                continue\n",
    "            if node_type_filter == \"ws\" and t != 1:\n",
    "                continue\n",
    "            mask = ((graph_labels == g) & (node_types == t)).cpu().numpy()\n",
    "            if np.any(mask):\n",
    "                z_sub = z[mask]\n",
    "                color, marker = appearance[(g, t)]\n",
    "                label = f\"{'G1' if g==0 else 'G2'} - {'room' if t==0 else 'ws'}\"\n",
    "                ax.scatter(z_sub[:, 0], z_sub[:, 1],\n",
    "                           s=50, c=color, marker=marker,\n",
    "                           edgecolors='k', linewidths=0.5,\n",
    "                           alpha=0.4, label=label)\n",
    "\n",
    "    ax.legend(loc='best', frameon=True)\n",
    "    plt.savefig(output_path, bbox_inches='tight', dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "    return node_types\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: generates a DiGraph with nodes A0…A4, random attributes, and p_edge as edge probability\n",
    "def make_random_graph(name, n_nodes=5, p_edge=0.4):\n",
    "    G = nx.DiGraph(name=name)\n",
    "    for i in range(n_nodes):\n",
    "        nid = f'N{i}'\n",
    "        # random type, center uniformly in [0,10], normal random unit vector, random length\n",
    "        t = random.choice(['room','ws'])\n",
    "        center = [random.uniform(0,10), random.uniform(0,10)]\n",
    "        v = torch.randn(2).tolist()\n",
    "        norm = [v[0]/(abs(v[0])+abs(v[1])+1e-6), v[1]/(abs(v[0])+abs(v[1])+1e-6)]\n",
    "        length = random.uniform(1,5)\n",
    "        G.add_node(nid, type=t, center=center, normal=norm, length=length)\n",
    "    # adds edges with probability p_edge\n",
    "    for u in G.nodes():\n",
    "        for v in G.nodes():\n",
    "            if u!=v and random.random() < p_edge:\n",
    "                G.add_edge(u, v, weight=random.uniform(0.1,1.0))\n",
    "    return G\n",
    "\n",
    "# 1) Generate 6 graphs\n",
    "graphs = [make_random_graph(f'G{i}') for i in range(6)]\n",
    "print(\"Total graphs generated:\", len(graphs))\n",
    "\n",
    "# 3) Test full matching (g0 vs g0 itself)\n",
    "pairs_full = []\n",
    "generate_matching_pair_as_data(graphs[0], graphs[0], pairs_full)\n",
    "\n",
    "# # 3.1) Split 70/15/15 \n",
    "# train, val, test = split_graphs_stratified(pairs_full, train_frac=0.6, val_frac=0.2, test_frac=0.2)\n",
    "# print(\"Split sizes → train:\", len(train), \"val:\", len(val), \"test:\", len(test))\n",
    "# assert len(train)==4 and len(val)==1 and len(test)==1, \"Split not conforming\"\n",
    "\n",
    "pyg1_f, pyg2_f, P_full = pairs_full[0]\n",
    "n = len(graphs[0].nodes())\n",
    "print(\"Full match shape:\", P_full.shape)\n",
    "assert P_full.shape == (n, n)\n",
    "assert torch.allclose(P_full.sum(dim=0), torch.ones(n))\n",
    "assert torch.allclose(P_full.sum(dim=1), torch.ones(n))\n",
    "print(\"Full matching OK\")\n",
    "\n",
    "# 4) Test partial matching (remove 2 nodes from G1)\n",
    "g_partial = graphs[1].copy()\n",
    "to_remove = random.sample(list(g_partial.nodes()), 2)\n",
    "for u in to_remove:\n",
    "    g_partial.remove_node(u)\n",
    "pairs_part = []\n",
    "generate_matching_pair_as_data(graphs[1], g_partial, pairs_part)\n",
    "pyg1_p, pyg2_p, P_part = pairs_part[0]\n",
    "print(\"Partial match shape:\", P_part.shape, \n",
    "      f\"(original {len(graphs[1].nodes())} vs partial {len(g_partial.nodes())})\")\n",
    "# each column max 1, each row max 1\n",
    "assert (P_part.sum(dim=0) <= 1).all()\n",
    "assert (P_part.sum(dim=1) <= 1).all()\n",
    "print(\"Partial matching OK\\n\", P_part)\n",
    "\n",
    "# 5) Test round-trip Data→NX on one of the matches\n",
    "recon = pyg_data_to_nx_digraph(pyg2_p, [graphs[1], g_partial])\n",
    "assert set(recon.nodes()) == set(g_partial.nodes())\n",
    "print(\"Round-trip PyG→NX OK\")\n",
    "\n",
    "# plot_two_graphs_with_matching(\n",
    "#     graphs_list=[pyg1_p, pyg2_p],\n",
    "#     gt_perm=P_part,\n",
    "#     original_graphs=[graphs[1]],\n",
    "#     noise_graphs=[g_partial],\n",
    "#     pred_perm=P_part,\n",
    "#     match_display=\"all\"\n",
    "# )\n",
    "\n",
    "print(\"All advanced tests passed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4RCatL5UdsZV",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Dataset Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folder Creation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MBpjTdWOdsZV"
   },
   "outputs": [],
   "source": [
    "# Construct the folders if they don't exist\n",
    "# GNN_PATH\n",
    "# ├── models\n",
    "# │   ├── graph matching\n",
    "# │   │   ├── equal\n",
    "# │   │   ├── global\n",
    "# │   │   ├── global_local\n",
    "# │   │   └── local\n",
    "# │   └── partial graph matching\n",
    "# │       ├── room_dropout_equal\n",
    "# │       ├── ws_dropout_equal\n",
    "# │       ├── room_dropout_noise\n",
    "# │       └── ws_dropout_noise\n",
    "# ├── preprocessed\n",
    "# │   ├── graph matching\n",
    "# │   │   ├── equal\n",
    "# │   │   ├── global\n",
    "# │   │   ├── global_local\n",
    "# │   │   └── local\n",
    "# │   └── partial graph matching\n",
    "# │       ├── room_dropout_equal\n",
    "# │       ├── ws_dropout_equal\n",
    "# │       ├── room_dropout_noise\n",
    "# │       └── ws_dropout_noise\n",
    "# └── raw\n",
    "#     ├── graph matching\n",
    "#     │   ├── equal\n",
    "#     │   ├── global\n",
    "#     │   ├── global_local\n",
    "#     │   └── local\n",
    "#     └── partial graph matching\n",
    "#         ├── room_dropout_equal\n",
    "#         ├── ws_dropout_equal\n",
    "#         ├── room_dropout_noise\n",
    "#         └── ws_dropout_noise\n",
    "\n",
    "def create_dir_structure(base_dir=\"GNN\"):\n",
    "    categories = [\n",
    "        \"graph_matching/equal\",\n",
    "        \"graph_matching/global\",\n",
    "        \"graph_matching/global_local\",\n",
    "        \"graph_matching/local\",\n",
    "        \"partial_graph_matching/room_dropout_equal\",\n",
    "        \"partial_graph_matching/ws_dropout_equal\",\n",
    "        \"partial_graph_matching/room_dropout_noise\",\n",
    "        \"partial_graph_matching/ws_dropout_noise\",\n",
    "    ]\n",
    "\n",
    "    levels = [\"models\", \"preprocessed\", \"raw\"]\n",
    "\n",
    "    for level in levels:\n",
    "        for category in categories:\n",
    "            path = os.path.join(base_dir, level, category)\n",
    "            os.makedirs(path, exist_ok=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_dir_structure(GNN_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Matching dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0wL_59NMdsZW"
   },
   "source": [
    "### GM Equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-voxq-c7dsZW"
   },
   "outputs": [],
   "source": [
    "# graph matching-equal path\n",
    "gm_path = os.path.join(GNN_PATH, \"raw\", \"graph_matching\")\n",
    "original_graphs, _, _ = deserialize_MSD_dataset(data_path=gm_path, original_path=\"equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C067q1ZRdsZW",
    "outputId": "92173103-00e3-4ee5-f638-3e74bb3e0647"
   },
   "outputs": [],
   "source": [
    "# Check the number of graphs\n",
    "print(f\"Number of original graphs: {len(original_graphs)}\")\n",
    "print(original_graphs[0])\n",
    "print(original_graphs[0].nodes(data=True))\n",
    "print(original_graphs[0].edges(data=True))\n",
    "plot_a_graph([original_graphs[0]], path=os.path.join(gm_path, \"equal\", \"apartment.png\"), viz_rooms=True, viz_ws=True, viz_openings=False, viz_room_connection=True, viz_normals=False, viz_room_normals=True, viz_walls=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "txNnbzQNdsZX"
   },
   "source": [
    "#### Generate G1,G2,GT dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bC9jsHBVdsZX",
    "outputId": "d756beb8-946c-47e6-c331-3172b5858fad"
   },
   "outputs": [],
   "source": [
    "pair_gt_list = []\n",
    "for i, g1 in enumerate(original_graphs):\n",
    "    generate_matching_pair_as_data(g1, g1, pair_gt_list)\n",
    "\n",
    "train, val, test = split_graphs_stratified(pair_gt_list)\n",
    "\n",
    "describe(train, \"TRAIN\")\n",
    "describe(val,   \"VAL\")\n",
    "describe(test,  \"TEST\")\n",
    "\n",
    "# compute mean and std\n",
    "mean, std = compute_mean_std(train)\n",
    "\n",
    "# Normalizzazione dei set\n",
    "train_pairs_norm = normalize_data_pairs(train, mean, std)\n",
    "val_pairs_norm = normalize_data_pairs(val, mean, std)\n",
    "test_pairs_norm = normalize_data_pairs(test, mean, std)\n",
    "\n",
    "gm_equal_preprocessed_path = os.path.join(GNN_PATH, \"preprocessed\", \"graph_matching\", \"equal\")\n",
    "serialize_graph_matching_dataset(\n",
    "    train_pairs_norm,\n",
    "    gm_equal_preprocessed_path,\n",
    "    \"train_dataset.pkl\"\n",
    ")\n",
    "serialize_graph_matching_dataset(\n",
    "    val_pairs_norm,\n",
    "    gm_equal_preprocessed_path,\n",
    "    \"valid_dataset.pkl\"\n",
    ")\n",
    "serialize_graph_matching_dataset(\n",
    "    test_pairs_norm,\n",
    "    gm_equal_preprocessed_path,\n",
    "    \"test_dataset.pkl\"\n",
    ")\n",
    "serialize_graph_matching_dataset(\n",
    "    original_graphs,\n",
    "    gm_equal_preprocessed_path,\n",
    "    \"original.pkl\"\n",
    ")\n",
    "\n",
    "# Visualize the two graphs\n",
    "g1_out, g2_perm, gt_perm = train[0]\n",
    "\n",
    "print(g1_out)\n",
    "print(\"G1 nodes:\", g1_out.x[0])\n",
    "print(g2_perm)\n",
    "print(\"G2 permuted nodes:\", g2_perm.x[0])\n",
    "print(\"Ground truth permutation:\\n\", gt_perm[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the two graphs\n",
    "plot_two_graphs_with_matching(\n",
    "    [g1_out, g2_perm],\n",
    "    gt_perm=gt_perm,\n",
    "    pred_perm=gt_perm,\n",
    "    original_graphs=original_graphs,\n",
    "    viz_rooms=True,\n",
    "    viz_ws=True,\n",
    "    match_display=\"all\",\n",
    "    path=os.path.join(gm_equal_preprocessed_path, \"gt.png\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xDBrICr9dsZY"
   },
   "source": [
    "### GM Local Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qr73ZwdNdsZZ"
   },
   "outputs": [],
   "source": [
    "# graph matching path\n",
    "gm_path = os.path.join(GNN_PATH, \"raw\", \"graph_matching\")\n",
    "noise_graphs, _, _ = deserialize_MSD_dataset(data_path=gm_path, original_path=\"local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J5Hv04_zdsZZ",
    "outputId": "ce138f8f-c426-4fb0-94ca-e60d1f91ef06"
   },
   "outputs": [],
   "source": [
    "# Check the number of graphs\n",
    "print(f\"Number of original graphs: {len(noise_graphs)}\")\n",
    "print(noise_graphs[0])\n",
    "print(noise_graphs[0].nodes(data=True))\n",
    "print(noise_graphs[0].edges(data=True))\n",
    "plot_a_graph([noise_graphs[0]], path=os.path.join(gm_path, \"local\", \"apartment.png\"), viz_rooms=True, viz_ws=True, viz_openings=False, viz_room_connection=True, viz_normals=False, viz_room_normals=True, viz_walls=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FxYqO6uWdsZa"
   },
   "source": [
    "#### Generate G1,G2,GT dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A8cG0CBKdsZa",
    "outputId": "7dbd9168-507f-4684-fa4e-000a1617a6d2"
   },
   "outputs": [],
   "source": [
    "pair_gt_list = []\n",
    "for i, g1 in enumerate(original_graphs):\n",
    "    generate_matching_pair_as_data(g1, noise_graphs[i], pair_gt_list)\n",
    "\n",
    "train, val, test = split_graphs_stratified(pair_gt_list)\n",
    "\n",
    "describe(train, \"TRAIN\")\n",
    "describe(val,   \"VAL\")\n",
    "describe(test,  \"TEST\")\n",
    "\n",
    "# compute mean and std\n",
    "mean, std = compute_mean_std(train)\n",
    "\n",
    "# Normalizzazione dei set\n",
    "train_pairs_norm = normalize_data_pairs(train, mean, std)\n",
    "val_pairs_norm = normalize_data_pairs(val, mean, std)\n",
    "test_pairs_norm = normalize_data_pairs(test, mean, std)\n",
    "\n",
    "gm_equal_preprocessed_path = os.path.join(GNN_PATH, \"preprocessed\", \"graph_matching\", \"local\")\n",
    "serialize_graph_matching_dataset(\n",
    "    train_pairs_norm,\n",
    "    gm_equal_preprocessed_path,\n",
    "    \"train_dataset.pkl\"\n",
    ")\n",
    "serialize_graph_matching_dataset(\n",
    "    val_pairs_norm,\n",
    "    gm_equal_preprocessed_path,\n",
    "    \"valid_dataset.pkl\"\n",
    ")\n",
    "serialize_graph_matching_dataset(\n",
    "    test_pairs_norm,\n",
    "    gm_equal_preprocessed_path,\n",
    "    \"test_dataset.pkl\"\n",
    ")\n",
    "serialize_graph_matching_dataset(\n",
    "    noise_graphs,\n",
    "    gm_equal_preprocessed_path,\n",
    "    \"noise.pkl\"\n",
    ")\n",
    "\n",
    "# Visualize the two graphs\n",
    "g1_out, g2_perm, gt_perm = train[0]\n",
    "\n",
    "print(g1_out)\n",
    "print(\"G1 nodes:\", g1_out.x[0])\n",
    "print(g2_perm)\n",
    "print(\"G2 permuted nodes:\", g2_perm.x[0])\n",
    "print(\"Ground truth permutation:\\n\", gt_perm[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the two graphs\n",
    "plot_two_graphs_with_matching(\n",
    "    [g1_out, g2_perm],\n",
    "    gt_perm=gt_perm,\n",
    "    pred_perm=gt_perm,\n",
    "    original_graphs=original_graphs,\n",
    "    noise_graphs=noise_graphs,\n",
    "    viz_rooms=True,\n",
    "    viz_ws=True,\n",
    "    match_display=\"all\",\n",
    "    path=os.path.join(gm_equal_preprocessed_path, \"gt.png\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cm2RdRK5dsZa"
   },
   "source": [
    "### GM Global Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KvDynD3edsZb"
   },
   "outputs": [],
   "source": [
    "# graph matching path\n",
    "gm_path = os.path.join(GNN_PATH, \"raw\", \"graph_matching\")\n",
    "noise_graphs, _, _ = deserialize_MSD_dataset(data_path=gm_path, original_path=\"global\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HWpxuPk0dsZc",
    "outputId": "e7a56a77-c751-40b6-c0b5-767f62f5fdb4"
   },
   "outputs": [],
   "source": [
    "# Check the number of graphs\n",
    "print(f\"Number of original graphs: {len(noise_graphs)}\")\n",
    "print(noise_graphs[0])\n",
    "print(noise_graphs[0].nodes(data=True))\n",
    "print(noise_graphs[0].edges(data=True))\n",
    "plot_a_graph([noise_graphs[0]], path=os.path.join(gm_path, \"global\", \"apartment.png\"), viz_rooms=True, viz_ws=True, viz_openings=False, viz_room_connection=True, viz_normals=False, viz_room_normals=True, viz_walls=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HT7-XrN8dsZc"
   },
   "source": [
    "#### Generate G1,G2,GT dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gjXVVYCEdsZd",
    "outputId": "fab19d62-fadc-4f66-a3d8-2a6ad37a0743"
   },
   "outputs": [],
   "source": [
    "pair_gt_list = []\n",
    "for i, g1 in enumerate(original_graphs):\n",
    "    generate_matching_pair_as_data(g1, noise_graphs[i], pair_gt_list)\n",
    "\n",
    "train, val, test = split_graphs_stratified(pair_gt_list)\n",
    "\n",
    "describe(train, \"TRAIN\")\n",
    "describe(val,   \"VAL\")\n",
    "describe(test,  \"TEST\")\n",
    "\n",
    "# compute mean and std\n",
    "mean, std = compute_mean_std(train)\n",
    "\n",
    "# Normalizzazione dei set\n",
    "train_pairs_norm = normalize_data_pairs(train, mean, std)\n",
    "val_pairs_norm = normalize_data_pairs(val, mean, std)\n",
    "test_pairs_norm = normalize_data_pairs(test, mean, std)\n",
    "\n",
    "gm_equal_preprocessed_path = os.path.join(GNN_PATH, \"preprocessed\", \"graph_matching\", \"global\")\n",
    "serialize_graph_matching_dataset(\n",
    "    train_pairs_norm,\n",
    "    gm_equal_preprocessed_path,\n",
    "    \"train_dataset.pkl\"\n",
    ")\n",
    "serialize_graph_matching_dataset(\n",
    "    val_pairs_norm,\n",
    "    gm_equal_preprocessed_path,\n",
    "    \"valid_dataset.pkl\"\n",
    ")\n",
    "serialize_graph_matching_dataset(\n",
    "    test_pairs_norm,\n",
    "    gm_equal_preprocessed_path,\n",
    "    \"test_dataset.pkl\"\n",
    ")\n",
    "serialize_graph_matching_dataset(\n",
    "    noise_graphs,\n",
    "    gm_equal_preprocessed_path,\n",
    "    \"noise.pkl\"\n",
    ")\n",
    "\n",
    "# Visualize the two graphs\n",
    "g1_out, g2_perm, gt_perm = train[0]\n",
    "\n",
    "print(g1_out)\n",
    "print(\"G1 nodes:\", g1_out.x[0])\n",
    "print(g2_perm)\n",
    "print(\"G2 permuted nodes:\", g2_perm.x[0])\n",
    "print(\"Ground truth permutation:\\n\", gt_perm[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the two graphs\n",
    "plot_two_graphs_with_matching(\n",
    "    [g1_out, g2_perm],\n",
    "    gt_perm=gt_perm,\n",
    "    pred_perm=gt_perm,\n",
    "    original_graphs=original_graphs,\n",
    "    noise_graphs=noise_graphs,\n",
    "    viz_rooms=True,\n",
    "    viz_ws=True,\n",
    "    match_display=\"all\",\n",
    "    path=os.path.join(gm_equal_preprocessed_path, \"gt.png\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ih7g4VddsZd"
   },
   "source": [
    "### GM Global + Local Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MzwL4zxTdsZe"
   },
   "outputs": [],
   "source": [
    "# graph matching path\n",
    "gm_path = os.path.join(GNN_PATH, \"raw\", \"graph_matching\")\n",
    "noise_graphs, _, _ = deserialize_MSD_dataset(data_path=gm_path, original_path=\"global_local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PTgPcgp_dsZe",
    "outputId": "2e17bd08-bd78-44c8-f8cc-c089ce81db11"
   },
   "outputs": [],
   "source": [
    "# Check the number of graphs\n",
    "print(f\"Number of original graphs: {len(noise_graphs)}\")\n",
    "print(noise_graphs[0])\n",
    "print(noise_graphs[0].nodes(data=True))\n",
    "print(noise_graphs[0].edges(data=True))\n",
    "plot_a_graph([noise_graphs[0]], path=os.path.join(gm_path, \"global_local\", \"apartment.png\"), viz_rooms=True, viz_ws=True, viz_openings=False, viz_room_connection=True, viz_normals=False, viz_room_normals=True, viz_walls=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CKHJVylIdsZf"
   },
   "source": [
    "#### Generate G1,G2,GT dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4oLVa11idsZf",
    "outputId": "6a9a1c49-3134-47b4-9964-6d3ee43c34e3"
   },
   "outputs": [],
   "source": [
    "pair_gt_list = []\n",
    "for i, g1 in enumerate(original_graphs):\n",
    "    generate_matching_pair_as_data(g1, noise_graphs[i], pair_gt_list)\n",
    "\n",
    "train, val, test = split_graphs_stratified(pair_gt_list)\n",
    "\n",
    "describe(train, \"TRAIN\")\n",
    "describe(val,   \"VAL\")\n",
    "describe(test,  \"TEST\")\n",
    "\n",
    "# compute mean and std\n",
    "mean, std = compute_mean_std(train)\n",
    "\n",
    "# Normalizzazione dei set\n",
    "train_pairs_norm = normalize_data_pairs(train, mean, std)\n",
    "val_pairs_norm = normalize_data_pairs(val, mean, std)\n",
    "test_pairs_norm = normalize_data_pairs(test, mean, std)\n",
    "\n",
    "gm_equal_preprocessed_path = os.path.join(GNN_PATH, \"preprocessed\", \"graph_matching\", \"global_local\")\n",
    "serialize_graph_matching_dataset(\n",
    "    train_pairs_norm,\n",
    "    gm_equal_preprocessed_path,\n",
    "    \"train_dataset.pkl\"\n",
    ")\n",
    "serialize_graph_matching_dataset(\n",
    "    val_pairs_norm,\n",
    "    gm_equal_preprocessed_path,\n",
    "    \"valid_dataset.pkl\"\n",
    ")\n",
    "serialize_graph_matching_dataset(\n",
    "    test_pairs_norm,\n",
    "    gm_equal_preprocessed_path,\n",
    "    \"test_dataset.pkl\"\n",
    ")\n",
    "serialize_graph_matching_dataset(\n",
    "    noise_graphs,\n",
    "    gm_equal_preprocessed_path,\n",
    "    \"noise.pkl\"\n",
    ")\n",
    "\n",
    "# Visualize the two graphs\n",
    "g1_out, g2_perm, gt_perm = train[0]\n",
    "\n",
    "print(g1_out)\n",
    "print(\"G1 nodes:\", g1_out.x[0])\n",
    "print(g2_perm)\n",
    "print(\"G2 permuted nodes:\", g2_perm.x[0])\n",
    "print(\"Ground truth permutation:\\n\", gt_perm[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the two graphs\n",
    "plot_two_graphs_with_matching(\n",
    "    [g1_out, g2_perm],\n",
    "    gt_perm=gt_perm,\n",
    "    pred_perm=gt_perm,\n",
    "    original_graphs=original_graphs,\n",
    "    noise_graphs=noise_graphs,\n",
    "    viz_rooms=True,\n",
    "    viz_ws=True,\n",
    "    match_display=\"all\",\n",
    "    path=os.path.join(gm_equal_preprocessed_path, \"gt.png\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial Graph Matching dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WS dropout equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph matching-equal path\n",
    "gm_path = os.path.join(GNN_PATH, \"raw\", \"graph_matching\")\n",
    "original_graphs, _, _ = deserialize_MSD_dataset(data_path=gm_path, original_path=\"equal\")\n",
    "# graph matching path\n",
    "gm_path = os.path.join(GNN_PATH, \"raw\", \"partial_graph_matching\")\n",
    "noise_graphs, _, _ = deserialize_MSD_dataset(data_path=gm_path, original_path=\"ws_dropout_equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of graphs\n",
    "print(f\"Number of original graphs: {len(noise_graphs)}\")\n",
    "print(noise_graphs[0])\n",
    "print(noise_graphs[0].nodes(data=True))\n",
    "print(noise_graphs[0].edges(data=True))\n",
    "plot_a_graph([noise_graphs[0]],path=os.path.join(gm_path, \"ws_dropout_equal\", \"apartment.png\"), viz_rooms=True, viz_ws=True, viz_openings=False, viz_room_connection=True, viz_normals=False, viz_room_normals=True, viz_walls=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate G1,G2,GT dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_gt_list = []\n",
    "for i, g1 in enumerate(original_graphs):\n",
    "    generate_matching_pair_as_data(g1, noise_graphs[i], pair_gt_list)\n",
    "\n",
    "train, val, test = split_graphs_stratified(pair_gt_list)\n",
    "\n",
    "describe(train, \"TRAIN\")\n",
    "describe(val,   \"VAL\")\n",
    "describe(test,  \"TEST\")\n",
    "\n",
    "# compute mean and std\n",
    "mean, std = compute_mean_std(train)\n",
    "\n",
    "# Normalizzazione dei set\n",
    "train_pairs_norm = normalize_data_pairs(train, mean, std)\n",
    "val_pairs_norm = normalize_data_pairs(val, mean, std)\n",
    "test_pairs_norm = normalize_data_pairs(test, mean, std)\n",
    "\n",
    "gm_equal_preprocessed_path = os.path.join(GNN_PATH, \"preprocessed\", \"partial_graph_matching\", \"ws_dropout_equal\")\n",
    "serialize_graph_matching_dataset(\n",
    "    train_pairs_norm,\n",
    "    gm_equal_preprocessed_path,\n",
    "    \"train_dataset.pkl\"\n",
    ")\n",
    "serialize_graph_matching_dataset(\n",
    "    val_pairs_norm,\n",
    "    gm_equal_preprocessed_path,\n",
    "    \"valid_dataset.pkl\"\n",
    ")\n",
    "serialize_graph_matching_dataset(\n",
    "    test_pairs_norm,\n",
    "    gm_equal_preprocessed_path,\n",
    "    \"test_dataset.pkl\"\n",
    ")\n",
    "serialize_graph_matching_dataset(\n",
    "    noise_graphs,\n",
    "    gm_equal_preprocessed_path,\n",
    "    \"noise.pkl\"\n",
    ")\n",
    "\n",
    "g1_out, g2_perm, gt_perm = train[0]\n",
    "\n",
    "print(g1_out)\n",
    "print(\"G1 nodes:\", g1_out.x[0])\n",
    "print(g2_perm)\n",
    "print(\"G2 permuted nodes:\", g2_perm.x[0])\n",
    "print(\"Ground truth permutation:\\n\", gt_perm[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the two graphs\n",
    "plot_two_graphs_with_matching(\n",
    "    [g1_out, g2_perm],\n",
    "    gt_perm=gt_perm,\n",
    "    pred_perm=gt_perm,\n",
    "    original_graphs=original_graphs,\n",
    "    noise_graphs=noise_graphs,\n",
    "    viz_rooms=True,\n",
    "    viz_ws=True,\n",
    "    match_display=\"all\",\n",
    "    path=os.path.join(gm_equal_preprocessed_path, \"gt.png\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WS dropout noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 4895 original graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Original graphs: 100%|██████████| 4895/4895 [00:25<00:00, 188.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 4895 original graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Original graphs: 100%|██████████| 4895/4895 [00:25<00:00, 190.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# graph matching-equal path\n",
    "gm_path = os.path.join(GNN_PATH, \"raw\", \"graph_matching\")\n",
    "original_graphs, _, _ = deserialize_MSD_dataset(data_path=gm_path, original_path=\"equal\")\n",
    "# graph matching path\n",
    "gm_path = os.path.join(GNN_PATH, \"raw\", \"partial_graph_matching\")\n",
    "noise_graphs, _, _ = deserialize_MSD_dataset(data_path=gm_path, original_path=\"ws_dropout_noise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of original graphs: 4895\n",
      "DiGraph named '0' with 62 nodes and 108 edges\n",
      "[('1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_centroid', {'polygon': [[-2.633860329934792, 0.7138940757015725], [-3.655978199226547, -0.2977872515891965], [-4.836915407798393, 0.8953325489168038], [-4.945931430179652, 0.7874296567630293], [-5.430087506940867, 1.2765803055241867], [-4.298953615267854, 2.39616452496873], [-2.633860329934792, 0.7138940757015725]], 'center': [-4.012239010171058, 1.0502945976303906], 'normal': [0.0, 0.0], 'type': 'room', 'category': 7, 'category_letter': 'Bathroom', 'viz_data': array([-4.01223901,  1.0502946 ])}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_0', {'geom': [array([-2.68667049,  0.46685368]), array([-3.61108401, -0.63481946])], 'polygon': [[-2.633860329934792, 0.7138940757015725], [-3.655978199226547, -0.2977872515891965], [-3.6550555337194495, -0.2878299081502057], [-2.6329376644276943, 0.7238514191405633], [-2.633860329934792, 0.7138940757015725]], 'center': [-3.1411051492813393, 0.2039246702826312], 'normal': [-0.7032226160924643, 0.7109697266523174], 'type': 'ws', 'category': 9, 'viz_data': array([-3.14110515,  0.20392467]), 'length': 1.438132138127206, 'limits': [[-3.6561520400744705, -0.29760878861371354], [-2.6336836269402584, 0.7137182558467494]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_1', {'geom': [array([-3.61108401, -0.63481946]), array([-4.8970688,  0.4442499])], 'polygon': [[-3.655978199226547, -0.2977872515891965], [-4.836915407798393, 0.8953325489168038], [-4.835992742291295, 0.9052898923557946], [-3.6550555337194495, -0.2878299081502057], [-3.655978199226547, -0.2977872515891965]], 'center': [-4.247232532855056, 0.30194076253762037], 'normal': [0.6986396812076892, 0.7154736863379524], 'type': 'ws', 'category': 9, 'viz_data': array([-4.24723253,  0.30194076]), 'length': 1.678733912491476, 'limits': [[-4.84693792097121, 0.8852015555009137], [-3.6458479802203994, -0.2876285699546677]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_2', {'geom': [array([-4.8970688,  0.4442499]), array([-4.99566397,  0.32674875])], 'polygon': [[-4.836915407798393, 0.8953325489168038], [-4.945931430179652, 0.7874296567630293], [-4.945008764672554, 0.7973870002020201], [-4.835992742291295, 0.9052898923557946], [-4.836915407798393, 0.8953325489168038]], 'center': [-4.888705935935345, 0.8428108747952191], 'normal': [-0.7003146510424825, 0.713834287167019], 'type': 'ws', 'category': 9, 'viz_data': array([-4.88870594,  0.84281087]), 'length': 0.15338685494846127, 'limits': [[-4.946176122151286, 0.7876836202060498], [-4.8366833258883615, 0.8951026820037853]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_3', {'geom': [array([-4.99566397,  0.32674875]), array([-5.52288704,  0.76914144])], 'polygon': [[-4.945931430179652, 0.7874296567630293], [-5.430087506940867, 1.2765803055241867], [-5.42916484143377, 1.2865376489631775], [-4.945008764672554, 0.7973870002020201], [-4.945931430179652, 0.7874296567630293]], 'center': [-5.19059397774774, 1.0353848409059965], 'normal': [0.6981890646284544, 0.7159134235598912], 'type': 'ws', 'category': 9, 'viz_data': array([-5.19059398,  1.03538484]), 'length': 0.6882408472680721, 'limits': [[-5.434310600792744, 1.2723122777496498], [-4.941589739591299, 0.7917900443564596]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_4', {'geom': [array([-5.52288704,  0.76914144]), array([-4.49987835,  1.98831572])], 'polygon': [[-5.430087506940867, 1.2765803055241867], [-4.298953615267854, 2.39616452496873], [-4.298030949760756, 2.406121868407721], [-5.42916484143377, 1.2865376489631775], [-5.430087506940867, 1.2765803055241867]], 'center': [-4.869158447321591, 1.8314075190675472], 'normal': [0.7001531172380805, -0.7139927257485181], 'type': 'ws', 'category': 9, 'viz_data': array([-4.86915845,  1.83140752]), 'length': 1.5915189930756675, 'limits': [[-4.296331009194739, 2.393504265491974], [-5.43266399314137, 1.2791972813464345]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_5', {'geom': [array([-4.49987835,  1.98831572]), array([-2.68667049,  0.46685368])], 'polygon': [[-4.298953615267854, 2.39616452496873], [-2.633860329934792, 0.7138940757015725], [-2.6329376644276943, 0.7238514191405633], [-4.298030949760756, 2.406121868407721], [-4.298953615267854, 2.39616452496873]], 'center': [-3.4623825542889923, 1.5584009970020125], 'normal': [-0.6984465404898305, -0.7156622318369104], 'type': 'ws', 'category': 9, 'viz_data': array([-3.46238255,  1.558401  ]), 'length': 2.366974759759548, 'limits': [[-2.6193708056263505, 0.7283574993526819], [-4.313325244897504, 2.3815628317334854]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_centroid', {'polygon': [[-2.089545559974777, -1.5198164417776683], [0.7804633544087439, -4.419432474302215], [-0.9139199862341069, -6.096514969874584], [-0.9259091964734144, -6.084402078498889], [-1.0591510016060646, -6.216283391131278], [-1.4008434934263452, -5.871065986923958], [-2.2441108959916876, -6.705723036486635], [-1.9443806400089854, -7.008545320879019], [-1.9600777110333203, -7.024082113773052], [-4.7761351793399545, -4.178974092439136], [-2.089545559974777, -1.5198164417776683]], 'center': [-2.0122383608915326, -4.211232421976876], 'normal': [0.0, 0.0], 'type': 'room', 'category': 3, 'category_letter': 'Dining', 'viz_data': array([-2.01223836, -4.21123242])}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_0', {'geom': [array([-1.93858082, -1.70710655]), array([ 1.1867232, -4.329548 ])], 'polygon': [[-2.089545559974777, -1.5198164417776683], [0.7804633544087439, -4.419432474302215], [0.7813860199158413, -4.409475130863225], [-2.0886228944676795, -1.5098590983386775], [-2.089545559974777, -1.5198164417776683]], 'center': [-0.6509293208298768, -2.97014843919451], 'normal': [-0.7296522662021493, -0.6838183753205729], 'type': 'ws', 'category': 9, 'viz_data': array([-0.65092932, -2.97014844]), 'length': 4.079794640017346, 'limits': [[0.7403938069537981, -4.457941825131918], [-2.049444735424445, -1.48111042040388]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_2', {'geom': [array([-0.34569387, -6.15581154]), array([-0.35874955, -6.14485652])], 'polygon': [[-0.9139199862341069, -6.096514969874584], [-0.9259091964734144, -6.084402078498889], [-0.9249865309663171, -6.074444735059899], [-0.9129973207270095, -6.086557626435594], [-0.9139199862341069, -6.096514969874584]], 'center': [-0.9184878903857677, -6.092956530143434], 'normal': [0.690547836787666, 0.7232867239953151], 'type': 'ws', 'category': 9, 'viz_data': array([-0.91848789, -6.09295653]), 'length': 0.017042983883161743, 'limits': [[-0.926148145571747, -6.084615372102066], [-0.91382118159179, -6.096384367754991]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_3', {'geom': [array([-0.35874955, -6.14485652]), array([-0.47925476, -6.28846904])], 'polygon': [[-0.9259091964734144, -6.084402078498889], [-1.0591510016060646, -6.216283391131278], [-1.058228336098967, -6.206326047692287], [-0.9249865309663171, -6.074444735059899], [-0.9259091964734144, -6.084402078498889]], 'center': [-0.9918430456120085, -6.1551280354573725], 'normal': [-0.679053311024681, 0.7340889597224699], 'type': 'ws', 'category': 9, 'viz_data': array([-0.99184305, -6.15512804]), 'length': 0.18747282271478447, 'limits': [[-1.0611788858413407, -6.213974273462808], [-0.9235571564384093, -6.08667023247119]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_4', {'geom': [array([-0.47925476, -6.28846904]), array([-0.85134173, -5.976251  ])], 'polygon': [[-1.0591510016060646, -6.216283391131278], [-1.4008434934263452, -5.871065986923958], [-1.3999208279192479, -5.861108643484968], [-1.058228336098967, -6.206326047692287], [-1.0591510016060646, -6.216283391131278]], 'center': [-1.2345916052239327, -6.040906545274196], 'normal': [0.6946520786237032, 0.7193458762401914], 'type': 'ws', 'category': 9, 'viz_data': array([-1.23459161, -6.04090655]), 'length': 0.48572504067012284, 'limits': [[-1.4046380357426376, -5.874865233970548], [-1.0552337307499857, -6.212275143111632]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_8', {'geom': [array([-1.30180563, -7.17594737]), array([-4.36835906, -4.60280351])], 'polygon': [[-1.9600777110333203, -7.024082113773052], [-4.7761351793399545, -4.178974092439136], [-4.775212513832857, -4.169016749000145], [-1.9591550455262228, -7.014124770334062], [-1.9600777110333203, -7.024082113773052]], 'center': [-3.367878689891415, -5.604706734762826], 'normal': [0.6988292410863899, 0.715288537446687], 'type': 'ws', 'category': 9, 'viz_data': array([-3.36787869, -5.60470673]), 'length': 4.003101212543116, 'limits': [[-4.7998459228872905, -4.202790278233639], [-1.9364735113162654, -7.00027446058715]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_9', {'geom': [array([-4.36835906, -4.60280351]), array([-1.93858082, -1.70710655])], 'polygon': [[-4.7761351793399545, -4.178974092439136], [-2.089545559974777, -1.5198164417776683], [-2.0886228944676795, -1.5098590983386775], [-4.775212513832857, -4.169016749000145], [-4.7761351793399545, -4.178974092439136]], 'center': [-3.435899780165284, -2.852542794008236], 'normal': [0.6981754924874749, -0.715926659435079], 'type': 'ws', 'category': 9, 'viz_data': array([-3.43589978, -2.85254279]), 'length': 3.7800639140035894, 'limits': [[-2.079692831754753, -1.5298440644263338], [-4.785941362158433, -4.168992049219923]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_centroid', {'polygon': [[-1.1550604286825588, -0.522934010575174], [-1.1490039829947105, -0.5169394054555192], [-1.3588151621826021, -0.3049638063808476], [-0.5850115660926027, 0.460938711004104], [-0.34522736130644005, 0.21868088349019535], [-0.3391709156185928, 0.2246754886098501], [-0.32718170537928587, 0.2125625972341559], [0.6115673762371089, 1.1417263907805315], [3.475581685500977, -1.7518331960561673], [0.8969572744323591, -4.304128039098026], [-1.9730516399511617, -1.4045120065734786], [-1.119092797964634, -0.5592726847022607], [-1.1550604286825588, -0.522934010575174]], 'center': [0.7115370352660189, -1.5413989049912817], 'normal': [0.0, 0.0], 'type': 'room', 'category': 0, 'category_letter': 'Bedroom', 'viz_data': array([ 0.71153704, -1.5413989 ])}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_0', {'geom': [array([-1.10006078, -0.62825476]), array([-1.09458327, -0.62172692])], 'polygon': [[-1.1550604286825588, -0.522934010575174], [-1.1490039829947105, -0.5169394054555192], [-1.1480813174876132, -0.5069820620165284], [-1.1541377631754612, -0.5129766671361832], [-1.1550604286825588, -0.522934010575174]], 'center': [-1.1527244544690258, -0.5240690708720529], 'normal': [0.7085505408187055, -0.7056600676710566], 'type': 'ws', 'category': 9, 'viz_data': array([-1.15272445, -0.52406907]), 'length': 0.008521491941581858, 'limits': [[-1.1490552363859958, -0.5169128934286076], [-1.1550685129661509, -0.5229508011523977]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_1', {'geom': [array([-1.09458327, -0.62172692]), array([-1.32305773, -0.43001409])], 'polygon': [[-1.1490039829947105, -0.5169394054555192], [-1.3588151621826021, -0.3049638063808476], [-1.3578924966755048, -0.2950064629418568], [-1.1480813174876132, -0.5069820620165284], [-1.1490039829947105, -0.5169394054555192]], 'center': [-1.2525139791062763, -0.4154011121091561], 'normal': [0.7217997243230518, 0.6921019852356776], 'type': 'ws', 'category': 9, 'viz_data': array([-1.25251398, -0.41540111]), 'length': 0.2982522179553398, 'limits': [[-1.3570492644060113, -0.30329083538459595], [-1.1506283122581764, -0.5185692040834989]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_2', {'geom': [array([-1.32305773, -0.43001409]), array([-0.62322209,  0.40401754])], 'polygon': [[-1.3588151621826021, -0.3049638063808476], [-0.5850115660926027, 0.460938711004104], [-0.5840889005855053, 0.4708960544430948], [-1.3578924966755048, -0.2950064629418568], [-1.3588151621826021, -0.3049638063808476]], 'center': [-0.9672242774844131, 0.07351159364173597], 'normal': [0.7098644980332606, -0.704338267050703], 'type': 'ws', 'category': 9, 'viz_data': array([-0.96722428,  0.07351159]), 'length': 1.08875096852238, 'limits': [[-0.5885291447734154, 0.46437771455552573], [-1.355378115192243, -0.30848794519783984]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_3', {'geom': [array([-0.62322209,  0.40401754]), array([-0.36210843,  0.18491716])], 'polygon': [[-0.5850115660926027, 0.460938711004104], [-0.34522736130644005, 0.21868088349019535], [-0.34430469579934264, 0.22863822692918614], [-0.5840889005855053, 0.4708960544430948], [-0.5850115660926027, 0.460938711004104]], 'center': [-0.46913665531682996, 0.3380700785740079], 'normal': [-0.6874089804405599, -0.7262705374787487], 'type': 'ws', 'category': 9, 'viz_data': array([-0.46913666,  0.33807008]), 'length': 0.34085967766324476, 'limits': [[-0.3414001589143715, 0.2227848647270509], [-0.5889565002156891, 0.45709486822283985]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_4', {'geom': [array([-0.36210843,  0.18491716]), array([-0.35663092,  0.191445  ])], 'polygon': [[-0.34522736130644005, 0.21868088349019535], [-0.3391709156185928, 0.2246754886098501], [-0.3382482501114954, 0.2346328320488409], [-0.34430469579934264, 0.22863822692918614], [-0.34522736130644005, 0.21868088349019535]], 'center': [-0.34412658801076057, 0.22462752094558866], 'normal': [0.6933690068543177, -0.7205826950002736], 'type': 'ws', 'category': 9, 'viz_data': array([-0.34412659,  0.22462752]), 'length': 0.008521491941581265, 'limits': [[-0.3391707321853051, 0.22460554840346145], [-0.34531117181399285, 0.21869700999901015]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_5', {'geom': [array([-0.35663092,  0.191445  ]), array([-0.34357524,  0.18048999])], 'polygon': [[-0.3391709156185928, 0.2246754886098501], [-0.32718170537928587, 0.2125625972341559], [-0.3262590398721885, 0.22251994067314668], [-0.3382482501114954, 0.2346328320488409], [-0.3391709156185928, 0.2246754886098501]], 'center': [-0.3332405708920914, 0.2158555262640735], 'normal': [-0.7024411630685903, -0.7117418158481672], 'type': 'ws', 'category': 9, 'viz_data': array([-0.33324057,  0.21585553]), 'length': 0.017042983883160497, 'limits': [[-0.3271435675642527, 0.21263375915289645], [-0.33927377186072444, 0.22460545257394293]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_6', {'geom': [array([-0.34357524,  0.18048999]), array([0.50543872, 1.19230543])], 'polygon': [[-0.32718170537928587, 0.2125625972341559], [0.6115673762371089, 1.1417263907805315], [0.6124900417442063, 1.1516837342195223], [-0.3262590398721885, 0.22251994067314668], [-0.32718170537928587, 0.2125625972341559]], 'center': [0.13782557426829917, 0.6793195999129534], 'normal': [0.7194396286995945, -0.6945549802978808], 'type': 'ws', 'category': 9, 'viz_data': array([0.13782557, 0.6793196 ]), 'length': 1.320831250945069, 'limits': [[0.6009361018585543, 1.152373480996475], [-0.31645382161842334, 0.20211513624173338]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_7', {'geom': [array([0.50543872, 1.19230543]), array([ 3.6242149 , -1.42465851])], 'polygon': [[0.6115673762371089, 1.1417263907805315], [3.475581685500977, -1.7518331960561673], [3.4765043510080744, -1.7418758526171765], [0.6124900417442063, 1.1516837342195223], [0.6115673762371089, 1.1417263907805315]], 'center': [2.0426952848124857, -0.3028950237010135], 'normal': [-0.7222514007358486, -0.6916306197206026], 'type': 'ws', 'category': 9, 'viz_data': array([ 2.04269528, -0.30289502]), 'length': 4.071273148075766, 'limits': [[3.451447336219604, -1.7753090015761723], [0.6356301657641139, 1.165173732399798]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_9', {'geom': [array([ 1.29208145, -4.20398692]), array([-1.83322256, -1.58154548])], 'polygon': [[0.8969572744323591, -4.304128039098026], [-1.9730516399511617, -1.4045120065734786], [-1.9721289744440644, -1.3945546631344878], [0.8978799399394564, -4.2941706956590355], [0.8969572744323591, -4.304128039098026]], 'center': [-0.5399613288304604, -2.856780318979197], 'normal': [0.7207211430590221, 0.6932250961611939], 'type': 'ws', 'category': 9, 'viz_data': array([-0.53996133, -2.85678032]), 'length': 4.079794640017346, 'limits': [[-1.9521201831826778, -1.3841505416351376], [0.8760958484612705, -4.324544798034511]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_10', {'geom': [array([-1.83322256, -1.58154548]), array([-1.06089373, -0.66111982])], 'polygon': [[-1.9730516399511617, -1.4045120065734786], [-1.119092797964634, -0.5592726847022607], [-1.1181701324575364, -0.5493153412632699], [-1.9721289744440644, -1.3945546631344878], [-1.9730516399511617, -1.4045120065734786]], 'center': [-1.5453286436029436, -0.9775324726973827], 'normal': [0.7172674569111163, -0.6967979587055777], 'type': 'ws', 'category': 9, 'viz_data': array([-1.54532864, -0.97753247]), 'length': 1.2015303637629338, 'limits': [[-1.1273746488859808, -0.5509967711894523], [-1.9645985536787631, -1.4128153996071802]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_11', {'geom': [array([-1.06089373, -0.66111982]), array([-1.10006078, -0.62825476])], 'polygon': [[-1.119092797964634, -0.5592726847022607], [-1.1550604286825588, -0.522934010575174], [-1.1541377631754612, -0.5129766671361832], [-1.1181701324575364, -0.5493153412632699], [-1.119092797964634, -0.5592726847022607]], 'center': [-1.1384553141485316, -0.5395876407533468], 'normal': [0.7288335049985752, 0.6846909682415068], 'type': 'ws', 'category': 9, 'viz_data': array([-1.13845531, -0.53958764]), 'length': 0.05112895164948728, 'limits': [[-1.1546203839697855, -0.5225065475660389], [-1.1196128525597249, -0.5597710406036374]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_3_centroid', {'polygon': [[-10.238905383091954, -3.4831361594811208], [-7.920708136600787, -1.1886093365843853], [-4.9907531710207245, -4.14878982598741], [-7.30895041751189, -6.443316648884144], [-10.238905383091954, -3.4831361594811208]], 'center': [-7.614829277056338, -3.815962992734265], 'normal': [0.0, 0.0], 'type': 'room', 'category': 0, 'category_letter': 'Bedroom', 'viz_data': array([-7.61482928, -3.81596299])}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_3_ws_0', {'geom': [array([-9.87202954, -4.41396475]), array([-7.775429  , -1.91533352])], 'polygon': [[-10.238905383091954, -3.4831361594811208], [-7.920708136600787, -1.1886093365843853], [-7.91978547109369, -1.1786519931453945], [-10.237982717584856, -3.4731788160421297], [-10.238905383091954, -3.4831361594811208]], 'center': [-9.075470634069635, -2.3393253580414672], 'normal': [0.6802601710969788, -0.7329707358545149], 'type': 'ws', 'category': 9, 'viz_data': array([-9.07547063, -2.33932536]), 'length': 3.2617314136255615, 'limits': [[-7.884316702718235, -1.2263221687268047], [-10.27507037712315, -3.4451481382321205]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_3_ws_1', {'geom': [array([-7.775429  , -1.91533352]), array([-4.58484657, -4.59255006])], 'polygon': [[-7.920708136600787, -1.1886093365843853], [-4.9907531710207245, -4.14878982598741], [-4.989830505513627, -4.13883248254842], [-7.91978547109369, -1.1786519931453945], [-7.920708136600787, -1.1886093365843853]], 'center': [-6.458327671252498, -2.670865775564829], 'normal': [-0.736572754454469, -0.6763583202677088], 'type': 'ws', 'category': 9, 'viz_data': array([-6.45832767, -2.67086578]), 'length': 4.165009559433158, 'limits': [[-5.04713191554199, -4.202714642657362], [-7.864170785059152, -1.1348820791364862]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_3_ws_2', {'geom': [array([-4.58484657, -4.59255006]), array([-6.68144711, -7.09118129])], 'polygon': [[-4.9907531710207245, -4.14878982598741], [-7.30895041751189, -6.443316648884144], [-7.308027752004793, -6.433359305445153], [-4.989830505513627, -4.13883248254842], [-4.9907531710207245, -4.14878982598741]], 'center': [-6.1480285847030824, -5.2918562143988845], 'normal': [-0.6796057210575543, 0.733577578655347], 'type': 'ws', 'category': 9, 'viz_data': array([-6.14802858, -5.29185621]), 'length': 3.2617314136255615, 'limits': [[-7.346355966686938, -6.404336380363592], [-4.953622934055416, -4.1876450511105165]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_3_ws_3', {'geom': [array([-6.68144711, -7.09118129]), array([-9.87202954, -4.41396475])], 'polygon': [[-7.30895041751189, -6.443316648884144], [-10.238905383091954, -3.4831361594811208], [-10.237982717584856, -3.4731788160421297], [-7.308027752004793, -6.433359305445153], [-7.30895041751189, -6.443316648884144]], 'center': [-8.77080833349274, -4.963910057344575], 'normal': [0.717578799669813, 0.6964773264539417], 'type': 'ws', 'category': 9, 'viz_data': array([-8.77080833, -4.96391006]), 'length': 4.165009559433158, 'limits': [[-10.224338419222892, -3.468834616601554], [-7.323503696613775, -6.457557176872895]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_centroid', {'polygon': [[-4.898423193180305, -4.045412760454335], [-7.822383553640714, -1.091288716739158], [-5.576863655403722, 1.131302844721727], [-3.832433565584394, -0.6311228504419584], [-3.771869108705915, -0.5711767992454182], [-2.592338838064834, -1.7628751477969087], [-4.898423193180305, -4.045412760454335]], 'center': [-5.215845305702894, -1.4542559402572395], 'normal': [0.0, 0.0], 'type': 'room', 'category': 2, 'category_letter': 'Kitchen', 'viz_data': array([-5.21584531, -1.45425594])}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_0', {'geom': [array([-4.50244868, -4.481095  ]), array([-7.68650327, -1.80935597])], 'polygon': [[-4.898423193180305, -4.045412760454335], [-7.822383553640714, -1.091288716739158], [-7.8214608881336165, -1.0813313733001673], [-4.897500527673207, -4.035455417015344], [-4.898423193180305, -4.045412760454335]], 'center': [-6.364148250568314, -2.5639347370285916], 'normal': [0.6838584764964996, 0.7296146819547195], 'type': 'ws', 'category': 9, 'viz_data': array([-6.36414825, -2.56393474]), 'length': 4.156488067491577, 'limits': [[-7.87655784024188, -1.1469824678027019], [-4.843923120830426, -3.9894320652133732]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_1', {'geom': [array([-7.68650327, -1.80935597]), array([-5.65563284,  0.61094116])], 'polygon': [[-7.822383553640714, -1.091288716739158], [-5.576863655403722, 1.131302844721727], [-5.575940989896625, 1.1412601881607178], [-7.8214608881336165, -1.0813313733001673], [-7.822383553640714, -1.091288716739158]], 'center': [-6.703456612229397, 0.01933990551232988], 'normal': [0.7249421473742599, -0.6888097581773915], 'type': 'ws', 'category': 9, 'viz_data': array([-6.70345661,  0.01933991]), 'length': 3.1594735103265865, 'limits': [[-5.611507784152952, 1.1653420980961382], [-7.787783968768883, -1.1250934130521084]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_2', {'geom': [array([-5.65563284,  0.61094116]), array([-3.75603095, -0.98301409])], 'polygon': [[-5.576863655403722, 1.131302844721727], [-3.832433565584394, -0.6311228504419584], [-3.8315109000772964, -0.6211655070029676], [-5.575940989896625, 1.1412601881607178], [-5.576863655403722, 1.131302844721727]], 'center': [-4.703508490825114, 0.2468396864651413], 'normal': [-0.7360929964648968, -0.676880418209398], 'type': 'ws', 'category': 9, 'viz_data': array([-4.70350849,  0.24683969]), 'length': 2.4797541550001014, 'limits': [[-3.865279902736852, -0.6625351403840719], [-5.543776932229814, 1.1627945260662311]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_3', {'geom': [array([-3.75603095, -0.98301409]), array([-3.70125586, -0.91773567])], 'polygon': [[-3.832433565584394, -0.6311228504419584], [-3.771869108705915, -0.5711767992454182], [-3.7709464431988176, -0.5612194558064274], [-3.8315109000772964, -0.6211655070029676], [-3.832433565584394, -0.6311228504419584]], 'center': [-3.7972419153032444, -0.5978739283176391], 'normal': [0.6812069669458248, -0.7320908879261303], 'type': 'ws', 'category': 9, 'viz_data': array([-3.79724192, -0.59787393]), 'length': 0.085214919415812, 'limits': [[-3.771057534195435, -0.5719723028604349], [-3.8334426002151103, -0.6300212996542132]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_4', {'geom': [array([-3.70125586, -0.91773567]), array([-2.41680316, -1.99551946])], 'polygon': [[-3.771869108705915, -0.5711767992454182], [-2.592338838064834, -1.7628751477969087], [-2.5914161725577363, -1.7529178043579179], [-3.7709464431988176, -0.5612194558064274], [-3.771869108705915, -0.5711767992454182]], 'center': [-3.182393783529673, -1.1643347019924284], 'normal': [-0.7009830066897424, -0.7131779752153097], 'type': 'ws', 'category': 9, 'viz_data': array([-3.18239378, -1.1643347 ]), 'length': 1.6767339124914755, 'limits': [[-2.5841621358395725, -1.754702722496019], [-3.7799718325250877, -0.5793407430990891]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_5', {'geom': [array([-2.41680316, -1.99551946]), array([-4.50244868, -4.481095  ])], 'polygon': [[-2.592338838064834, -1.7628751477969087], [-4.898423193180305, -4.045412760454335], [-4.897500527673207, -4.035455417015344], [-2.5914161725577363, -1.7529178043579179], [-2.592338838064834, -1.7628751477969087]], 'center': [-3.749239017300384, -2.903455719580188], 'normal': [-0.6931269437368974, 0.7208155380303258], 'type': 'ws', 'category': 9, 'viz_data': array([-3.74923902, -2.90345572]), 'length': 3.2446884297423986, 'limits': [[-4.914802280064799, -4.02869011018013], [-2.575980443839258, -1.7797091354943075]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Livingroom_5_centroid', {'polygon': [[-4.606186554820489, -9.05567008395921], [-4.665329559744457, -9.114209197224989], [-7.181656772068392, -6.571923460283457], [-4.778669285947358, -4.193472165711566], [-1.9686064227603763, -7.032523741357636], [-3.8265137969751146, -8.871460575160663], [-4.126244052957817, -8.568638290768277], [-4.612181159940143, -9.049613638271364], [-4.606186554820489, -9.05567008395921]], 'center': [-4.5832229558822135, -6.748108530632319], 'normal': [0.0, 0.0], 'type': 'room', 'category': 1, 'category_letter': 'Livingroom', 'viz_data': array([-4.58322296, -6.74810853])}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Livingroom_5_ws_0', {'geom': [array([-3.74917946, -9.44301662]), array([-3.80266898, -9.50676295])], 'polygon': [[-4.606186554820489, -9.05567008395921], [-4.665329559744457, -9.114209197224989], [-4.664406894237359, -9.104251853785998], [-4.605263889313392, -9.04571274052022], [-4.606186554820489, -9.05567008395921]], 'center': [-4.636395423279606, -9.081669339206734], 'normal': [-0.7237524941183033, 0.6900596548542272], 'type': 'ws', 'category': 9, 'viz_data': array([-4.63639542, -9.08166934]), 'length': 0.08321491941581208, 'limits': [[-4.664375265001668, -9.115033317836735], [-4.606952006430871, -9.054806312361686]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Livingroom_5_ws_2', {'geom': [array([-6.54283035, -7.20749456]), array([-4.36954467, -4.61747355])], 'polygon': [[-7.181656772068392, -6.571923460283457], [-4.778669285947358, -4.193472165711566], [-4.7777466204402605, -4.183514822272575], [-7.180734106561294, -6.5619661168444665], [-7.181656772068392, -6.571923460283457]], 'center': [-5.9791348289625, -5.380315351732174], 'normal': [0.7009080152463323, -0.7132516765935064], 'type': 'ws', 'category': 9, 'viz_data': array([-5.97913483, -5.38031535]), 'length': 3.381032300807696, 'limits': [[-4.774408113211621, -4.197797779547182], [-7.185935070379511, -6.5675904189900445]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Livingroom_5_ws_3', {'geom': [array([-4.36954467, -4.61747355]), array([-1.30951908, -7.1851399 ])], 'polygon': [[-4.778669285947358, -4.193472165711566], [-1.9686064227603763, -7.032523741357636], [-1.967683757253279, -7.022566397918646], [-4.7777466204402605, -4.183514822272575], [-4.778669285947358, -4.193472165711566]], 'center': [-3.376318530138619, -5.615301755692088], 'normal': [-0.7291049563208655, -0.6844019014207577], 'type': 'ws', 'category': 9, 'viz_data': array([-3.37631853, -5.61530176]), 'length': 3.9945797206015357, 'limits': [[-2.006628810477075, -7.069303683395958], [-4.7405267666335655, -4.156835810686561]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Livingroom_5_ws_4', {'geom': [array([-1.30951908, -7.1851399 ]), array([-2.9898289 , -9.18765517])], 'polygon': [[-1.9686064227603763, -7.032523741357636], [-3.8265137969751146, -8.871460575160663], [-3.8255911314680175, -8.861503231721672], [-1.967683757253279, -7.022566397918646], [-1.9686064227603763, -7.032523741357636]], 'center': [-2.8991481001428396, -7.954232887448654], 'normal': [-0.7216068867519588, 0.6923030412992175], 'type': 'ws', 'category': 9, 'viz_data': array([-2.8991481 , -7.95423289]), 'length': 2.6140980260653968, 'limits': [[-3.8024925726296828, -8.895127425000124], [-1.9927445589303274, -7.008776286746634]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Livingroom_5_ws_6', {'geom': [array([-3.31622098, -8.9137797 ]), array([-3.75570731, -9.43753911])], 'polygon': [[-4.126244052957817, -8.568638290768277], [-4.612181159940143, -9.049613638271364], [-4.611258494433046, -9.039656294832374], [-4.12532138745072, -8.558680947329286], [-4.126244052957817, -8.568638290768277]], 'center': [-4.3706445757208, -8.810836750271616], 'normal': [-0.7088294197297909, 0.7053799357265049], 'type': 'ws', 'category': 9, 'viz_data': array([-4.37064458, -8.81083675]), 'length': 0.6837193553264883, 'limits': [[-4.610366556597824, -9.051435369643357], [-4.128084641682658, -8.566794975749255]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Livingroom_5_ws_7', {'geom': [array([-3.75570731, -9.43753911]), array([-3.74917946, -9.44301662])], 'polygon': [[-4.612181159940143, -9.049613638271364], [-4.606186554820489, -9.05567008395921], [-4.605263889313392, -9.04571274052022], [-4.611258494433046, -9.039656294832374], [-4.612181159940143, -9.049613638271364]], 'center': [-4.611892530471875, -9.054177796490713], 'normal': [-0.7053556807335297, -0.7088535558611095], 'type': 'ws', 'category': 9, 'viz_data': array([-4.61189253, -9.0541778 ]), 'length': 0.008521491941580377, 'limits': [[-4.606175371264298, -9.055626647973117], [-4.6122158611283295, -9.049615965223797]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_centroid', {'polygon': [[-3.101521576082771, -0.5551254366381514], [-3.4252302525440874, -0.22807736949437535], [-2.5545235254485252, 0.6337388298050429], [-1.3749932548074442, -0.5579595187464473], [-2.53035292923185, -1.7015221586696063], [-3.386174523411614, -0.8368718772618902], [-3.101521576082771, -0.5551254366381514]], 'center': [-2.4798356503516072, -0.5339944260500263], 'normal': [0.0, 0.0], 'type': 'room', 'category': 4, 'category_letter': 'Corridor', 'viz_data': array([-2.47983565, -0.53399443])}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_0', {'geom': [array([-3.0352488 , -0.83990213]), array([-3.38775225, -0.54411662])], 'polygon': [[-3.101521576082771, -0.5551254366381514], [-3.4252302525440874, -0.22807736949437535], [-3.4243075870369903, -0.21812002605538455], [-3.1005989105756737, -0.5451680931991606], [-3.101521576082771, -0.5551254366381514]], 'center': [-3.2679225643662115, -0.38706260483133564], 'normal': [0.7023161030380234, 0.7118652199774088], 'type': 'ws', 'category': 9, 'viz_data': array([-3.26792256, -0.3870626 ]), 'length': 0.4601605648453778, 'limits': [[-3.427108449311053, -0.22995796502288116], [-3.0995361475924694, -0.5531361396968626]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_1', {'geom': [array([-3.38775225, -0.54411662]), array([-2.60027646,  0.39436048])], 'polygon': [[-3.4252302525440874, -0.22807736949437535], [-2.5545235254485252, 0.6337388298050429], [-2.5536008599414277, 0.6436961732440337], [-3.4243075870369903, -0.21812002605538455], [-3.4252302525440874, -0.22807736949437535]], 'center': [-2.9901368295905306, 0.2064784530281298], 'normal': [0.6959012392721868, -0.718137497405222], 'type': 'ws', 'category': 9, 'viz_data': array([-2.99013683,  0.20647845]), 'length': 1.2250948395876788, 'limits': [[-2.550022270458114, 0.6291006899593444], [-3.429808812643661, -0.2234443271356821]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_2', {'geom': [array([-2.60027646,  0.39436048]), array([-1.31582377, -0.68342331])], 'polygon': [[-2.5545235254485252, 0.6337388298050429], [-1.3749932548074442, -0.5579595187464473], [-1.3740705893003466, -0.5480021753074565], [-2.5536008599414277, 0.6436961732440337], [-2.5545235254485252, 0.6337388298050429]], 'center': [-1.9655231360051681, 0.038278396765458064], 'normal': [-0.7254189344126613, -0.6883076126235996], 'type': 'ws', 'category': 9, 'viz_data': array([-1.96552314,  0.0382784 ]), 'length': 1.6767339124914755, 'limits': [[-1.3877124093666116, -0.5702936668907725], [-2.5418211256786467, 0.6460408612023659]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_3', {'geom': [array([-1.31582377, -0.68342331]), array([-2.36074249, -1.92870895])], 'polygon': [[-1.3749932548074442, -0.5579595187464473], [-2.53035292923185, -1.7015221586696063], [-2.5294302637247523, -1.6915648152306155], [-1.3740705893003466, -0.5480021753074565], [-1.3749932548074442, -0.5579595187464473]], 'center': [-1.9525061891077273, -1.127785402925664], 'normal': [-0.717394805463434, 0.6966668451233211], 'type': 'ws', 'category': 9, 'viz_data': array([-1.95250619, -1.1277854 ]), 'length': 1.6256049608419916, 'limits': [[-2.5188869056652528, -1.7128440357783408], [-1.386381826178643, -0.5466434811347066]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_4', {'geom': [array([-2.36074249, -1.92870895]), array([-3.29269175, -1.14671068])], 'polygon': [[-2.53035292923185, -1.7015221586696063], [-3.386174523411614, -0.8368718772618902], [-3.3852518579045165, -0.8269145338228994], [-2.5294302637247523, -1.6915648152306155], [-2.53035292923185, -1.7015221586696063]], 'center': [-2.9578663872263897, -1.268244188513523], 'normal': [0.7046265385530492, 0.7095783544942367], 'type': 'ws', 'category': 9, 'viz_data': array([-2.95786639, -1.26824419]), 'length': 1.216573347646099, 'limits': [[-3.3898825429371646, -0.8405854792114447], [-2.5266284287929013, -1.6978153460592107]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_5', {'geom': [array([-3.29269175, -1.14671068]), array([-3.0352488 , -0.83990213])], 'polygon': [[-3.386174523411614, -0.8368718772618902], [-3.101521576082771, -0.5551254366381514], [-3.1005989105756737, -0.5451680931991606], [-3.3852518579045165, -0.8269145338228994], [-3.386174523411614, -0.8368718772618902]], 'center': [-3.2476096511549186, -0.6984875656957914], 'normal': [0.6857580374454751, -0.7278295913735096], 'type': 'ws', 'category': 9, 'viz_data': array([-3.24760965, -0.69848757]), 'length': 0.4005101212543112, 'limits': [[-3.0980363553269035, -0.5587655026514393], [-3.3895394732203834, -0.8334185373798451]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_centroid', {'polygon': [[-3.571543997536397, -9.952780646602744], [-4.063101617348029, -9.45615210019923], [-3.651263310574384, -9.048518952062754], [-3.657257915694038, -9.042462506374907], [-1.7751247587279086, -7.179547252093266], [-1.7691301536082549, -7.185603697781112], [-1.333066064083219, -6.753992129166021], [-0.8534976545108955, -7.238507784193839], [-0.38109489085877335, -6.770928584860823], [0.7924407746626547, -7.956570487724467], [-2.870287414530704, -11.581899647184398], [-4.031833869812823, -10.40837063569645], [-3.571543997536397, -9.952780646602744]], 'center': [-1.8199268313965615, -8.979924558006939], 'normal': [0.0, 0.0], 'type': 'room', 'category': 8, 'category_letter': 'Balcony', 'viz_data': array([-1.81992683, -8.97992456])}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_0', {'geom': [array([ -2.63617704, -10.24083752]), array([-3.17146005, -9.79168174])], 'polygon': [[-3.571543997536397, -9.952780646602744], [-4.063101617348029, -9.45615210019923], [-4.062178951840932, -9.44619475676024], [-3.5706213320292997, -9.942823303163753], [-3.571543997536397, -9.952780646602744]], 'center': [-3.8181279483897423, -9.704793185782552], 'normal': [0.7254585669689348, 0.6882658407994542], 'type': 'ws', 'category': 9, 'viz_data': array([-3.81812795, -9.70479319]), 'length': 0.6987623392096509, 'limits': [[-4.057783193976929, -9.451021928179406], [-3.576848945061806, -9.957945053434301]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_3', {'geom': [array([-2.80551725, -9.34231101]), array([-1.10329739, -7.31368438])], 'polygon': [[-3.657257915694038, -9.042462506374907], [-1.7751247587279086, -7.179547252093266], [-1.7742020932208113, -7.169589908654276], [-3.6563352501869404, -9.032505162935918], [-3.657257915694038, -9.042462506374907]], 'center': [-2.7181370089889354, -8.115332258007685], 'normal': [0.692490386390366, -0.7214271028710538], 'type': 'ws', 'category': 9, 'viz_data': array([-2.71813701, -8.11533226]), 'length': 2.6481839938317204, 'limits': [[-1.7608893709792803, -7.194114237688091], [-3.671361077518795, -9.0279561948094]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_4', {'geom': [array([-1.10329739, -7.31368438]), array([-1.09676955, -7.31916189])], 'polygon': [[-1.7751247587279086, -7.179547252093266], [-1.7691301536082549, -7.185603697781112], [-1.7682074881011574, -7.175646354342122], [-1.7742020932208113, -7.169589908654276], [-1.7751247587279086, -7.179547252093266]], 'center': [-1.7760477923725377, -7.183759990493601], 'normal': [-0.7218339770118839, -0.692066261012056], 'type': 'ws', 'category': 9, 'viz_data': array([-1.77604779, -7.18375999]), 'length': 0.008521491941580608, 'limits': [[-1.7691603788487704, -7.1857135814404876], [-1.7750578159150245, -7.179562479022223]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_5', {'geom': [array([-1.09676955, -7.31916189]), array([-0.70238887, -6.84915729])], 'polygon': [[-1.7691301536082549, -7.185603697781112], [-1.333066064083219, -6.753992129166021], [-1.3321433985761217, -6.744034785727031], [-1.7682074881011574, -7.175646354342122], [-1.7691301536082549, -7.185603697781112]], 'center': [-1.5472844021057248, -6.964967755517851], 'normal': [0.7119057310893866, -0.70227503874343], 'type': 'ws', 'category': 9, 'viz_data': array([-1.5472844 , -6.96496776]), 'length': 0.6135474197938394, 'limits': [[-1.3356006400405835, -6.751449147107202], [-1.7664796780472338, -7.188237071553542]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_6', {'geom': [array([-0.70238887, -6.84915729]), array([-0.18016154, -7.28735805])], 'polygon': [[-1.333066064083219, -6.753992129166021], [-0.8534976545108955, -7.238507784193839], [-0.8525749890037981, -7.228550440754849], [-1.3321433985761217, -6.744034785727031], [-1.333066064083219, -6.753992129166021]], 'center': [-1.0935908170316224, -6.9980643885545994], 'normal': [-0.7334776768702649, -0.6797135407897946], 'type': 'ws', 'category': 9, 'viz_data': array([-1.09359082, -6.99806439]), 'length': 0.681719355326488, 'limits': [[-0.8615354136927915, -7.246274063984435], [-1.3249092905266946, -6.746248134962068]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_7', {'geom': [array([-0.18016154, -7.28735805]), array([ 0.24708419, -6.77818641])], 'polygon': [[-0.8534976545108955, -7.238507784193839], [-0.38109489085877335, -6.770928584860823], [-0.38017222535167605, -6.760971241421833], [-0.8525749890037981, -7.228550440754849], [-0.8534976545108955, -7.238507784193839]], 'center': [-0.6202470607302185, -7.006821576536533], 'normal': [0.7049015585006793, -0.709305147890042], 'type': 'ws', 'category': 9, 'viz_data': array([-0.62024706, -7.00682158]), 'length': 0.6646763714433258, 'limits': [[-0.38157133671255833, -6.7704465299673515], [-0.8530297086581832, -7.23897794009633]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_8', {'geom': [array([ 0.24708419, -6.77818641]), array([ 1.52500905, -7.85049268])], 'polygon': [[-0.38109489085877335, -6.770928584860823], [0.7924407746626547, -7.956570487724467], [0.793363440169752, -7.946613144285476], [-0.38017222535167605, -6.760971241421833], [-0.38109489085877335, -6.770928584860823]], 'center': [0.20185049846975744, -7.363384781818203], 'normal': [-0.7248982029717671, -0.6888560047849647], 'type': 'ws', 'category': 9, 'viz_data': array([ 0.2018505 , -7.36338478]), 'length': 1.6682124205498956, 'limits': [[0.7802437967147027, -7.968469361501449], [-0.3689143464379533, -6.759185175669646]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_10', {'geom': [array([ -1.78759858, -11.79830473]), array([ -3.05246776, -10.73695348])], 'polygon': [[-2.870287414530704, -11.581899647184398], [-4.031833869812823, -10.40837063569645], [-4.030911204305727, -10.398413292257459], [-2.8693647490236063, -11.571942303745407], [-2.870287414530704, -11.581899647184398]], 'center': [-3.4516678962159233, -10.992014712690677], 'normal': [0.700946895550376, 0.7132134670758049], 'type': 'ws', 'category': 9, 'viz_data': array([ -3.4516679 , -10.99201471]), 'length': 1.6511694366667338, 'limits': [[-4.039835762000169, -10.416435415643878], [-2.862199483345484, -11.573817506303088]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_11', {'geom': [array([ -3.05246776, -10.73695348]), array([ -2.63617704, -10.24083752])], 'polygon': [[-4.031833869812823, -10.40837063569645], [-3.571543997536397, -9.952780646602744], [-3.5706213320292997, -9.942823303163753], [-4.030911204305727, -10.398413292257459], [-4.031833869812823, -10.40837063569645]], 'center': [-3.8008947701730476, -10.18040512309153], 'normal': [0.7111591724275649, -0.7030310316565987], 'type': 'ws', 'category': 9, 'viz_data': array([ -3.80089477, -10.18040512]), 'length': 0.6476333875601632, 'limits': [[-3.5740338473542113, -9.950299058626447], [-4.02934021594589, -10.410869482560193]]})]\n",
      "[('1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_0', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_1', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_2', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_3', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_4', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_5', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_centroid', {'type': 'connected_by_door', 'opening': 'door'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_0', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_1', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_0', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_5', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_1', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_2', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_2', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_3', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_3', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_4', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_4', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_5', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_0', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_2', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_3', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_4', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_8', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_9', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_centroid', {'type': 'connected_by_door', 'opening': 'door'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Livingroom_5_centroid', {'type': 'connected_by_passage', 'opening': 'passage'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_0', '1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_9', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_2', '1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_3', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_3', '1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_4', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_8', '1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_9', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_0', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_1', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_2', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_3', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_4', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_5', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_6', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_7', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_9', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_10', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_11', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_centroid', {'type': 'connected_by_door', 'opening': 'door'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_0', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_1', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_0', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_11', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_1', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_2', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_2', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_3', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_3', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_4', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_4', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_5', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_5', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_6', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_6', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_7', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_9', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_10', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_10', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_11', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_3_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_3_ws_0', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_3_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_3_ws_1', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_3_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_3_ws_2', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_3_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_3_ws_3', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_3_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_centroid', {'type': 'connected_by_door', 'opening': 'door'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_3_ws_0', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_3_ws_1', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_3_ws_0', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_3_ws_3', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_3_ws_1', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_3_ws_2', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_3_ws_2', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_3_ws_3', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_0', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_1', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_2', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_3', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_4', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_5', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_centroid', {'type': 'connected_by_door', 'opening': 'door'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_0', '1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_1', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_0', '1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_5', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_1', '1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_2', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_2', '1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_3', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_3', '1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_4', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_4', '1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_5', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Livingroom_5_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Livingroom_5_ws_0', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Livingroom_5_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Livingroom_5_ws_2', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Livingroom_5_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Livingroom_5_ws_3', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Livingroom_5_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Livingroom_5_ws_4', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Livingroom_5_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Livingroom_5_ws_6', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Livingroom_5_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Livingroom_5_ws_7', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Livingroom_5_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_centroid', {'type': 'connected_by_door', 'opening': 'door'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Livingroom_5_ws_0', '1588_dd7f04c697c2d6ba20587aad0f95b928_Livingroom_5_ws_7', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Livingroom_5_ws_2', '1588_dd7f04c697c2d6ba20587aad0f95b928_Livingroom_5_ws_3', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Livingroom_5_ws_3', '1588_dd7f04c697c2d6ba20587aad0f95b928_Livingroom_5_ws_4', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Livingroom_5_ws_6', '1588_dd7f04c697c2d6ba20587aad0f95b928_Livingroom_5_ws_7', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_0', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_1', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_2', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_3', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_4', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_5', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_0', '1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_1', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_0', '1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_5', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_1', '1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_2', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_2', '1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_3', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_3', '1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_4', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_4', '1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_5', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_0', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_3', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_4', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_5', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_6', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_7', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_8', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_10', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_11', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_0', '1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_11', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_3', '1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_4', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_4', '1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_5', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_5', '1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_6', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_6', '1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_7', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_7', '1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_8', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_10', '1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_11', {'type': 'ws_same_room'})]\n"
     ]
    }
   ],
   "source": [
    "# Check the number of graphs\n",
    "print(f\"Number of original graphs: {len(noise_graphs)}\")\n",
    "print(noise_graphs[0])\n",
    "print(noise_graphs[0].nodes(data=True))\n",
    "print(noise_graphs[0].edges(data=True))\n",
    "plot_a_graph([noise_graphs[9]],path=os.path.join(gm_path, \"ws_dropout_noise\", \"apartment.png\"), viz_rooms=True, viz_ws=True, viz_openings=False, viz_room_connection=True, viz_normals=False, viz_room_normals=True, viz_walls=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate G1,G2,GT dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: count=3426, nodes min=5, max=296, mean=78.6\n",
      "VAL: count=734, nodes min=5, max=310, mean=77.8\n",
      "TEST: count=735, nodes min=5, max=242, mean=78.4\n",
      "Serialized 3426 pairs to ./GNN/preprocessed/partial_graph_matching/ws_dropout_noise/train_dataset.pkl\n",
      "Serialized 734 pairs to ./GNN/preprocessed/partial_graph_matching/ws_dropout_noise/valid_dataset.pkl\n",
      "Serialized 735 pairs to ./GNN/preprocessed/partial_graph_matching/ws_dropout_noise/test_dataset.pkl\n",
      "Serialized 4895 pairs to ./GNN/preprocessed/partial_graph_matching/ws_dropout_noise/noise.pkl\n",
      "Data(x=[109, 7], edge_index=[2, 209], name='2245', node_names=[109], permutation=[109])\n",
      "G1 nodes: tensor([ 2.7960e+00, -2.7960e+00,  7.7763e-01, -1.7104e+00, -1.4349e-03,\n",
      "         1.9520e-03, -1.2917e+00])\n",
      "Data(x=[94, 7], edge_index=[2, 166], name='2245', node_names=[94], permutation=[94])\n",
      "G2 permuted nodes: tensor([-0.3577,  0.3577,  1.5073, -1.0891,  0.9188, -1.1852, -0.4930])\n",
      "Ground truth permutation:\n",
      " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "pair_gt_list = []\n",
    "for i, g1 in enumerate(original_graphs):\n",
    "    generate_matching_pair_as_data(g1, noise_graphs[i], pair_gt_list)\n",
    "\n",
    "train, val, test = split_graphs_stratified(pair_gt_list)\n",
    "\n",
    "describe(train, \"TRAIN\")\n",
    "describe(val,   \"VAL\")\n",
    "describe(test,  \"TEST\")\n",
    "\n",
    "# compute mean and std\n",
    "mean, std = compute_mean_std(train)\n",
    "\n",
    "# Normalizzazione dei set\n",
    "train_pairs_norm = normalize_data_pairs(train, mean, std)\n",
    "val_pairs_norm = normalize_data_pairs(val, mean, std)\n",
    "test_pairs_norm = normalize_data_pairs(test, mean, std)\n",
    "\n",
    "gm_equal_preprocessed_path = os.path.join(GNN_PATH, \"preprocessed\", \"partial_graph_matching\", \"ws_dropout_noise\")\n",
    "serialize_graph_matching_dataset(\n",
    "    train_pairs_norm,\n",
    "    gm_equal_preprocessed_path,\n",
    "    \"train_dataset.pkl\"\n",
    ")\n",
    "serialize_graph_matching_dataset(\n",
    "    val_pairs_norm,\n",
    "    gm_equal_preprocessed_path,\n",
    "    \"valid_dataset.pkl\"\n",
    ")\n",
    "serialize_graph_matching_dataset(\n",
    "    test_pairs_norm,\n",
    "    gm_equal_preprocessed_path,\n",
    "    \"test_dataset.pkl\"\n",
    ")\n",
    "serialize_graph_matching_dataset(\n",
    "    noise_graphs,\n",
    "    gm_equal_preprocessed_path,\n",
    "    \"noise.pkl\"\n",
    ")\n",
    "\n",
    "g1_out, g2_perm, gt_perm = train[5]\n",
    "\n",
    "print(g1_out)\n",
    "print(\"G1 nodes:\", g1_out.x[0])\n",
    "print(g2_perm)\n",
    "print(\"G2 permuted nodes:\", g2_perm.x[0])\n",
    "print(\"Ground truth permutation:\\n\", gt_perm[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the two graphs\n",
    "plot_two_graphs_with_matching(\n",
    "    [g1_out, g2_perm],\n",
    "    gt_perm=gt_perm,\n",
    "    pred_perm=gt_perm,\n",
    "    original_graphs=original_graphs,\n",
    "    noise_graphs=noise_graphs,\n",
    "    viz_rooms=True,\n",
    "    viz_ws=True,\n",
    "    match_display=\"all\",\n",
    "    path=os.path.join(gm_equal_preprocessed_path, \"gt.png\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Room dropout equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph matching-equal path\n",
    "gm_path = os.path.join(GNN_PATH, \"raw\", \"graph_matching\")\n",
    "original_graphs, _, _ = deserialize_MSD_dataset(data_path=gm_path, original_path=\"equal\")\n",
    "# graph matching path\n",
    "gm_path = os.path.join(GNN_PATH, \"raw\", \"partial_graph_matching\")\n",
    "noise_graphs, _, _ = deserialize_MSD_dataset(data_path=gm_path, original_path=\"room_dropout_equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of graphs\n",
    "print(f\"Number of original graphs: {len(noise_graphs)}\")\n",
    "print(noise_graphs[0])\n",
    "print(noise_graphs[0].nodes(data=True))\n",
    "print(noise_graphs[0].edges(data=True))\n",
    "plot_a_graph([noise_graphs[0]],path=os.path.join(gm_path, \"room_dropout_equal\", \"apartment.png\"), viz_rooms=True, viz_ws=True, viz_openings=False, viz_room_connection=True, viz_normals=False, viz_room_normals=True, viz_walls=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate G1,G2,GT dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_gt_list = []\n",
    "for i, g1 in enumerate(original_graphs):\n",
    "    generate_matching_pair_as_data(g1, noise_graphs[i], pair_gt_list)\n",
    "\n",
    "train, val, test = split_graphs_stratified(pair_gt_list)\n",
    "\n",
    "describe(train, \"TRAIN\")\n",
    "describe(val,   \"VAL\")\n",
    "describe(test,  \"TEST\")\n",
    "\n",
    "# compute mean and std\n",
    "mean, std = compute_mean_std(train)\n",
    "\n",
    "# Normalizzazione dei set\n",
    "train_pairs_norm = normalize_data_pairs(train, mean, std)\n",
    "val_pairs_norm = normalize_data_pairs(val, mean, std)\n",
    "test_pairs_norm = normalize_data_pairs(test, mean, std)\n",
    "\n",
    "gm_equal_preprocessed_path = os.path.join(GNN_PATH, \"preprocessed\", \"partial_graph_matching\", \"room_dropout_equal\")\n",
    "serialize_graph_matching_dataset(\n",
    "    train_pairs_norm,\n",
    "    gm_equal_preprocessed_path,\n",
    "    \"train_dataset.pkl\"\n",
    ")\n",
    "serialize_graph_matching_dataset(\n",
    "    val_pairs_norm,\n",
    "    gm_equal_preprocessed_path,\n",
    "    \"valid_dataset.pkl\"\n",
    ")\n",
    "serialize_graph_matching_dataset(\n",
    "    test_pairs_norm,\n",
    "    gm_equal_preprocessed_path,\n",
    "    \"test_dataset.pkl\"\n",
    ")\n",
    "serialize_graph_matching_dataset(\n",
    "    noise_graphs,\n",
    "    gm_equal_preprocessed_path,\n",
    "    \"noise.pkl\"\n",
    ")\n",
    "\n",
    "g1_out, g2_perm, gt_perm = train[0]\n",
    "\n",
    "print(g1_out)\n",
    "print(\"G1 nodes:\", g1_out.x[0])\n",
    "print(g2_perm)\n",
    "print(\"G2 permuted nodes:\", g2_perm.x[0])\n",
    "print(\"Ground truth permutation:\\n\", gt_perm[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the two graphs\n",
    "plot_two_graphs_with_matching(\n",
    "    [g1_out, g2_perm],\n",
    "    gt_perm=gt_perm,\n",
    "    pred_perm=gt_perm,\n",
    "    original_graphs=original_graphs,\n",
    "    noise_graphs=noise_graphs,\n",
    "    viz_rooms=True,\n",
    "    viz_ws=True,\n",
    "    match_display=\"all\",\n",
    "    path=os.path.join(gm_equal_preprocessed_path, \"gt.png\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Room dropout noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 4895 original graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Original graphs: 100%|██████████| 4895/4895 [00:35<00:00, 136.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 4895 original graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Original graphs: 100%|██████████| 4895/4895 [00:28<00:00, 169.95it/s]\n"
     ]
    }
   ],
   "source": [
    "# graph matching-equal path\n",
    "gm_path = os.path.join(GNN_PATH, \"raw\", \"graph_matching\")\n",
    "original_graphs, _, _ = deserialize_MSD_dataset(data_path=gm_path, original_path=\"equal\")\n",
    "# graph matching path\n",
    "gm_path = os.path.join(GNN_PATH, \"raw\", \"partial_graph_matching\")\n",
    "noise_graphs, _, _ = deserialize_MSD_dataset(data_path=gm_path, original_path=\"room_dropout_noise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of original graphs: 4895\n",
      "DiGraph named '0' with 58 nodes and 108 edges\n",
      "[('1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_centroid', {'polygon': [[0.710810706618149, -2.630142902548412], [2.0997009034287744, -3.0032488766598853], [1.6641737115326602, -4.624502593407521], [1.8123085689004663, -4.66429695611884], [1.6337528124887806, -5.32897229468687], [0.09672775831034901, -4.9160719578640775], [0.710810706618149, -2.630142902548412]], 'center': [1.1147806460367276, -3.990253701465177], 'normal': [0.0, 0.0], 'type': 'room', 'category': 7, 'category_letter': 'Bathroom', 'viz_data': array([ 1.11478065, -3.9902537 ])}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_0', {'geom': [array([-2.68667049,  0.46685368]), array([-3.61108401, -0.63481946])], 'polygon': [[0.710810706618149, -2.630142902548412], [2.0997009034287744, -3.0032488766598853], [2.0906351195549373, -3.007469251377001], [0.7017449227443117, -2.6343632772655283], [0.710810706618149, -2.630142902548412]], 'center': [1.4002955577685974, -2.8122063167057094], 'normal': [-0.26180463665438214, -0.965120889954345], 'type': 'ws', 'category': 9, 'viz_data': array([ 1.40029556, -2.81220632]), 'length': 1.438132138127206, 'limits': [[2.0992304686205836, -3.004962866903628], [0.7112590995993096, -2.6284532050202447]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_1', {'geom': [array([-3.61108401, -0.63481946]), array([-4.8970688,  0.4442499])], 'polygon': [[2.0997009034287744, -3.0032488766598853], [1.6641737115326602, -4.624502593407521], [1.6551079276588228, -4.628722968124637], [2.0906351195549373, -3.007469251377001], [2.0997009034287744, -3.0032488766598853]], 'center': [1.8822621902454622, -3.8144837963656717], 'normal': [-0.9612164750191446, 0.27579501110747134], 'type': 'ws', 'category': 9, 'viz_data': array([ 1.88226219, -3.8144838 ]), 'length': 1.678733912491476, 'limits': [[1.650454457574648, -4.620683654454474], [2.1134408956167237, -3.00705696059432]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_2', {'geom': [array([-4.8970688,  0.4442499]), array([-4.99566397,  0.32674875])], 'polygon': [[1.6641737115326602, -4.624502593407521], [1.8123085689004663, -4.66429695611884], [1.8032427850266288, -4.668517330835956], [1.6551079276588228, -4.628722968124637], [1.6641737115326602, -4.624502593407521]], 'center': [1.7398314761087108, -4.6458209626142795], 'normal': [-0.22457429670595608, -0.9744569694240098], 'type': 'ws', 'category': 9, 'viz_data': array([ 1.73983148, -4.64582096]), 'length': 0.15338685494846127, 'limits': [[1.8129255538450193, -4.661681199542008], [1.6634566640224622, -4.62723445446802]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_3', {'geom': [array([-4.99566397,  0.32674875]), array([-5.52288704,  0.76914144])], 'polygon': [[1.8123085689004663, -4.66429695611884], [1.6337528124887806, -5.32897229468687], [1.6246870286149433, -5.333192669403986], [1.8032427850266288, -4.668517330835956], [1.8123085689004663, -4.66429695611884]], 'center': [1.7240653185210821, -4.991777202159543], 'normal': [-0.9737170898030887, 0.22776090319763848], 'type': 'ws', 'category': 9, 'viz_data': array([ 1.72406532, -4.9917772 ]), 'length': 0.6882408472680721, 'limits': [[1.6448126918891899, -5.331741759639132], [1.8015670488804738, -4.661589884753653]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_4', {'geom': [array([-5.52288704,  0.76914144]), array([-4.49987835,  1.98831572])], 'polygon': [[1.6337528124887806, -5.32897229468687], [0.09672775831034901, -4.9160719578640775], [0.08766197443651173, -4.920292332581194], [1.6246870286149433, -5.333192669403986], [1.6337528124887806, -5.32897229468687]], 'center': [0.8688851580205026, -5.125367996297868], 'normal': [0.24614016943279085, 0.9692342425810165], 'type': 'ws', 'category': 9, 'viz_data': array([ 0.86888516, -5.125368  ]), 'length': 1.5915189930756675, 'limits': [[0.0939241636538447, -4.926704112208521], [1.636478869460841, -5.318440866819669]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_5', {'geom': [array([-4.49987835,  1.98831572]), array([-2.68667049,  0.46685368])], 'polygon': [[0.09672775831034901, -4.9160719578640775], [0.710810706618149, -2.630142902548412], [0.7017449227443117, -2.6343632772655283], [0.08766197443651173, -4.920292332581194], [0.09672775831034901, -4.9160719578640775]], 'center': [0.3992471298435235, -3.77679438562538], 'normal': [0.9739079788194515, -0.2269432721889122], 'type': 'ws', 'category': 9, 'viz_data': array([ 0.39924713, -3.77679439]), 'length': 2.366974759759548, 'limits': [[0.6722276954188697, -2.6203502249183566], [0.13505869825047356, -4.9255658291124345]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_centroid', {'polygon': [[2.3659541913207196, -1.0344482921230238], [3.424407523238259, 2.90565333713312], [5.726796007150345, 2.2871487929685084], [5.722374411293532, 2.2706893643720862], [5.903428125854182, 2.22205180994714], [5.777412643935002, 1.7529580949490924], [6.923274450973475, 1.4451383071113109], [7.0338143473938075, 1.8566240220218782], [7.055144087064092, 1.8508940850437785], [6.016587936502211, -2.0151401155284634], [2.3659541913207196, -1.0344482921230238]], 'center': [4.651768189362073, 0.38848907398272237], 'normal': [0.0, 0.0], 'type': 'room', 'category': 3, 'category_letter': 'Dining', 'viz_data': array([4.65176819, 0.38848907])}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_0', {'geom': [array([-1.93858082, -1.70710655]), array([ 1.1867232, -4.329548 ])], 'polygon': [[2.3659541913207196, -1.0344482921230238], [3.424407523238259, 2.90565333713312], [3.415341739364422, 2.9014329624160045], [2.356888407446882, -1.0386686668401397], [2.3659541913207196, -1.0344482921230238]], 'center': [2.896158109185549, 0.9373155295619985], 'normal': [0.9615493466036726, -0.27463221596537035], 'type': 'ws', 'category': 9, 'viz_data': array([2.89615811, 0.93731553]), 'length': 4.079794640017346, 'limits': [[3.4553754921067235, 2.8970800783789508], [2.3349324494351196, -1.025843792006894]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_1', {'geom': [array([ 1.1867232, -4.329548 ]), array([-0.34569387, -6.15581154])], 'polygon': [[3.424407523238259, 2.90565333713312], [5.726796007150345, 2.2871487929685084], [5.717730223276509, 2.2829284182513927], [3.415341739364422, 2.9014329624160045], [3.424407523238259, 2.90565333713312]], 'center': [4.573735285120676, 2.597319340518214], 'normal': [-0.22982183711635082, -0.9732327178966321], 'type': 'ws', 'category': 9, 'viz_data': array([4.57373529, 2.59731934]), 'length': 2.3840177436427084, 'limits': [[5.735730973430736, 2.3225088283399202], [3.415526905271547, 2.870408165901865]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_2', {'geom': [array([-0.34569387, -6.15581154]), array([-0.35874955, -6.14485652])], 'polygon': [[5.726796007150345, 2.2871487929685084], [5.722374411293532, 2.2706893643720862], [5.713308627419695, 2.2664689896549706], [5.717730223276509, 2.2829284182513927], [5.726796007150345, 2.2871487929685084]], 'center': [5.7276267433216015, 2.274593174176803], 'normal': [-0.9621732061386982, 0.2724384726663578], 'type': 'ws', 'category': 9, 'viz_data': array([5.72762674, 2.27459317]), 'length': 0.017042983883161743, 'limits': [[5.722322242422492, 2.2707605519757728], [5.726965406921298, 2.287158854420805]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_3', {'geom': [array([-0.35874955, -6.14485652]), array([-0.47925476, -6.28846904])], 'polygon': [[5.722374411293532, 2.2706893643720862], [5.903428125854182, 2.22205180994714], [5.894362341980345, 2.217831435230024], [5.713308627419695, 2.2664689896549706], [5.722374411293532, 2.2706893643720862]], 'center': [5.811004601332997, 2.2452131128078174], 'normal': [-0.28402383565172024, -0.958817219693975], 'type': 'ws', 'category': 9, 'viz_data': array([5.8110046 , 2.24521311]), 'length': 0.18747282271478447, 'limits': [[5.902806302955292, 2.219698383446654], [5.72305413231172, 2.272945133634561]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_4', {'geom': [array([-0.47925476, -6.28846904]), array([-0.85134173, -5.976251  ])], 'polygon': [[5.903428125854182, 2.22205180994714], [5.777412643935002, 1.7529580949490924], [5.768346860061166, 1.7487377202319763], [5.894362341980345, 2.217831435230024], [5.903428125854182, 2.22205180994714]], 'center': [5.841442180090973, 1.9912737133867855], 'normal': [-0.9599662327853087, 0.2801157473473823], 'type': 'ws', 'category': 9, 'viz_data': array([5.84144218, 1.99127371]), 'length': 0.48572504067012284, 'limits': [[5.772310077846208, 1.7543879435927594], [5.908369310618858, 2.220667581054349]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_5', {'geom': [array([-0.85134173, -5.976251  ]), array([-1.61400112, -6.88515307])], 'polygon': [[5.777412643935002, 1.7529580949490924], [6.923274450973475, 1.4451383071113109], [6.914208667099637, 1.4409179323941952], [5.768346860061166, 1.7487377202319763], [5.777412643935002, 1.7529580949490924]], 'center': [6.3480928747535454, 1.59734021939581], 'normal': [-0.22724730456483483, -0.9738370821487632], 'type': 'ws', 'category': 9, 'viz_data': array([6.34809287, 1.59734022]), 'length': 1.1864873798797735, 'limits': [[6.928008334389686, 1.4643089170609647], [5.7725629263612355, 1.7339349760388365]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_6', {'geom': [array([-1.61400112, -6.88515307]), array([-1.28760904, -7.15902854])], 'polygon': [[6.923274450973475, 1.4451383071113109], [7.0338143473938075, 1.8566240220218782], [7.02474856351997, 1.8524036473047625], [6.914208667099637, 1.4409179323941952], [6.923274450973475, 1.4451383071113109]], 'center': [6.979799446309092, 1.650733671340132], 'normal': [0.9726608405649466, -0.23223025046597962], 'type': 'ws', 'category': 9, 'viz_data': array([6.97979945, 1.65073367]), 'length': 0.4260745970790544, 'limits': [[7.028014459185483, 1.8580589196249797], [6.929067048788622, 1.4436328438866952]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_7', {'geom': [array([-1.28760904, -7.15902854]), array([-1.30180563, -7.17594737])], 'polygon': [[7.0338143473938075, 1.8566240220218782], [7.055144087064092, 1.8508940850437785], [7.046078303190255, 1.8466737103266628], [7.02474856351997, 1.8524036473047625], [7.0338143473938075, 1.8566240220218782]], 'center': [7.046175281148285, 1.8546905659297952], 'normal': [-0.27758309311494134, -0.9607016323587371], 'type': 'ws', 'category': 9, 'viz_data': array([7.04617528, 1.85469057]), 'length': 0.022085967766323985, 'limits': [[7.0550709846446376, 1.8507258205434824], [7.033852959359309, 1.856856511790496]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_8', {'geom': [array([-1.30180563, -7.17594737]), array([-4.36835906, -4.60280351])], 'polygon': [[7.055144087064092, 1.8508940850437785], [6.016587936502211, -2.0151401155284634], [6.007522152628375, -2.019360490245579], [7.046078303190255, 1.8466737103266628], [7.055144087064092, 1.8508940850437785]], 'center': [6.534784582349188, -0.07803352220127913], 'normal': [-0.95852210294672, 0.2850182067212509], 'type': 'ws', 'category': 9, 'viz_data': array([ 6.53478458, -0.07803352]), 'length': 4.003101212543116, 'limits': [[5.965278557587339, -2.000680813162017], [7.106235286510042, 1.8363801793933756]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_9', {'geom': [array([-4.36835906, -4.60280351]), array([-1.93858082, -1.70710655])], 'polygon': [[6.016587936502211, -2.0151401155284634], [2.3659541913207196, -1.0344482921230238], [2.356888407446882, -1.0386686668401397], [6.007522152628375, -2.019360490245579], [6.016587936502211, -2.0151401155284634]], 'center': [4.191625240807073, -1.5215980337135715], 'normal': [0.28398725350676063, 0.9588280554122761], 'type': 'ws', 'category': 9, 'viz_data': array([ 4.19162524, -1.52159803]), 'length': 3.7800639140035894, 'limits': [[2.378973987991061, -0.9880391453714473], [6.003405319989239, -2.0615291143893426]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_centroid', {'polygon': [[1.034003596449372, -0.7295800335779707], [1.02577388215116, -0.7273692356495641], [0.9483959546569252, -1.0154092360869624], [-0.1030759559270335, -0.7329459770401617], [-0.014644038790767382, -0.4037574051117066], [-0.02287375308897909, -0.40154660718330065], [-0.018452157232166255, -0.38508717858687963], [-1.2940578734549246, -0.04241349968384686], [-0.23781533946579225, 3.8894584152740865], [3.2661114319851507, 2.948177373562101], [2.2076581000676114, -0.991924255694043], [1.047268384019812, -0.680201747788702], [1.034003596449372, -0.7295800335779707]], 'center': [0.9731756169134246, 1.3959215049965954], 'normal': [0.0, 0.0], 'type': 'room', 'category': 0, 'category_letter': 'Bedroom', 'viz_data': array([0.97317562, 1.3959215 ])}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_0', {'geom': [array([-1.10006078, -0.62825476]), array([-1.09458327, -0.62172692])], 'polygon': [[1.034003596449372, -0.7295800335779707], [1.02577388215116, -0.7273692356495641], [1.0167080982773224, -0.7315896103666799], [1.0249378125755346, -0.7338004082950866], [1.034003596449372, -0.7295800335779707]], 'center': [1.0313081229263055, -0.7266583969982637], 'normal': [0.280032695751045, 0.9599904631351305], 'type': 'ws', 'category': 9, 'viz_data': array([ 1.03130812, -0.7266584 ]), 'length': 0.008521491941581858, 'limits': [[1.0257599456282709, -0.7272507155063647], [1.033940496623872, -0.7296370118665866]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_1', {'geom': [array([-1.09458327, -0.62172692]), array([-1.32305773, -0.43001409])], 'polygon': [[1.02577388215116, -0.7273692356495641], [0.9483959546569252, -1.0154092360869624], [0.9393301707830878, -1.0196296108040783], [1.0167080982773224, -0.7315896103666799], [1.02577388215116, -0.7273692356495641]], 'center': [0.9911725368469884, -0.8705229351124784], 'normal': [-0.9619604100705984, 0.2731888897023554], 'type': 'ws', 'category': 9, 'viz_data': array([ 0.99117254, -0.87052294]), 'length': 0.2982522179553398, 'limits': [[0.9463333797062222, -1.014784247254153], [1.0278125719807065, -0.7278774213653689]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_2', {'geom': [array([-1.32305773, -0.43001409]), array([-0.62322209,  0.40401754])], 'polygon': [[0.9483959546569252, -1.0154092360869624], [-0.1030759559270335, -0.7329459770401617], [-0.11214173980087083, -0.7371663517572776], [0.9393301707830878, -1.0196296108040783], [0.9483959546569252, -1.0154092360869624]], 'center': [0.4216611202057866, -0.8771571887535943], 'normal': [0.28205038044316216, 0.9593995950029724], 'type': 'ws', 'category': 9, 'viz_data': array([ 0.42166112, -0.87715719]), 'length': 1.08875096852238, 'limits': [[-0.09954391000519325, -0.720660578135188], [0.945003328254272, -1.0277432030147864]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_3', {'geom': [array([-0.62322209,  0.40401754]), array([-0.36210843,  0.18491716])], 'polygon': [[-0.1030759559270335, -0.7329459770401617], [-0.014644038790767382, -0.4037574051117066], [-0.023709822664604738, -0.40797777982882244], [-0.11214173980087083, -0.7371663517572776], [-0.1030759559270335, -0.7329459770401617]], 'center': [-0.0564846032461703, -0.5661378889332628], 'normal': [0.9723821439964644, -0.23339444302904644], 'type': 'ws', 'category': 9, 'viz_data': array([-0.0564846 , -0.56613789]), 'length': 0.34085967766324476, 'limits': [[-0.01902227795662713, -0.4026917860614909], [-0.09857703257590039, -0.7341376502296206]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_4', {'geom': [array([-0.36210843,  0.18491716]), array([-0.35663092,  0.191445  ])], 'polygon': [[-0.014644038790767382, -0.4037574051117066], [-0.02287375308897909, -0.40154660718330065], [-0.03193953696281645, -0.40576698190041655], [-0.023709822664604738, -0.40797777982882244], [-0.014644038790767382, -0.4037574051117066]], 'center': [-0.02271262144177273, -0.4031927187492894], 'normal': [0.24032945439469294, 0.9706913790440035], 'type': 'ws', 'category': 9, 'viz_data': array([-0.02271262, -0.40319272]), 'length': 0.008521491941581265, 'limits': [[-0.02290620542525725, -0.40155010743289365], [-0.014634466660971363, -0.40359807294184263]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_5', {'geom': [array([-0.35663092,  0.191445  ]), array([-0.34357524,  0.18048999])], 'polygon': [[-0.02287375308897909, -0.40154660718330065], [-0.018452157232166255, -0.38508717858687963], [-0.027517941106003613, -0.38930755330399547], [-0.03193953696281645, -0.40576698190041655], [-0.02287375308897909, -0.40154660718330065]], 'center': [-0.01858735551530065, -0.3893864639864062], 'normal': [0.9578192679872419, -0.2873712753084133], 'type': 'ws', 'category': 9, 'viz_data': array([-0.01858736, -0.38938646]), 'length': 0.017042983883160497, 'limits': [[-0.01832737585058994, -0.3850929171896097], [-0.023225039864154483, -0.4014170155368968]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_6', {'geom': [array([-0.34357524,  0.18048999]), array([0.50543872, 1.19230543])], 'polygon': [[-0.018452157232166255, -0.38508717858687963], [-1.2940578734549246, -0.04241349968384686], [-1.3031236573287621, -0.046633874400962644], [-0.027517941106003613, -0.38930755330399547], [-0.018452157232166255, -0.38508717858687963]], 'center': [-0.6524284445593692, -0.2108772239030546], 'normal': [0.26061691652468794, 0.9654422938846027], 'type': 'ws', 'category': 9, 'viz_data': array([-0.65242844, -0.21087722]), 'length': 1.320831250945069, 'limits': [[-1.2938516970053646, -0.04163018072580235], [-0.01866534425848798, -0.3858611485965525]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_7', {'geom': [array([0.50543872, 1.19230543]), array([ 3.6242149 , -1.42465851])], 'polygon': [[-1.2940578734549246, -0.04241349968384686], [-0.23781533946579225, 3.8894584152740865], [-0.24688112333962975, 3.885238040556971], [-1.3031236573287621, -0.046633874400962644], [-1.2940578734549246, -0.04241349968384686]], 'center': [-0.7660923022304231, 1.927895812457138], 'normal': [0.972728664759129, -0.23194599534357502], 'type': 'ws', 'category': 9, 'viz_data': array([-0.7660923 ,  1.92789581]), 'length': 4.071273148075766, 'limits': [[-0.29365489571415115, 3.9036506785986855], [-1.2379703983601549, -0.05659341459874967]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_8', {'geom': [array([ 3.6242149 , -1.42465851]), array([ 1.29208145, -4.20398692])], 'polygon': [[-0.23781533946579225, 3.8894584152740865], [3.2661114319851507, 2.948177373562101], [3.2570456481113137, 2.9439569988449854], [-0.24688112333962975, 3.885238040556971], [-0.23781533946579225, 3.8894584152740865]], 'center': [1.5174713572215945, 3.4172471707872214], 'normal': [-0.2304181119779469, -0.9730917190442626], 'type': 'ws', 'category': 9, 'viz_data': array([1.51747136, 3.41724717]), 'length': 3.6281555671135486, 'limits': [[3.2793665947089807, 3.0007213518309674], [-0.2511615430535534, 3.8367141075675484]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_9', {'geom': [array([ 1.29208145, -4.20398692]), array([-1.83322256, -1.58154548])], 'polygon': [[3.2661114319851507, 2.948177373562101], [2.2076581000676114, -0.991924255694043], [2.198592316193774, -0.9961446304111589], [3.2570456481113137, 2.9439569988449854], [3.2661114319851507, 2.948177373562101]], 'center': [2.7356530026817096, 0.9737215708589617], 'normal': [-0.9570734407808914, 0.2898455260165758], 'type': 'ws', 'category': 9, 'viz_data': array([2.735653  , 0.97372157]), 'length': 4.079794640017346, 'limits': [[2.145768324245128, -0.9742461390319099], [3.3282785477205614, 2.93041695476893]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_10', {'geom': [array([-1.83322256, -1.58154548]), array([-1.06089373, -0.66111982])], 'polygon': [[2.2076581000676114, -0.991924255694043], [1.047268384019812, -0.680201747788702], [1.0382026001459748, -0.6844221225058178], [2.198592316193774, -0.9961446304111589], [2.2076581000676114, -0.991924255694043]], 'center': [1.6282123022537596, -0.8337505466831137], 'normal': [0.27563462208840733, 0.9612624798181715], 'type': 'ws', 'category': 9, 'viz_data': array([ 1.6282123 , -0.83375055]), 'length': 1.2015303637629338, 'limits': [[1.049931449470893, -0.6704584002716938], [2.2049175065184805, -1.0016417680152365]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_11', {'geom': [array([-1.06089373, -0.66111982]), array([-1.10006078, -0.62825476])], 'polygon': [[1.047268384019812, -0.680201747788702], [1.034003596449372, -0.7295800335779707], [1.0249378125755346, -0.7338004082950866], [1.0382026001459748, -0.6844221225058178], [1.047268384019812, -0.680201747788702]], 'center': [1.044872457184385, -0.708753315503202], 'normal': [-0.9617219738561674, 0.2740270880810826], 'type': 'ws', 'category': 9, 'viz_data': array([ 1.04487246, -0.70875332]), 'length': 0.05112895164948728, 'limits': [[1.0336895831299904, -0.7294131230368301], [1.047700300867138, -0.6802412867352887]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_centroid', {'polygon': [[5.962840473555462, -2.1880684184674553], [4.884489960282264, -6.202237476407503], [1.8331974752329456, -5.382550320757885], [2.476539672399285, -2.987703459978379], [2.3942425294171708, -2.965595480694311], [2.82925084552403, -1.346273283533769], [5.962840473555462, -2.1880684184674553]], 'center': [3.884617538711848, -3.7678911608857986], 'normal': [0.0, 0.0], 'type': 'room', 'category': 2, 'category_letter': 'Kitchen', 'viz_data': array([ 3.88461754, -3.76789116])}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_0', {'geom': [array([-4.50244868, -4.481095  ]), array([-7.68650327, -1.80935597])], 'polygon': [[5.962840473555462, -2.1880684184674553], [4.884489960282264, -6.202237476407503], [4.875424176408426, -6.206457851124618], [5.953774689681625, -2.192288793184571], [5.962840473555462, -2.1880684184674553]], 'center': [5.420286459005335, -4.191523029074843], 'normal': [-0.9734654869842084, 0.22883388221720471], 'type': 'ws', 'category': 9, 'viz_data': array([ 5.42028646, -4.19152303]), 'length': 4.156488067491577, 'limits': [[4.948205426955903, -6.218143362520486], [5.899350727829487, -2.171945681755746]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_1', {'geom': [array([-7.68650327, -1.80935597]), array([-5.65563284,  0.61094116])], 'polygon': [[4.884489960282264, -6.202237476407503], [1.8331974752329456, -5.382550320757885], [1.8241316913591084, -5.3867706954750005], [4.875424176408426, -6.206457851124618], [4.884489960282264, -6.202237476407503]], 'center': [3.3555315607637, -5.791434690533252], 'normal': [0.25838205781469337, 0.9660428107488013], 'type': 'ws', 'category': 9, 'viz_data': array([ 3.35553156, -5.79143469]), 'length': 3.1594735103265865, 'limits': [[1.832751429097669, -5.384214643852664], [4.884938099499946, -6.200565911061859]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_2', {'geom': [array([-5.65563284,  0.61094116]), array([-3.75603095, -0.98301409])], 'polygon': [[1.8331974752329456, -5.382550320757885], [2.476539672399285, -2.987703459978379], [2.4674738885254475, -2.9919238346954953], [1.8241316913591084, -5.3867706954750005], [1.8331974752329456, -5.382550320757885]], 'center': [2.1557038967739457, -4.184763333216331], 'normal': [0.9742203157754413, -0.22559870640231733], 'type': 'ws', 'category': 9, 'viz_data': array([ 2.1557039 , -4.18476333]), 'length': 2.4797541550001014, 'limits': [[2.434596425994839, -2.9772423635506495], [1.8751670964310447, -5.393069239480312]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_3', {'geom': [array([-3.75603095, -0.98301409]), array([-3.70125586, -0.91773567])], 'polygon': [[2.476539672399285, -2.987703459978379], [2.3942425294171708, -2.965595480694311], [2.3851767455433333, -2.9698158554114267], [2.4674738885254475, -2.9919238346954953], [2.476539672399285, -2.987703459978379]], 'center': [2.4367620733078086, -2.9735776651981274], 'normal': [0.2791567465259892, 0.9602455471747966], 'type': 'ws', 'category': 9, 'viz_data': array([ 2.43676207, -2.97357767]), 'length': 0.085214919415812, 'limits': [[2.3944148718356955, -2.964726596923558], [2.476242118757588, -2.98851491658315]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_4', {'geom': [array([-3.70125586, -0.91773567]), array([-2.41680316, -1.99551946])], 'polygon': [[2.3942425294171708, -2.965595480694311], [2.82925084552403, -1.346273283533769], [2.820185061650193, -1.3504936582508849], [2.3851767455433333, -2.9698158554114267], [2.3942425294171708, -2.965595480694311]], 'center': [2.614862237625599, -2.151510551560495], 'normal': [0.9673644778726327, -0.25338896374982206], 'type': 'ws', 'category': 9, 'viz_data': array([ 2.61486224, -2.15151055]), 'length': 1.6767339124914755, 'limits': [[2.824207367672804, -1.3449473801093736], [2.3993414991024045, -2.966960205898026]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_5', {'geom': [array([-2.41680316, -1.99551946]), array([-4.50244868, -4.481095  ])], 'polygon': [[2.82925084552403, -1.346273283533769], [5.962840473555462, -2.1880684184674553], [5.953774689681625, -2.192288793184571], [2.820185061650193, -1.3504936582508849], [2.82925084552403, -1.346273283533769]], 'center': [4.3954900273311015, -1.7711963145051852], 'normal': [-0.2347996572158972, -0.9720437855216693], 'type': 'ws', 'category': 9, 'viz_data': array([ 4.39549003, -1.77119631]), 'length': 3.2446884297423986, 'limits': [[5.97293274485894, -2.148083890925557], [2.8189535207737775, -1.3862321598496539]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_centroid', {'polygon': [[2.0426003829659924, -2.3946565508824658], [1.9232172948320319, -2.839061122985877], [0.74006995547669, -2.5212250970845713], [1.1750782715835493, -0.901902899924029], [2.745022182954826, -1.3236464284604488], [2.429396954981925, -2.49856405351758], [2.0426003829659924, -2.3946565508824658]], 'center': [1.7110903907320136, -1.8683096738995042], 'normal': [0.0, 0.0], 'type': 'room', 'category': 4, 'category_letter': 'Corridor', 'viz_data': array([ 1.71109039, -1.86830967])}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_0', {'geom': [array([-3.0352488 , -0.83990213]), array([-3.38775225, -0.54411662])], 'polygon': [[2.0426003829659924, -2.3946565508824658], [1.9232172948320319, -2.839061122985877], [1.9141515109581946, -2.843281497702993], [2.033534599092155, -2.398876925599582], [2.0426003829659924, -2.3946565508824658]], 'center': [1.9875009736107445, -2.613178564937557], 'normal': [-0.9689619289669005, 0.2472099921377438], 'type': 'ws', 'category': 9, 'viz_data': array([ 1.98750097, -2.61317856]), 'length': 0.4601605648453778, 'limits': [[1.92607757947949, -2.8398556216529953], [2.039833869097016, -2.3939775531059193]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_1', {'geom': [array([-3.38775225, -0.54411662]), array([-2.60027646,  0.39436048])], 'polygon': [[1.9232172948320319, -2.839061122985877], [0.74006995547669, -2.5212250970845713], [0.7310041716028526, -2.525445471801687], [1.9141515109581946, -2.843281497702993], [1.9232172948320319, -2.839061122985877]], 'center': [1.3272818987817705, -2.675707037397445], 'normal': [0.23327325896947726, 0.9724112230171755], 'type': 'ws', 'category': 9, 'viz_data': array([ 1.3272819 , -2.67570704]), 'length': 1.2250948395876788, 'limits': [[0.7361137990958753, -2.5371328184506052], [1.9274097703713604, -2.8229146842279116]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_2', {'geom': [array([-2.60027646,  0.39436048]), array([-1.31582377, -0.68342331])], 'polygon': [[0.74006995547669, -2.5212250970845713], [1.1750782715835493, -0.901902899924029], [1.1660124877097118, -0.9061232746411447], [0.7310041716028526, -2.525445471801687], [0.74006995547669, -2.5212250970845713]], 'center': [0.9530927137223765, -1.7117305503969817], 'normal': [0.9562071257277274, -0.2926908483494454], 'type': 'ws', 'category': 9, 'viz_data': array([ 0.95309271, -1.71173055]), 'length': 1.6767339124914755, 'limits': [[1.202959528514222, -0.9100666643229884], [0.7121948572108073, -2.513371579396669]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_3', {'geom': [array([-1.31582377, -0.68342331]), array([-2.36074249, -1.92870895])], 'polygon': [[1.1750782715835493, -0.901902899924029], [2.745022182954826, -1.3236464284604488], [2.7359563990809885, -1.3278668031775647], [1.1660124877097118, -0.9061232746411447], [1.1750782715835493, -0.901902899924029]], 'center': [1.9632163166210033, -1.112625303833148], 'normal': [-0.22932475929687982, -0.9733499652095478], 'type': 'ws', 'category': 9, 'viz_data': array([ 1.96321632, -1.1126253 ]), 'length': 1.6256049608419916, 'limits': [[2.751197657839275, -1.2992686363280521], [1.1689151257592543, -0.9264771699711487]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_4', {'geom': [array([-2.36074249, -1.92870895]), array([-3.29269175, -1.14671068])], 'polygon': [[2.745022182954826, -1.3236464284604488], [2.429396954981925, -2.49856405351758], [2.4203311711080877, -2.5027844282346963], [2.7359563990809885, -1.3278668031775647], [2.745022182954826, -1.3236464284604488]], 'center': [2.5902372881236633, -1.9115106031745874], 'normal': [-0.9642959871228933, 0.26482682873660035], 'type': 'ws', 'category': 9, 'viz_data': array([ 2.59023729, -1.9115106 ]), 'length': 1.216573347646099, 'limits': [[2.4261212490008046, -2.497656738560109], [2.748302510583391, -1.3245199413843114]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_5', {'geom': [array([-3.29269175, -1.14671068]), array([-3.0352488 , -0.83990213])], 'polygon': [[2.429396954981925, -2.49856405351758], [2.0426003829659924, -2.3946565508824658], [2.033534599092155, -2.398876925599582], [2.4203311711080877, -2.5027844282346963], [2.429396954981925, -2.49856405351758]], 'center': [2.2400862426694714, -2.446286757921461], 'normal': [0.2602138487661732, 0.9655510099991068], 'type': 'ws', 'category': 9, 'viz_data': array([ 2.24008624, -2.44628676]), 'length': 0.4005101212543112, 'limits': [[2.0426419342630937, -2.39449787745819], [2.4293548863550587, -2.4987161575795813]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_centroid', {'polygon': [[10.39686199267121, 1.9346802896335598], [10.215576562541864, 1.2598437171802281], [9.655955990263491, 1.4101779763118811], [9.653745192335085, 1.4019482620136707], [7.096235565178449, 2.0889875419588897], [7.098446363106856, 2.0972172562571005], [6.505906933635638, 2.256394707102381], [6.6827707679081705, 2.9147718509592893], [6.040853052647686, 3.0872140893750095], [6.473650570826138, 4.698306572237342], [11.450696201656914, 3.3612927013405622], [11.022320279335272, 1.7666596470746527], [10.39686199267121, 1.9346802896335598]], 'center': [8.67392485087109, 2.957470234460603], 'normal': [0.0, 0.0], 'type': 'room', 'category': 8, 'category_letter': 'Balcony', 'viz_data': array([8.67392485, 2.95747023])}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_0', {'geom': [array([ -2.63617704, -10.24083752]), array([-3.17146005, -9.79168174])], 'polygon': [[10.39686199267121, 1.9346802896335598], [10.215576562541864, 1.2598437171802281], [10.206510778668028, 1.255623342463112], [10.387796208797374, 1.9304599149164436], [10.39686199267121, 1.9346802896335598]], 'center': [10.30709903198691, 1.5945688934301079], 'normal': [-0.9612653360797249, 0.27562466081890014], 'type': 'ws', 'category': 9, 'viz_data': array([10.30709903,  1.59456889]), 'length': 0.6987623392096509, 'limits': [[10.209966575747154, 1.2614283945806521], [10.402562708484835, 1.9331244094208715]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_1', {'geom': [array([-3.17146005, -9.79168174]), array([-2.7989894 , -9.34778852])], 'polygon': [[10.215576562541864, 1.2598437171802281], [9.655955990263491, 1.4101779763118811], [9.646890206389655, 1.4059576015947655], [10.206510778668028, 1.255623342463112], [10.215576562541864, 1.2598437171802281]], 'center': [9.935559260230733, 1.3391568526691273], 'normal': [0.27415954367700796, 0.961684222918737], 'type': 'ws', 'category': 9, 'viz_data': array([9.93555926, 1.33915685]), 'length': 0.5794614520275155, 'limits': [[9.657073454180455, 1.4144406119295498], [10.2143323903849, 1.2555757246632697]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_2', {'geom': [array([-2.7989894 , -9.34778852]), array([-2.80551725, -9.34231101])], 'polygon': [[9.655955990263491, 1.4101779763118811], [9.653745192335085, 1.4019482620136707], [9.644679408461249, 1.397727887296555], [9.646890206389655, 1.4059576015947655], [9.655955990263491, 1.4101779763118811]], 'center': [9.655867323682122, 1.4017528896326583], 'normal': [-0.9684073081435122, 0.2493737867824851], 'type': 'ws', 'category': 9, 'viz_data': array([9.65586732, 1.40175289]), 'length': 0.008521491941580035, 'limits': [[9.65374327412531, 1.401926167737273], [9.655868310839818, 1.410178442809785]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_3', {'geom': [array([-2.80551725, -9.34231101]), array([-1.10329739, -7.31368438])], 'polygon': [[9.653745192335085, 1.4019482620136707], [7.096235565178449, 2.0889875419588897], [7.087169781304612, 2.084767167241774], [9.644679408461249, 1.397727887296555], [9.653745192335085, 1.4019482620136707]], 'center': [8.375370573483314, 1.745948607713163], 'normal': [0.2537060821280324, 0.9672813571506711], 'type': 'ws', 'category': 9, 'viz_data': array([8.37537057, 1.74594861]), 'length': 2.6481839938317204, 'limits': [[7.09422373240488, 2.081395848683008], [9.65576273994311, 1.4095354628537964]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_4', {'geom': [array([-1.10329739, -7.31368438]), array([-1.09676955, -7.31916189])], 'polygon': [[7.096235565178449, 2.0889875419588897], [7.098446363106856, 2.0972172562571005], [7.089380579233018, 2.092996881539985], [7.087169781304612, 2.084767167241774], [7.096235565178449, 2.0889875419588897]], 'center': [7.0962613435431985, 2.0965426810564467], 'normal': [0.9596533065003111, -0.28118593727819924], 'type': 'ws', 'category': 9, 'viz_data': array([7.09626134, 2.09654268]), 'length': 0.008521491941580608, 'limits': [[7.098461042696994, 2.0971677297167033], [7.096064918998392, 2.08899005179865]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_5', {'geom': [array([-1.09676955, -7.31916189]), array([-0.70238887, -6.84915729])], 'polygon': [[7.098446363106856, 2.0972172562571005], [6.505906933635638, 2.256394707102381], [6.496841149761801, 2.2521743323852648], [7.089380579233018, 2.092996881539985], [7.098446363106856, 2.0972172562571005]], 'center': [6.8011742566195945, 2.172572970247709], 'normal': [0.294731527651937, 0.9555800995248673], 'type': 'ws', 'category': 9, 'viz_data': array([6.80117426, 2.17257297]), 'length': 0.6135474197938394, 'limits': [[6.509184582187437, 2.2671821961004173], [7.09547828665726, 2.0863504277776745]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_6', {'geom': [array([-0.70238887, -6.84915729]), array([-0.18016154, -7.28735805])], 'polygon': [[6.505906933635638, 2.256394707102381], [6.6827707679081705, 2.9147718509592893], [6.673704984034334, 2.9105514762421736], [6.496841149761801, 2.2521743323852648], [6.505906933635638, 2.256394707102381]], 'center': [6.596521323153781, 2.5831035214644205], 'normal': [0.9653952098217882, -0.2607912744958034], 'type': 'ws', 'category': 9, 'viz_data': array([6.59652132, 2.58310352]), 'length': 0.681719355326488, 'limits': [[6.683235558372133, 2.9146506356440702], [6.505449098848081, 2.256522035569081]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_7', {'geom': [array([-0.18016154, -7.28735805]), array([ 0.24708419, -6.77818641])], 'polygon': [[6.6827707679081705, 2.9147718509592893], [6.040853052647686, 3.0872140893750095], [6.031787268773848, 3.0829937146578934], [6.673704984034334, 2.9105514762421736], [6.6827707679081705, 2.9147718509592893]], 'center': [6.35683010905114, 2.9991733926436672], 'normal': [0.2702317907867397, 0.9627952945710694], 'type': 'ws', 'category': 9, 'viz_data': array([6.35683011, 2.99917339]), 'length': 0.6646763714433258, 'limits': [[6.041858324042895, 3.0907454358831408], [6.681805606881102, 2.911128749734379]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_8', {'geom': [array([ 0.24708419, -6.77818641]), array([ 1.52500905, -7.85049268])], 'polygon': [[6.040853052647686, 3.0872140893750095], [6.473650570826138, 4.698306572237342], [6.464584786952301, 4.6940861975202255], [6.031787268773848, 3.0829937146578934], [6.040853052647686, 3.0872140893750095]], 'center': [6.258708114006977, 3.8889417933599524], 'normal': [0.9579750321467378, -0.2868515953998794], 'type': 'ws', 'category': 9, 'viz_data': array([6.25870811, 3.88894179]), 'length': 1.6682124205498956, 'limits': [[6.496625908353793, 4.691853200779132], [6.01809651405316, 3.0937473535752584]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_9', {'geom': [array([ 1.52500905, -7.85049268]), array([ -1.78759858, -11.79830473])], 'polygon': [[6.473650570826138, 4.698306572237342], [11.450696201656914, 3.3612927013405622], [11.441630417783076, 3.357072326623447], [6.464584786952301, 4.6940861975202255], [6.473650570826138, 4.698306572237342]], 'center': [8.963605345820945, 4.033628918650032], 'normal': [-0.2895318930060851, -0.957168367076719], 'type': 'ws', 'category': 9, 'viz_data': array([8.96360535, 4.03362892]), 'length': 5.153502624656564, 'limits': [[11.42843910563905, 3.283794636458401], [6.495669413670939, 4.775898006987045]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_10', {'geom': [array([ -1.78759858, -11.79830473]), array([ -3.05246776, -10.73695348])], 'polygon': [[11.450696201656914, 3.3612927013405622], [11.022320279335272, 1.7666596470746527], [11.013254495461435, 1.7624392723575366], [11.441630417783076, 3.357072326623447], [11.450696201656914, 3.3612927013405622]], 'center': [11.23958105566532, 2.5591805401243173], 'normal': [-0.960950378747546, 0.2767207429611085], 'type': 'ws', 'category': 9, 'viz_data': array([11.23958106,  2.55918054]), 'length': 1.6511694366667338, 'limits': [[11.008138346357608, 1.7706845774459539], [11.465051179626702, 3.357376472987224]]}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_11', {'geom': [array([ -3.05246776, -10.73695348]), array([ -2.63617704, -10.24083752])], 'polygon': [[11.022320279335272, 1.7666596470746527], [10.39686199267121, 1.9346802896335598], [10.387796208797374, 1.9304599149164436], [11.013254495461435, 1.7624392723575366], [11.022320279335272, 1.7666596470746527]], 'center': [10.714583207346537, 1.8469891923261075], 'normal': [0.28230444695778895, 0.9593248663658505], 'type': 'ws', 'category': 9, 'viz_data': array([10.71458321,  1.84698919]), 'length': 0.6476333875601632, 'limits': [[10.39903456769422, 1.9422023994736581], [11.020325380669435, 1.7593726141670871]]})]\n",
      "[('1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_0', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_1', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_2', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_3', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_4', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_5', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_centroid', {'type': 'connected_by_door', 'opening': 'door'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_0', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_1', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_0', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_5', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_1', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_2', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_2', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_3', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_3', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_4', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_4', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bathroom_0_ws_5', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_0', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_1', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_2', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_3', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_4', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_5', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_6', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_7', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_8', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_9', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_centroid', {'type': 'connected_by_door', 'opening': 'door'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_0', '1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_1', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_0', '1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_9', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_1', '1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_2', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_2', '1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_3', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_3', '1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_4', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_4', '1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_5', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_5', '1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_6', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_6', '1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_7', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_7', '1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_8', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_8', '1588_dd7f04c697c2d6ba20587aad0f95b928_Dining_1_ws_9', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_0', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_1', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_2', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_3', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_4', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_5', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_6', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_7', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_8', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_9', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_10', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_11', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_centroid', {'type': 'connected_by_door', 'opening': 'door'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_0', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_1', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_0', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_11', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_1', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_2', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_2', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_3', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_3', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_4', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_4', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_5', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_5', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_6', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_6', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_7', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_7', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_8', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_8', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_9', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_9', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_10', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_10', '1588_dd7f04c697c2d6ba20587aad0f95b928_Bedroom_2_ws_11', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_0', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_1', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_2', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_3', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_4', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_5', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_centroid', {'type': 'connected_by_door', 'opening': 'door'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_0', '1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_1', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_0', '1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_5', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_1', '1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_2', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_2', '1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_3', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_3', '1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_4', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_4', '1588_dd7f04c697c2d6ba20587aad0f95b928_Kitchen_4_ws_5', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_0', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_1', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_2', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_3', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_4', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_5', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_0', '1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_1', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_0', '1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_5', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_1', '1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_2', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_2', '1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_3', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_3', '1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_4', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_4', '1588_dd7f04c697c2d6ba20587aad0f95b928_Corridor_6_ws_5', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_0', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_1', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_2', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_3', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_4', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_5', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_6', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_7', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_8', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_9', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_10', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_centroid', '1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_11', {'type': 'ws_belongs_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_0', '1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_1', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_0', '1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_11', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_1', '1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_2', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_2', '1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_3', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_3', '1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_4', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_4', '1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_5', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_5', '1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_6', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_6', '1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_7', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_7', '1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_8', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_8', '1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_9', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_9', '1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_10', {'type': 'ws_same_room'}), ('1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_10', '1588_dd7f04c697c2d6ba20587aad0f95b928_Balcony_7_ws_11', {'type': 'ws_same_room'})]\n"
     ]
    }
   ],
   "source": [
    "# Check the number of graphs\n",
    "print(f\"Number of original graphs: {len(noise_graphs)}\")\n",
    "print(noise_graphs[0])\n",
    "print(noise_graphs[0].nodes(data=True))\n",
    "print(noise_graphs[0].edges(data=True))\n",
    "plot_a_graph([noise_graphs[0]],path=os.path.join(gm_path, \"room_dropout_noise\", \"apartment.png\"), viz_rooms=True, viz_ws=True, viz_openings=False, viz_room_connection=True, viz_normals=False, viz_room_normals=True, viz_walls=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate G1,G2,GT dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: count=3426, nodes min=5, max=254, mean=78.8\n",
      "VAL: count=734, nodes min=5, max=248, mean=76.6\n",
      "TEST: count=735, nodes min=5, max=310, mean=78.7\n",
      "Serialized 3426 pairs to ./GNN/preprocessed/partial_graph_matching/room_dropout_noise/train_dataset.pkl\n",
      "Serialized 734 pairs to ./GNN/preprocessed/partial_graph_matching/room_dropout_noise/valid_dataset.pkl\n",
      "Serialized 735 pairs to ./GNN/preprocessed/partial_graph_matching/room_dropout_noise/test_dataset.pkl\n",
      "Serialized 4895 pairs to ./GNN/preprocessed/partial_graph_matching/room_dropout_noise/noise.pkl\n",
      "Data(x=[25, 7], edge_index=[2, 46], name='4110', node_names=[25], permutation=[25])\n",
      "G1 nodes: tensor([ 2.9468e+00, -2.9468e+00, -4.7606e-01,  3.7298e+00, -1.0862e-03,\n",
      "         1.0258e-03, -1.3095e+00])\n",
      "Data(x=[16, 7], edge_index=[2, 28], name='4110', node_names=[16], permutation=[16])\n",
      "G2 permuted nodes: tensor([-0.3394,  0.3394, -2.7801, -2.6256,  0.9889, -1.1171,  0.0478])\n",
      "Ground truth permutation:\n",
      " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "pair_gt_list = []\n",
    "for i, g1 in enumerate(original_graphs):\n",
    "    generate_matching_pair_as_data(g1, noise_graphs[i], pair_gt_list)\n",
    "\n",
    "train, val, test = split_graphs_stratified(pair_gt_list)\n",
    "\n",
    "describe(train, \"TRAIN\")\n",
    "describe(val,   \"VAL\")\n",
    "describe(test,  \"TEST\")\n",
    "\n",
    "# compute mean and std\n",
    "mean, std = compute_mean_std(train)\n",
    "\n",
    "# Normalizzazione dei set\n",
    "train_pairs_norm = normalize_data_pairs(train, mean, std)\n",
    "val_pairs_norm = normalize_data_pairs(val, mean, std)\n",
    "test_pairs_norm = normalize_data_pairs(test, mean, std)\n",
    "\n",
    "gm_equal_preprocessed_path = os.path.join(GNN_PATH, \"preprocessed\", \"partial_graph_matching\", \"room_dropout_noise\")\n",
    "serialize_graph_matching_dataset(\n",
    "    train_pairs_norm,\n",
    "    gm_equal_preprocessed_path,\n",
    "    \"train_dataset.pkl\"\n",
    ")\n",
    "serialize_graph_matching_dataset(\n",
    "    val_pairs_norm,\n",
    "    gm_equal_preprocessed_path,\n",
    "    \"valid_dataset.pkl\"\n",
    ")\n",
    "serialize_graph_matching_dataset(\n",
    "    test_pairs_norm,\n",
    "    gm_equal_preprocessed_path,\n",
    "    \"test_dataset.pkl\"\n",
    ")\n",
    "serialize_graph_matching_dataset(\n",
    "    noise_graphs,\n",
    "    gm_equal_preprocessed_path,\n",
    "    \"noise.pkl\"\n",
    ")\n",
    "\n",
    "g1_out, g2_perm, gt_perm = train[0]\n",
    "\n",
    "print(g1_out)\n",
    "print(\"G1 nodes:\", g1_out.x[0])\n",
    "print(g2_perm)\n",
    "print(\"G2 permuted nodes:\", g2_perm.x[0])\n",
    "print(\"Ground truth permutation:\\n\", gt_perm[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the two graphs\n",
    "plot_two_graphs_with_matching(\n",
    "    [g1_out, g2_perm],\n",
    "    gt_perm=gt_perm,\n",
    "    pred_perm=gt_perm,\n",
    "    original_graphs=original_graphs,\n",
    "    noise_graphs=noise_graphs,\n",
    "    viz_rooms=True,\n",
    "    viz_ws=True,\n",
    "    match_display=\"all\",\n",
    "    path=os.path.join(gm_equal_preprocessed_path, \"gt.png\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B_XTk3X9dsZV"
   },
   "source": [
    "# Graph matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4EdN2opdsZf",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Equal graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ML4uKWG6dsZg",
    "outputId": "fb598dac-68bc-4cf1-be6d-7b2515082bfb"
   },
   "outputs": [],
   "source": [
    "#load preprocessed dataset\n",
    "gm_equal_preprocessed_path = os.path.join(GNN_PATH, \"preprocessed\", \"graph_matching\", \"equal\")\n",
    "models_path = os.path.join(GNN_PATH, 'models', 'graph_matching', 'equal')\n",
    "\n",
    "original_graphs = deserialize_graph_matching_dataset(\n",
    "    gm_equal_preprocessed_path,\n",
    "    \"original.pkl\"\n",
    ")\n",
    "train_list = deserialize_graph_matching_dataset(\n",
    "    gm_equal_preprocessed_path,\n",
    "    \"train_dataset.pkl\"\n",
    ")\n",
    "val_list = deserialize_graph_matching_dataset(\n",
    "    gm_equal_preprocessed_path,\n",
    "    \"valid_dataset.pkl\"\n",
    ")\n",
    "test_list = deserialize_graph_matching_dataset(\n",
    "    gm_equal_preprocessed_path,\n",
    "    \"test_dataset.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b5FE_ULjdsZg",
    "outputId": "1e4727f4-51c8-4c06-dc8a-b19c13b30d45"
   },
   "outputs": [],
   "source": [
    "d1,d2,gt = train_list[0]\n",
    "print(d1)\n",
    "print(d2)\n",
    "print(gt)\n",
    "plot_two_graphs_with_matching([d1,d2],gt_perm=gt,original_graphs=original_graphs,path=os.path.join(models_path, \"train.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2iIhvpIEdsZg"
   },
   "outputs": [],
   "source": [
    "train_dataset = GraphMatchingDataset(train_list)\n",
    "val_dataset = GraphMatchingDataset(val_list)\n",
    "test_dataset = GraphMatchingDataset(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w8Q-TdAwdsZh",
    "outputId": "34f61cf7-042c-4a78-d225-f8087844d31f"
   },
   "outputs": [],
   "source": [
    "# Percorsi per salvare i modelli\n",
    "best_val_model_path = os.path.join(models_path, 'best_val_model.pt')\n",
    "final_model_path = os.path.join(models_path, 'final_model.pt')\n",
    "\n",
    "# Loader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_pyg_matching, generator=g)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_pyg_matching)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_pyg_matching)\n",
    "\n",
    "# Modello e ottimizzatore\n",
    "model = MatchingModel_GATv2Sinkhorn(in_dim=in_dim, hidden_dim=hidden_dim, out_dim=out_dim).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# Logger TensorBoard\n",
    "writer = setup_tb_logger(\n",
    "    base_dir=\"tb_logs\",\n",
    "    model_name=model._get_name(),\n",
    "    dataset_name=\"GM_equal\",\n",
    "    experiment_name=\"exp1\"\n",
    ")\n",
    "\n",
    "#model summary\n",
    "print(model)\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize initial validation embeddings\n",
    "batch = next(iter(val_loader))\n",
    "h1_val, h2_val = batch[0], batch[1]\n",
    "visualize_initial_embeddings(h1_val.x, h2_val.x, os.path.join(models_path, 'initial_room.png'), node_type_filter=\"room\")\n",
    "visualize_initial_embeddings(h1_val.x, h2_val.x, os.path.join(models_path, 'initial_ws.png'), node_type_filter=\"ws\")\n",
    "embedding_type = visualize_initial_embeddings(h1_val.x, h2_val.x, os.path.join(models_path, 'initial_all.png'), node_type_filter=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, val_losses, val_embeddings_history = train_loop(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=num_epochs,\n",
    "    writer=writer,\n",
    "    best_model_path=best_val_model_path,\n",
    "    final_model_path=final_model_path,\n",
    "    patience=patience,\n",
    "    resume=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_embedding_gif_stride(val_embeddings_history, os.path.join(models_path, \"embeddings_evolution.gif\"), embedding_type=embedding_type, fps=0.001, node_type_filter=\"all\")\n",
    "create_embedding_gif_stride(val_embeddings_history, os.path.join(models_path, \"embeddings_evolution_room.gif\"), embedding_type=embedding_type, fps=0.001, node_type_filter=\"room\")\n",
    "create_embedding_gif_stride(val_embeddings_history, os.path.join(models_path, \"embeddings_evolution_ws.gif\"), embedding_type=embedding_type, fps=0.001, node_type_filter=\"ws\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LV-pTNGNdsZi",
    "outputId": "4c3d20dc-91bf-45b8-9cdd-752dde65a066"
   },
   "outputs": [],
   "source": [
    "plot_losses(train_losses, val_losses, os.path.join(models_path, 'losses.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-hwnmcy8dsZi",
    "outputId": "e507cdb0-3184-4452-9237-d90c18500ecf"
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load(best_val_model_path, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_acc, test_loss, test_embeddings = evaluate_sinkhorn(model, test_loader)\n",
    "print(f\"Test Accuracy: {test_acc:.4f} | Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "inference_times = []\n",
    "# use the model to predict the matching on a test graph\n",
    "correct = 0\n",
    "total_cols = 0\n",
    "\n",
    "for i, (g1_out, g2_perm, gt_perm) in enumerate(test_list):\n",
    "    start_time = time.time()\n",
    "    result = predict_matching_matrix(model, g1_out, g2_perm, use_hungarian=True)\n",
    "    end_time = time.time()\n",
    "    inference_times.append(end_time - start_time)\n",
    "    errors = (result != gt_perm.to(result.device)).sum().item()\n",
    "    if errors > 0:\n",
    "        print(f\"Graph {i}: Errors found: {errors}\")\n",
    "\n",
    "    # Accuracy calculation after hungarian\n",
    "    pred_idx = result.argmax(dim=0)\n",
    "    target_idx = gt_perm.argmax(dim=0)\n",
    "    correct += (pred_idx == target_idx).sum().item()\n",
    "    total_cols += result.shape[1]\n",
    "\n",
    "accuracy = correct / total_cols if total_cols > 0 else 0.0\n",
    "print(f\"Test Accuracy (after Hungarian): {accuracy:.4f}\")\n",
    "\n",
    "mean_inference_time = np.mean(inference_times)\n",
    "std_inference_time = np.std(inference_times)\n",
    "print(f\"Inference time: {mean_inference_time:.6f} seconds (mean) ± {std_inference_time:.6f} seconds (std)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1QHU0aZ-dsZj",
    "outputId": "5d3ffa20-fc79-4279-b57d-942416da5e50"
   },
   "outputs": [],
   "source": [
    "g1_out, g2_perm, gt_perm = test_list[236]\n",
    "result = predict_matching_matrix(model, g1_out, g2_perm, use_hungarian=True)\n",
    "\n",
    "plot_two_graphs_with_matching(\n",
    "    [g1_out, g2_perm],\n",
    "    gt_perm=gt_perm,\n",
    "    pred_perm=result,\n",
    "    original_graphs=original_graphs,\n",
    "    viz_rooms=True,\n",
    "    viz_ws=True,\n",
    "    match_display=\"all\",\n",
    "    path=os.path.join(models_path, \"test.png\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7UF3A67XdsZj",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Local noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UZ1u7aCedsZj",
    "outputId": "a4e95313-546c-4e5b-e313-273a116bdf41"
   },
   "outputs": [],
   "source": [
    "#load preprocessed dataset\n",
    "gm_equal_preprocessed_path = os.path.join(GNN_PATH, \"preprocessed\", \"graph_matching\", \"equal\")\n",
    "gm_local_preprocessed_path = os.path.join(GNN_PATH, \"preprocessed\", \"graph_matching\", \"local\")\n",
    "models_path = os.path.join(GNN_PATH, 'models', 'graph_matching', 'local')\n",
    "\n",
    "original_graphs = deserialize_graph_matching_dataset(\n",
    "    gm_equal_preprocessed_path,\n",
    "    \"original.pkl\"\n",
    ")\n",
    "noise_graphs = deserialize_graph_matching_dataset(\n",
    "    gm_local_preprocessed_path,\n",
    "    \"noise.pkl\"\n",
    ")\n",
    "\n",
    "train_list = deserialize_graph_matching_dataset(\n",
    "    gm_local_preprocessed_path,\n",
    "    \"train_dataset.pkl\"\n",
    ")\n",
    "val_list = deserialize_graph_matching_dataset(\n",
    "    gm_local_preprocessed_path,\n",
    "    \"valid_dataset.pkl\"\n",
    ")\n",
    "test_list = deserialize_graph_matching_dataset(\n",
    "    gm_local_preprocessed_path,\n",
    "    \"test_dataset.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rt4rX3pBdsZk",
    "outputId": "4ed3571a-2df9-490f-fd1e-4264e9a62847"
   },
   "outputs": [],
   "source": [
    "d1,d2,gt = train_list[0]\n",
    "print(d1)\n",
    "print(d2)\n",
    "print(gt)\n",
    "plot_two_graphs_with_matching([d1,d2],gt_perm=gt,original_graphs=original_graphs,noise_graphs=noise_graphs,path=os.path.join(models_path, \"train.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SmRO1JSodsZk"
   },
   "outputs": [],
   "source": [
    "train_dataset = GraphMatchingDataset(train_list)\n",
    "val_dataset = GraphMatchingDataset(val_list)\n",
    "test_dataset = GraphMatchingDataset(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z9oIucY9dsZl",
    "outputId": "778692cc-114d-4326-e6c0-fbcfd41e611c"
   },
   "outputs": [],
   "source": [
    "# Percorsi per salvare i modelli\n",
    "best_val_model_path = os.path.join(models_path, 'best_val_model.pt')\n",
    "final_model_path = os.path.join(models_path, 'final_model.pt')\n",
    "\n",
    "# Loader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_pyg_matching, generator=g)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_pyg_matching)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_pyg_matching)\n",
    "\n",
    "# Modello e ottimizzatore\n",
    "model = MatchingModel_GATv2Sinkhorn(in_dim=in_dim, hidden_dim=hidden_dim, out_dim=out_dim).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# Logger TensorBoard\n",
    "writer = setup_tb_logger(\n",
    "    base_dir=\"tb_logs\",\n",
    "    model_name=model._get_name(),\n",
    "    dataset_name=\"GM_local\",\n",
    "    experiment_name=\"exp1\"\n",
    ")\n",
    "\n",
    "#model summary\n",
    "print(model)\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize initial validation embeddings\n",
    "batch = next(iter(val_loader))\n",
    "h1_val, h2_val = batch[0], batch[1]\n",
    "visualize_initial_embeddings(h1_val.x, h2_val.x, os.path.join(models_path, 'initial_room.png'), node_type_filter=\"room\")\n",
    "visualize_initial_embeddings(h1_val.x, h2_val.x, os.path.join(models_path, 'initial_ws.png'), node_type_filter=\"ws\")\n",
    "embedding_type = visualize_initial_embeddings(h1_val.x, h2_val.x, os.path.join(models_path, 'initial_all.png'), node_type_filter=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, val_losses, val_embeddings_history = train_loop(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=num_epochs,\n",
    "    writer=writer,\n",
    "    best_model_path=best_val_model_path,\n",
    "    final_model_path=final_model_path,\n",
    "    patience=patience,\n",
    "    resume=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_embedding_gif_stride(val_embeddings_history, os.path.join(models_path, \"embeddings_evolution.gif\"), embedding_type=embedding_type, fps=0.001, node_type_filter=\"all\")\n",
    "create_embedding_gif_stride(val_embeddings_history, os.path.join(models_path, \"embeddings_evolution_room.gif\"), embedding_type=embedding_type, fps=0.001, node_type_filter=\"room\")\n",
    "create_embedding_gif_stride(val_embeddings_history, os.path.join(models_path, \"embeddings_evolution_ws.gif\"), embedding_type=embedding_type, fps=0.001, node_type_filter=\"ws\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ivzH9FuUdsZl",
    "outputId": "45ec61ec-1d89-4e15-985d-275a33c095fe"
   },
   "outputs": [],
   "source": [
    "plot_losses(train_losses, val_losses, os.path.join(models_path, 'losses.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8w4aanj7dsZm",
    "outputId": "6f119110-4989-4082-cf9e-43b1001e9194"
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load(best_val_model_path, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_acc, test_loss, test_embeddings = evaluate_sinkhorn(model, test_loader)\n",
    "print(f\"Test Accuracy: {test_acc:.4f} | Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "inference_times = []\n",
    "# use the model to predict the matching on a test graph\n",
    "correct = 0\n",
    "total_cols = 0\n",
    "\n",
    "for i, (g1_out, g2_perm, gt_perm) in enumerate(test_list):\n",
    "    start_time = time.time()\n",
    "    result = predict_matching_matrix(model, g1_out, g2_perm, use_hungarian=True)\n",
    "    end_time = time.time()\n",
    "    inference_times.append(end_time - start_time)\n",
    "    errors = (result != gt_perm.to(result.device)).sum().item()\n",
    "    if errors > 0:\n",
    "        print(f\"Graph {i}: Errors found: {errors}\")\n",
    "\n",
    "    # Accuracy calculation after hungarian\n",
    "    pred_idx = result.argmax(dim=0)\n",
    "    target_idx = gt_perm.argmax(dim=0)\n",
    "    correct += (pred_idx == target_idx).sum().item()\n",
    "    total_cols += result.shape[1]\n",
    "\n",
    "accuracy = correct / total_cols if total_cols > 0 else 0.0\n",
    "print(f\"Test Accuracy (after Hungarian): {accuracy:.4f}\")\n",
    "\n",
    "mean_inference_time = np.mean(inference_times)\n",
    "std_inference_time = np.std(inference_times)\n",
    "print(f\"Inference time: {mean_inference_time:.6f} seconds (mean) ± {std_inference_time:.6f} seconds (std)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AQuRATYWdsZm",
    "outputId": "eb1a2fbf-9d59-474a-9d00-076837879026"
   },
   "outputs": [],
   "source": [
    "g1_out, g2_perm, gt_perm = test_list[586]\n",
    "result = predict_matching_matrix(model, g1_out, g2_perm, use_hungarian=True)\n",
    "\n",
    "plot_two_graphs_with_matching(\n",
    "    [g1_out, g2_perm],\n",
    "    gt_perm=gt_perm,\n",
    "    pred_perm=result,\n",
    "    original_graphs=original_graphs,\n",
    "    noise_graphs=noise_graphs,\n",
    "    viz_rooms=True,\n",
    "    viz_ws=True,\n",
    "    match_display=\"wrong\",\n",
    "    path=os.path.join(models_path, \"test.png\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gch5GNBNdsZm",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Global noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q2zESEQodsZn",
    "outputId": "7d8ff7a6-ebe2-4f22-c09a-2bca30bc764b"
   },
   "outputs": [],
   "source": [
    "#load preprocessed dataset\n",
    "gm_equal_preprocessed_path = os.path.join(GNN_PATH, \"preprocessed\", \"graph_matching\", \"equal\")\n",
    "gm_local_preprocessed_path = os.path.join(GNN_PATH, \"preprocessed\", \"graph_matching\", \"global\")\n",
    "models_path = os.path.join(GNN_PATH, 'models', 'graph_matching', 'global')\n",
    "\n",
    "original_graphs = deserialize_graph_matching_dataset(\n",
    "    gm_equal_preprocessed_path,\n",
    "    \"original.pkl\"\n",
    ")\n",
    "noise_graphs = deserialize_graph_matching_dataset(\n",
    "    gm_local_preprocessed_path,\n",
    "    \"noise.pkl\"\n",
    ")\n",
    "\n",
    "train_list = deserialize_graph_matching_dataset(\n",
    "    gm_local_preprocessed_path,\n",
    "    \"train_dataset.pkl\"\n",
    ")\n",
    "val_list = deserialize_graph_matching_dataset(\n",
    "    gm_local_preprocessed_path,\n",
    "    \"valid_dataset.pkl\"\n",
    ")\n",
    "test_list = deserialize_graph_matching_dataset(\n",
    "    gm_local_preprocessed_path,\n",
    "    \"test_dataset.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZEOkiXDKdsZn",
    "outputId": "bf78e9ad-46ac-4dbb-ac11-2a3bbcc46236"
   },
   "outputs": [],
   "source": [
    "d1,d2,gt = train_list[0]\n",
    "print(d1)\n",
    "print(d2)\n",
    "print(gt)\n",
    "plot_two_graphs_with_matching([d1,d2],gt_perm=gt,original_graphs=original_graphs,noise_graphs=noise_graphs,path=os.path.join(models_path, \"train.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VnstUFO0dsZn"
   },
   "outputs": [],
   "source": [
    "train_dataset = GraphMatchingDataset(train_list)\n",
    "val_dataset = GraphMatchingDataset(val_list)\n",
    "test_dataset = GraphMatchingDataset(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BNqgzChNdsZo",
    "outputId": "e989ac19-645a-46ed-ca7c-0e6dee09521b"
   },
   "outputs": [],
   "source": [
    "# Percorsi per salvare i modelli\n",
    "best_val_model_path = os.path.join(models_path, 'best_val_model.pt')\n",
    "final_model_path = os.path.join(models_path, 'final_model.pt')\n",
    "\n",
    "# Loader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_pyg_matching, generator=g)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_pyg_matching)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_pyg_matching)\n",
    "\n",
    "# Modello e ottimizzatore\n",
    "model = MatchingModel_GATv2Sinkhorn(in_dim=in_dim, hidden_dim=hidden_dim, out_dim=out_dim).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# Logger TensorBoard\n",
    "writer = setup_tb_logger(\n",
    "    base_dir=\"tb_logs\",\n",
    "    model_name=model._get_name(),\n",
    "    dataset_name=\"GM_global\",\n",
    "    experiment_name=\"exp1\"\n",
    ")\n",
    "\n",
    "#model summary\n",
    "print(model)\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize initial validation embeddings\n",
    "batch = next(iter(val_loader))\n",
    "h1_val, h2_val = batch[0], batch[1]\n",
    "visualize_initial_embeddings(h1_val.x, h2_val.x, os.path.join(models_path, 'initial_room.png'), node_type_filter=\"room\")\n",
    "visualize_initial_embeddings(h1_val.x, h2_val.x, os.path.join(models_path, 'initial_ws.png'), node_type_filter=\"ws\")\n",
    "embedding_type = visualize_initial_embeddings(h1_val.x, h2_val.x, os.path.join(models_path, 'initial_all.png'), node_type_filter=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, val_losses, val_embeddings_history = train_loop(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=num_epochs,\n",
    "    writer=writer,\n",
    "    best_model_path=best_val_model_path,\n",
    "    final_model_path=final_model_path,\n",
    "    patience=patience,\n",
    "    resume=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_embedding_gif_stride(val_embeddings_history, os.path.join(models_path, \"embeddings_evolution.gif\"), embedding_type=embedding_type, fps=0.001, node_type_filter=\"all\")\n",
    "create_embedding_gif_stride(val_embeddings_history, os.path.join(models_path, \"embeddings_evolution_room.gif\"), embedding_type=embedding_type, fps=0.001, node_type_filter=\"room\")\n",
    "create_embedding_gif_stride(val_embeddings_history, os.path.join(models_path, \"embeddings_evolution_ws.gif\"), embedding_type=embedding_type, fps=0.001, node_type_filter=\"ws\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rt9jD976dsZo",
    "outputId": "686e8e71-156d-4a75-e35a-dc24bf5ac427"
   },
   "outputs": [],
   "source": [
    "plot_losses(train_losses, val_losses, os.path.join(models_path, 'losses.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NzGHyR7XdsZp",
    "outputId": "dd3520c5-1e50-4de8-a812-72a4d1840ce6"
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load(best_val_model_path, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_acc, test_loss, test_embeddings = evaluate_sinkhorn(model, test_loader)\n",
    "print(f\"Test Accuracy: {test_acc:.4f} | Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "inference_times = []\n",
    "# use the model to predict the matching on a test graph\n",
    "correct = 0\n",
    "total_cols = 0\n",
    "\n",
    "for i, (g1_out, g2_perm, gt_perm) in enumerate(test_list):\n",
    "    start_time = time.time()\n",
    "    result = predict_matching_matrix(model, g1_out, g2_perm, use_hungarian=True)\n",
    "    end_time = time.time()\n",
    "    inference_times.append(end_time - start_time)\n",
    "    errors = (result != gt_perm.to(result.device)).sum().item()\n",
    "    if errors > 0:\n",
    "        print(f\"Graph {i}: Errors found: {errors}\")\n",
    "\n",
    "    # Accuracy calculation after hungarian\n",
    "    pred_idx = result.argmax(dim=0)\n",
    "    target_idx = gt_perm.argmax(dim=0)\n",
    "    correct += (pred_idx == target_idx).sum().item()\n",
    "    total_cols += result.shape[1]\n",
    "\n",
    "accuracy = correct / total_cols if total_cols > 0 else 0.0\n",
    "print(f\"Test Accuracy (after Hungarian): {accuracy:.4f}\")\n",
    "\n",
    "mean_inference_time = np.mean(inference_times)\n",
    "std_inference_time = np.std(inference_times)\n",
    "print(f\"Inference time: {mean_inference_time:.6f} seconds (mean) ± {std_inference_time:.6f} seconds (std)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5DMHg-WBdsZp",
    "outputId": "bab4b0e7-4744-4b6b-ce21-efd4e5237d0f"
   },
   "outputs": [],
   "source": [
    "g1_out, g2_perm, gt_perm = test_list[39]\n",
    "result = predict_matching_matrix(model, g1_out, g2_perm, use_hungarian=True)\n",
    "\n",
    "plot_two_graphs_with_matching(\n",
    "    [g1_out, g2_perm],\n",
    "    gt_perm=gt_perm,\n",
    "    pred_perm=result,\n",
    "    original_graphs=original_graphs,\n",
    "    noise_graphs=noise_graphs,\n",
    "    viz_rooms=True,\n",
    "    viz_ws=True,\n",
    "    match_display=\"wrong\",\n",
    "    path=os.path.join(models_path, \"test.png\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ivsyBkoTdsZp",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Global + Local noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xi34oY4ddsZq",
    "outputId": "23516bc1-b8dc-4092-a9e8-ccb86298c6c9"
   },
   "outputs": [],
   "source": [
    "#load preprocessed dataset\n",
    "gm_equal_preprocessed_path = os.path.join(GNN_PATH, \"preprocessed\", \"graph_matching\", \"equal\")\n",
    "gm_local_preprocessed_path = os.path.join(GNN_PATH, \"preprocessed\", \"graph_matching\", \"global_local\")\n",
    "models_path = os.path.join(GNN_PATH, 'models', 'graph_matching', 'global_local')\n",
    "\n",
    "original_graphs = deserialize_graph_matching_dataset(\n",
    "    gm_equal_preprocessed_path,\n",
    "    \"original.pkl\"\n",
    ")\n",
    "noise_graphs = deserialize_graph_matching_dataset(\n",
    "    gm_local_preprocessed_path,\n",
    "    \"noise.pkl\"\n",
    ")\n",
    "\n",
    "train_list = deserialize_graph_matching_dataset(\n",
    "    gm_local_preprocessed_path,\n",
    "    \"train_dataset.pkl\"\n",
    ")\n",
    "val_list = deserialize_graph_matching_dataset(\n",
    "    gm_local_preprocessed_path,\n",
    "    \"valid_dataset.pkl\"\n",
    ")\n",
    "test_list = deserialize_graph_matching_dataset(\n",
    "    gm_local_preprocessed_path,\n",
    "    \"test_dataset.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UZoeGiMLdsZq",
    "outputId": "00a9a594-3e47-4543-e087-94d1a8f1c938"
   },
   "outputs": [],
   "source": [
    "d1,d2,gt = train_list[0]\n",
    "print(d1)\n",
    "print(d2)\n",
    "print(gt)\n",
    "plot_two_graphs_with_matching([d1,d2],gt_perm=gt,original_graphs=original_graphs,noise_graphs=noise_graphs,path=os.path.join(models_path, \"train.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cIlYmrxadsZq"
   },
   "outputs": [],
   "source": [
    "train_dataset = GraphMatchingDataset(train_list)\n",
    "val_dataset = GraphMatchingDataset(val_list)\n",
    "test_dataset = GraphMatchingDataset(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fd8vviCMdsZs",
    "outputId": "768f8fe0-de43-4576-f7c1-cb756b7c236c"
   },
   "outputs": [],
   "source": [
    "# Percorsi per salvare i modelli\n",
    "best_val_model_path = os.path.join(models_path, 'best_val_model.pt')\n",
    "final_model_path = os.path.join(models_path, 'final_model.pt')\n",
    "\n",
    "# Loader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_pyg_matching, generator=g)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_pyg_matching)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_pyg_matching)\n",
    "\n",
    "# Modello e ottimizzatore\n",
    "model = MatchingModel_GATv2Sinkhorn(in_dim=in_dim, hidden_dim=hidden_dim, out_dim=out_dim).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# Logger TensorBoard\n",
    "writer = setup_tb_logger(\n",
    "    base_dir=\"tb_logs\",\n",
    "    model_name=model._get_name(),\n",
    "    dataset_name=\"GM_global_local\",\n",
    "    experiment_name=\"exp1\"\n",
    ")\n",
    "#model summary\n",
    "print(model)\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize initial validation embeddings\n",
    "batch = next(iter(val_loader))\n",
    "h1_val, h2_val = batch[0], batch[1]\n",
    "visualize_initial_embeddings(h1_val.x, h2_val.x, os.path.join(models_path, 'initial_room.png'), node_type_filter=\"room\")\n",
    "visualize_initial_embeddings(h1_val.x, h2_val.x, os.path.join(models_path, 'initial_ws.png'), node_type_filter=\"ws\")\n",
    "embedding_type = visualize_initial_embeddings(h1_val.x, h2_val.x, os.path.join(models_path, 'initial_all.png'), node_type_filter=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, val_losses, val_embeddings_history = train_loop(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=num_epochs,\n",
    "    writer=writer,\n",
    "    best_model_path=best_val_model_path,\n",
    "    final_model_path=final_model_path,\n",
    "    patience=patience,\n",
    "    resume=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_embedding_gif_stride(val_embeddings_history, os.path.join(models_path, \"embeddings_evolution.gif\"), embedding_type=embedding_type, fps=0.001, node_type_filter=\"all\")\n",
    "create_embedding_gif_stride(val_embeddings_history, os.path.join(models_path, \"embeddings_evolution_room.gif\"), embedding_type=embedding_type, fps=0.001, node_type_filter=\"room\")\n",
    "create_embedding_gif_stride(val_embeddings_history, os.path.join(models_path, \"embeddings_evolution_ws.gif\"), embedding_type=embedding_type, fps=0.001, node_type_filter=\"ws\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J1hwMXy0dsZt",
    "outputId": "bed82726-b546-49a4-a261-32733fefd5c6"
   },
   "outputs": [],
   "source": [
    "plot_losses(train_losses, val_losses, os.path.join(models_path, 'losses.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r6H7I20sdsZv",
    "outputId": "2b6171bf-09ff-4d59-b77f-6be6bd9f89aa"
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load(best_val_model_path, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_acc, test_loss, test_embeddings = evaluate_sinkhorn(model, test_loader)\n",
    "print(f\"Test Accuracy: {test_acc:.4f} | Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "inference_times = []\n",
    "# use the model to predict the matching on a test graph\n",
    "correct = 0\n",
    "total_cols = 0\n",
    "\n",
    "for i, (g1_out, g2_perm, gt_perm) in enumerate(test_list):\n",
    "    start_time = time.time()\n",
    "    result = predict_matching_matrix(model, g1_out, g2_perm, use_hungarian=True)\n",
    "    end_time = time.time()\n",
    "    inference_times.append(end_time - start_time)\n",
    "    errors = (result != gt_perm.to(result.device)).sum().item()\n",
    "    if errors > 0:\n",
    "        print(f\"Graph {i}: Errors found: {errors}\")\n",
    "\n",
    "    # Accuracy calculation after hungarian\n",
    "    pred_idx = result.argmax(dim=0)\n",
    "    target_idx = gt_perm.argmax(dim=0)\n",
    "    correct += (pred_idx == target_idx).sum().item()\n",
    "    total_cols += result.shape[1]\n",
    "\n",
    "accuracy = correct / total_cols if total_cols > 0 else 0.0\n",
    "print(f\"Test Accuracy (after Hungarian): {accuracy:.4f}\")\n",
    "\n",
    "mean_inference_time = np.mean(inference_times)\n",
    "std_inference_time = np.std(inference_times)\n",
    "print(f\"Inference time: {mean_inference_time:.6f} seconds (mean) ± {std_inference_time:.6f} seconds (std)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ereHBI3dsZv",
    "outputId": "f6cbce29-0a3e-44db-cb3f-3b2ea2d3dce1"
   },
   "outputs": [],
   "source": [
    "g1_out, g2_perm, gt_perm = test_list[25]\n",
    "result = predict_matching_matrix(model, g1_out, g2_perm, use_hungarian=True)\n",
    "\n",
    "plot_two_graphs_with_matching(\n",
    "    [g1_out, g2_perm],\n",
    "    gt_perm=gt_perm,\n",
    "    pred_perm=result,\n",
    "    original_graphs=original_graphs,\n",
    "    noise_graphs=noise_graphs,\n",
    "    viz_rooms=True,\n",
    "    viz_ws=True,\n",
    "    match_display=\"wrong\",\n",
    "    path=os.path.join(models_path, \"test.png\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qE4_rdTCdsZv"
   },
   "source": [
    "# Partial graph matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V9cx0sDmdsZw"
   },
   "source": [
    "## Ws dropout equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4895 pairs from ./GNN/preprocessed/graph_matching/equal/original.pkl\n",
      "Loaded 4895 pairs from ./GNN/preprocessed/partial_graph_matching/ws_dropout_equal/noise.pkl\n",
      "Loaded 3426 pairs from ./GNN/preprocessed/partial_graph_matching/ws_dropout_equal/train_dataset.pkl\n",
      "Loaded 734 pairs from ./GNN/preprocessed/partial_graph_matching/ws_dropout_equal/valid_dataset.pkl\n",
      "Loaded 735 pairs from ./GNN/preprocessed/partial_graph_matching/ws_dropout_equal/test_dataset.pkl\n"
     ]
    }
   ],
   "source": [
    "#load preprocessed dataset\n",
    "gm_equal_preprocessed_path = os.path.join(GNN_PATH, \"preprocessed\", \"graph_matching\", \"equal\")\n",
    "gm_local_preprocessed_path = os.path.join(GNN_PATH, \"preprocessed\", \"partial_graph_matching\", \"ws_dropout_equal\")\n",
    "models_path = os.path.join(GNN_PATH, 'models', \"partial_graph_matching\", \"ws_dropout_equal\")\n",
    "\n",
    "original_graphs = deserialize_graph_matching_dataset(\n",
    "    gm_equal_preprocessed_path,\n",
    "    \"original.pkl\"\n",
    ")\n",
    "noise_graphs = deserialize_graph_matching_dataset(\n",
    "    gm_local_preprocessed_path,\n",
    "    \"noise.pkl\"\n",
    ")\n",
    "\n",
    "train_list = deserialize_graph_matching_dataset(\n",
    "    gm_local_preprocessed_path,\n",
    "    \"train_dataset.pkl\"\n",
    ")\n",
    "val_list = deserialize_graph_matching_dataset(\n",
    "    gm_local_preprocessed_path,\n",
    "    \"valid_dataset.pkl\"\n",
    ")\n",
    "test_list = deserialize_graph_matching_dataset(\n",
    "    gm_local_preprocessed_path,\n",
    "    \"test_dataset.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[57, 7], edge_index=[2, 109], name='1575', node_names=[57], permutation=[57])\n",
      "Data(x=[43, 7], edge_index=[2, 71], name='1575', node_names=[43], permutation=[43])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([57, 43])\n"
     ]
    }
   ],
   "source": [
    "d1,d2,gt = train_list[0]\n",
    "print(d1)\n",
    "print(d2)\n",
    "print(gt)\n",
    "print(gt.shape)\n",
    "plot_two_graphs_with_matching([d1,d2],gt_perm=gt,original_graphs=original_graphs,noise_graphs=noise_graphs,path=os.path.join(models_path, \"train.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = GraphMatchingDataset(train_list)\n",
    "val_dataset = GraphMatchingDataset(val_list)\n",
    "test_dataset = GraphMatchingDataset(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MatchingModel_GATv2SinkhornTopK(\n",
      "  (gnn): ModuleList(\n",
      "    (0): GATv2Conv(7, 64, heads=1)\n",
      "    (1): GATv2Conv(64, 32, heads=1)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (inst_norm): InstanceNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      ")\n",
      "Number of parameters: 5378\n"
     ]
    }
   ],
   "source": [
    "# Percorsi per salvare i modelli\n",
    "best_val_model_path = os.path.join(models_path, 'best_val_model.pt')\n",
    "final_model_path = os.path.join(models_path, 'final_model.pt')\n",
    "\n",
    "# Loader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_pyg_matching, generator=g)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_pyg_matching)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_pyg_matching)\n",
    "\n",
    "# Modello e ottimizzatore\n",
    "model = MatchingModel_GATv2SinkhornTopK(in_dim=in_dim, hidden_dim=hidden_dim, out_dim=out_dim).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# Logger TensorBoard\n",
    "writer = setup_tb_logger(\n",
    "    base_dir=\"tb_logs\",\n",
    "    model_name=model._get_name(),\n",
    "    dataset_name=\"PGM_ws_dropout_equal\",\n",
    "    experiment_name=\"exp1\"\n",
    ")\n",
    "\n",
    "#model summary\n",
    "print(model)\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize initial validation embeddings\n",
    "batch = next(iter(val_loader))\n",
    "h1_val, h2_val = batch[0], batch[1]\n",
    "visualize_initial_embeddings(h1_val.x, h2_val.x, os.path.join(models_path, 'initial_room.png'), node_type_filter=\"room\")\n",
    "visualize_initial_embeddings(h1_val.x, h2_val.x, os.path.join(models_path, 'initial_ws.png'), node_type_filter=\"ws\")\n",
    "embedding_type = visualize_initial_embeddings(h1_val.x, h2_val.x, os.path.join(models_path, 'initial_all.png'), node_type_filter=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, val_losses, val_embeddings_history = train_loop(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=num_epochs,\n",
    "    writer=writer,\n",
    "    best_model_path=best_val_model_path,\n",
    "    final_model_path=final_model_path,\n",
    "    patience=patience,\n",
    "    resume=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_embedding_gif_stride(val_embeddings_history, os.path.join(models_path, \"embeddings_evolution.gif\"), embedding_type=embedding_type, fps=0.001, node_type_filter=\"all\")\n",
    "create_embedding_gif_stride(val_embeddings_history, os.path.join(models_path, \"embeddings_evolution_room.gif\"), embedding_type=embedding_type, fps=0.001, node_type_filter=\"room\")\n",
    "create_embedding_gif_stride(val_embeddings_history, os.path.join(models_path, \"embeddings_evolution_ws.gif\"), embedding_type=embedding_type, fps=0.001, node_type_filter=\"ws\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(train_losses, val_losses, os.path.join(models_path, 'losses.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(best_val_model_path, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_acc, test_loss, test_embeddings = evaluate_sinkhorn(model, test_loader)\n",
    "print(f\"Test Accuracy: {test_acc:.4f} | Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "inference_times = []\n",
    "# use the model to predict the matching on a test graph\n",
    "correct = 0\n",
    "total_cols = 0\n",
    "\n",
    "for i, (g1_out, g2_perm, gt_perm) in enumerate(test_list):\n",
    "    start_time = time.time()\n",
    "    result = predict_matching_matrix(model, g1_out, g2_perm, use_hungarian=False)\n",
    "    end_time = time.time()\n",
    "    inference_times.append(end_time - start_time)\n",
    "    errors = (result != gt_perm.to(result.device)).sum().item()\n",
    "    if errors > 0:\n",
    "        print(f\"Graph {i}: Errors found: {errors}\")\n",
    "\n",
    "    # Accuracy calculation after hungarian\n",
    "    pred_idx = result.argmax(dim=0)\n",
    "    target_idx = gt_perm.argmax(dim=0)\n",
    "    correct += (pred_idx == target_idx).sum().item()\n",
    "    total_cols += result.shape[1]\n",
    "\n",
    "accuracy = correct / total_cols if total_cols > 0 else 0.0\n",
    "print(f\"Test Accuracy (after Hungarian): {accuracy:.4f}\")\n",
    "\n",
    "mean_inference_time = np.mean(inference_times)\n",
    "std_inference_time = np.std(inference_times)\n",
    "print(f\"Inference time: {mean_inference_time:.6f} seconds (mean) ± {std_inference_time:.6f} seconds (std)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1_out, g2_perm, gt_perm = test_list[3]\n",
    "result = predict_matching_matrix(model, g1_out, g2_perm, use_hungarian=False)\n",
    "\n",
    "plot_two_graphs_with_matching(\n",
    "    [g1_out, g2_perm],\n",
    "    gt_perm=gt_perm,\n",
    "    pred_perm=result,\n",
    "    original_graphs=original_graphs,\n",
    "    noise_graphs=noise_graphs,\n",
    "    viz_rooms=True,\n",
    "    viz_ws=True,\n",
    "    match_display=\"wrong\",\n",
    "    path=os.path.join(models_path, \"test.png\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ws dropout noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load preprocessed dataset\n",
    "gm_equal_preprocessed_path = os.path.join(GNN_PATH, \"preprocessed\", \"graph_matching\", \"equal\")\n",
    "gm_local_preprocessed_path = os.path.join(GNN_PATH, \"preprocessed\", \"partial_graph_matching\", \"ws_dropout_noise\")\n",
    "models_path = os.path.join(GNN_PATH, 'models', \"partial_graph_matching\", \"ws_dropout_noise\")\n",
    "\n",
    "original_graphs = deserialize_graph_matching_dataset(\n",
    "    gm_equal_preprocessed_path,\n",
    "    \"original.pkl\"\n",
    ")\n",
    "noise_graphs = deserialize_graph_matching_dataset(\n",
    "    gm_local_preprocessed_path,\n",
    "    \"noise.pkl\"\n",
    ")\n",
    "\n",
    "train_list = deserialize_graph_matching_dataset(\n",
    "    gm_local_preprocessed_path,\n",
    "    \"train_dataset.pkl\"\n",
    ")\n",
    "val_list = deserialize_graph_matching_dataset(\n",
    "    gm_local_preprocessed_path,\n",
    "    \"valid_dataset.pkl\"\n",
    ")\n",
    "test_list = deserialize_graph_matching_dataset(\n",
    "    gm_local_preprocessed_path,\n",
    "    \"test_dataset.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1,d2,gt = train_list[0]\n",
    "print(d1)\n",
    "print(d2)\n",
    "print(gt)\n",
    "print(gt.shape)\n",
    "plot_two_graphs_with_matching([d1,d2],gt_perm=gt,original_graphs=original_graphs,noise_graphs=noise_graphs,path=os.path.join(models_path, \"train.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = GraphMatchingDataset(train_list)\n",
    "val_dataset = GraphMatchingDataset(val_list)\n",
    "test_dataset = GraphMatchingDataset(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percorsi per salvare i modelli\n",
    "best_val_model_path = os.path.join(models_path, 'best_val_model.pt')\n",
    "final_model_path = os.path.join(models_path, 'final_model.pt')\n",
    "\n",
    "# Loader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_pyg_matching, generator=g)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_pyg_matching)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_pyg_matching)\n",
    "\n",
    "# Load best hyperparameters\n",
    "best_params_path = os.path.join(\"output\", \"ws_noise_params.out\")\n",
    "with open(best_params_path, \"r\") as f:\n",
    "    best_params = eval(f.read().strip().split(\"Best hyperparameters: \")[-1])\n",
    "learning_rate = best_params['lr']\n",
    "weight_decay = best_params['weight_decay']\n",
    "hidden_dim = best_params['hidden_dim']\n",
    "out_dim = best_params['out_dim']\n",
    "batch_size = best_params['batch_size']\n",
    "dropout_emb = best_params['dropout_emb']\n",
    "attn_dropout = best_params['attn_dropout']\n",
    "num_layers = best_params['num_layers']\n",
    "heads = best_params['heads']\n",
    "\n",
    "# Modello e ottimizzatore\n",
    "model = MatchingModel_GATv2SinkhornTopK(\n",
    "    in_dim=in_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    out_dim=out_dim,\n",
    "    attention_dropout=attn_dropout,\n",
    "    dropout_emb=dropout_emb,\n",
    "    num_layers=num_layers,\n",
    "    heads=heads\n",
    ").to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# Logger TensorBoard\n",
    "writer = setup_tb_logger(\n",
    "    base_dir=\"tb_logs\",\n",
    "    model_name=model._get_name(),\n",
    "    dataset_name=\"PGM_ws_dropout_noise\",\n",
    "    experiment_name=\"exp1\"\n",
    ")\n",
    "\n",
    "#model summary\n",
    "print(model)\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize initial validation embeddings\n",
    "batch = next(iter(val_loader))\n",
    "h1_val, h2_val = batch[0], batch[1]\n",
    "visualize_initial_embeddings(h1_val.x, h2_val.x, os.path.join(models_path, 'initial_room.png'), node_type_filter=\"room\")\n",
    "visualize_initial_embeddings(h1_val.x, h2_val.x, os.path.join(models_path, 'initial_ws.png'), node_type_filter=\"ws\")\n",
    "embedding_type = visualize_initial_embeddings(h1_val.x, h2_val.x, os.path.join(models_path, 'initial_all.png'), node_type_filter=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, val_losses, val_embeddings_history = train_loop(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=num_epochs,\n",
    "    writer=writer,\n",
    "    best_model_path=best_val_model_path,\n",
    "    final_model_path=final_model_path,\n",
    "    patience=patience,\n",
    "    resume=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_embedding_gif_stride(val_embeddings_history, os.path.join(models_path, \"embeddings_evolution.gif\"), embedding_type=embedding_type, fps=0.001, node_type_filter=\"all\")\n",
    "create_embedding_gif_stride(val_embeddings_history, os.path.join(models_path, \"embeddings_evolution_room.gif\"), embedding_type=embedding_type, fps=0.001, node_type_filter=\"room\")\n",
    "create_embedding_gif_stride(val_embeddings_history, os.path.join(models_path, \"embeddings_evolution_ws.gif\"), embedding_type=embedding_type, fps=0.001, node_type_filter=\"ws\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(train_losses, val_losses, os.path.join(models_path, 'losses.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(best_val_model_path, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_acc, test_loss, test_embeddings = evaluate_sinkhorn(model, test_loader)\n",
    "print(f\"Test Accuracy: {test_acc:.4f} | Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "inference_times = []\n",
    "# use the model to predict the matching on a test graph\n",
    "correct = 0\n",
    "total_cols = 0\n",
    "\n",
    "for i, (g1_out, g2_perm, gt_perm) in enumerate(test_list):\n",
    "    start_time = time.time()\n",
    "    result = predict_matching_matrix(model, g1_out, g2_perm, use_hungarian=False)\n",
    "    end_time = time.time()\n",
    "    inference_times.append(end_time - start_time)\n",
    "    errors = (result != gt_perm.to(result.device)).sum().item()\n",
    "    if errors > 0:\n",
    "        print(f\"Graph {i}: Errors found: {errors}\")\n",
    "\n",
    "    # Accuracy calculation after hungarian\n",
    "    pred_idx = result.argmax(dim=0)\n",
    "    target_idx = gt_perm.argmax(dim=0)\n",
    "    correct += (pred_idx == target_idx).sum().item()\n",
    "    total_cols += result.shape[1]\n",
    "\n",
    "accuracy = correct / total_cols if total_cols > 0 else 0.0\n",
    "print(f\"Test Accuracy (after Hungarian): {accuracy:.4f}\")\n",
    "\n",
    "mean_inference_time = np.mean(inference_times)\n",
    "std_inference_time = np.std(inference_times)\n",
    "print(f\"Inference time: {mean_inference_time:.6f} seconds (mean) ± {std_inference_time:.6f} seconds (std)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1_out, g2_perm, gt_perm = test_list[3]\n",
    "result = predict_matching_matrix(model, g1_out, g2_perm, use_hungarian=False)\n",
    "\n",
    "plot_two_graphs_with_matching(\n",
    "    [g1_out, g2_perm],\n",
    "    gt_perm=gt_perm,\n",
    "    pred_perm=result,\n",
    "    original_graphs=original_graphs,\n",
    "    noise_graphs=noise_graphs,\n",
    "    viz_rooms=True,\n",
    "    viz_ws=True,\n",
    "    match_display=\"wrong\",\n",
    "    path=os.path.join(models_path, \"test.png\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Room dropout equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load preprocessed dataset\n",
    "gm_equal_preprocessed_path = os.path.join(GNN_PATH, \"preprocessed\", \"graph_matching\", \"equal\")\n",
    "gm_local_preprocessed_path = os.path.join(GNN_PATH, \"preprocessed\", \"partial_graph_matching\", \"room_dropout_equal\")\n",
    "models_path = os.path.join(GNN_PATH, 'models', \"partial_graph_matching\", \"room_dropout_equal\")\n",
    "\n",
    "original_graphs = deserialize_graph_matching_dataset(\n",
    "    gm_equal_preprocessed_path,\n",
    "    \"original.pkl\"\n",
    ")\n",
    "noise_graphs = deserialize_graph_matching_dataset(\n",
    "    gm_local_preprocessed_path,\n",
    "    \"noise.pkl\"\n",
    ")\n",
    "\n",
    "train_list = deserialize_graph_matching_dataset(\n",
    "    gm_local_preprocessed_path,\n",
    "    \"train_dataset.pkl\"\n",
    ")\n",
    "val_list = deserialize_graph_matching_dataset(\n",
    "    gm_local_preprocessed_path,\n",
    "    \"valid_dataset.pkl\"\n",
    ")\n",
    "test_list = deserialize_graph_matching_dataset(\n",
    "    gm_local_preprocessed_path,\n",
    "    \"test_dataset.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1,d2,gt = train_list[0]\n",
    "print(d1)\n",
    "print(d2)\n",
    "print(gt)\n",
    "print(gt.shape)\n",
    "plot_two_graphs_with_matching([d1,d2],gt_perm=gt,original_graphs=original_graphs,noise_graphs=noise_graphs,path=os.path.join(models_path, \"train.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = GraphMatchingDataset(train_list)\n",
    "val_dataset = GraphMatchingDataset(val_list)\n",
    "test_dataset = GraphMatchingDataset(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percorsi per salvare i modelli\n",
    "best_val_model_path = os.path.join(models_path, 'best_val_model.pt')\n",
    "final_model_path = os.path.join(models_path, 'final_model.pt')\n",
    "\n",
    "# Loader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_pyg_matching, generator=g)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_pyg_matching)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_pyg_matching)\n",
    "\n",
    "# Modello e ottimizzatore\n",
    "model = MatchingModel_GATv2SinkhornTopK(in_dim=in_dim, hidden_dim=hidden_dim, out_dim=out_dim).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# Logger TensorBoard\n",
    "writer = setup_tb_logger(\n",
    "    base_dir=\"tb_logs\",\n",
    "    model_name=model._get_name(),\n",
    "    dataset_name=\"PGM_room_dropout_equal\",\n",
    "    experiment_name=\"exp1\"\n",
    ")\n",
    "\n",
    "#model summary\n",
    "print(model)\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize initial validation embeddings\n",
    "batch = next(iter(val_loader))\n",
    "h1_val, h2_val = batch[0], batch[1]\n",
    "visualize_initial_embeddings(h1_val.x, h2_val.x, os.path.join(models_path, 'initial_room.png'), node_type_filter=\"room\")\n",
    "visualize_initial_embeddings(h1_val.x, h2_val.x, os.path.join(models_path, 'initial_ws.png'), node_type_filter=\"ws\")\n",
    "embedding_type = visualize_initial_embeddings(h1_val.x, h2_val.x, os.path.join(models_path, 'initial_all.png'), node_type_filter=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, val_losses, val_embeddings_history = train_loop(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=num_epochs,\n",
    "    writer=writer,\n",
    "    best_model_path=best_val_model_path,\n",
    "    final_model_path=final_model_path,\n",
    "    patience=patience,\n",
    "    resume=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_embedding_gif_stride(val_embeddings_history, os.path.join(models_path, \"embeddings_evolution.gif\"), embedding_type=embedding_type, fps=0.001, node_type_filter=\"all\")\n",
    "create_embedding_gif_stride(val_embeddings_history, os.path.join(models_path, \"embeddings_evolution_room.gif\"), embedding_type=embedding_type, fps=0.001, node_type_filter=\"room\")\n",
    "create_embedding_gif_stride(val_embeddings_history, os.path.join(models_path, \"embeddings_evolution_ws.gif\"), embedding_type=embedding_type, fps=0.001, node_type_filter=\"ws\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(train_losses, val_losses, os.path.join(models_path, 'losses.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(best_val_model_path, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_acc, test_loss, test_embeddings = evaluate_sinkhorn(model, test_loader)\n",
    "print(f\"Test Accuracy: {test_acc:.4f} | Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "inference_times = []\n",
    "# use the model to predict the matching on a test graph\n",
    "correct = 0\n",
    "total_cols = 0\n",
    "\n",
    "for i, (g1_out, g2_perm, gt_perm) in enumerate(test_list):\n",
    "    start_time = time.time()\n",
    "    result = predict_matching_matrix(model, g1_out, g2_perm, use_hungarian=False)\n",
    "    end_time = time.time()\n",
    "    inference_times.append(end_time - start_time)\n",
    "    errors = (result != gt_perm.to(result.device)).sum().item()\n",
    "    if errors > 0:\n",
    "        print(f\"Graph {i}: Errors found: {errors}\")\n",
    "\n",
    "    # Accuracy calculation after hungarian\n",
    "    pred_idx = result.argmax(dim=0)\n",
    "    target_idx = gt_perm.argmax(dim=0)\n",
    "    correct += (pred_idx == target_idx).sum().item()\n",
    "    total_cols += result.shape[1]\n",
    "\n",
    "accuracy = correct / total_cols if total_cols > 0 else 0.0\n",
    "print(f\"Test Accuracy (after Hungarian): {accuracy:.4f}\")\n",
    "\n",
    "mean_inference_time = np.mean(inference_times)\n",
    "std_inference_time = np.std(inference_times)\n",
    "print(f\"Inference time: {mean_inference_time:.6f} seconds (mean) ± {std_inference_time:.6f} seconds (std)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1_out, g2_perm, gt_perm = test_list[3]\n",
    "result = predict_matching_matrix(model, g1_out, g2_perm, use_hungarian=False)\n",
    "\n",
    "plot_two_graphs_with_matching(\n",
    "    [g1_out, g2_perm],\n",
    "    gt_perm=gt_perm,\n",
    "    pred_perm=result,\n",
    "    original_graphs=original_graphs,\n",
    "    noise_graphs=noise_graphs,\n",
    "    viz_rooms=True,\n",
    "    viz_ws=True,\n",
    "    match_display=\"wrong\",\n",
    "    path=os.path.join(models_path, \"test.png\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Room dropout noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load preprocessed dataset\n",
    "gm_equal_preprocessed_path = os.path.join(GNN_PATH, \"preprocessed\", \"graph_matching\", \"equal\")\n",
    "gm_local_preprocessed_path = os.path.join(GNN_PATH, \"preprocessed\", \"partial_graph_matching\", \"room_dropout_noise\")\n",
    "models_path = os.path.join(GNN_PATH, 'models', \"partial_graph_matching\", \"room_dropout_noise\")\n",
    "\n",
    "original_graphs = deserialize_graph_matching_dataset(\n",
    "    gm_equal_preprocessed_path,\n",
    "    \"original.pkl\"\n",
    ")\n",
    "noise_graphs = deserialize_graph_matching_dataset(\n",
    "    gm_local_preprocessed_path,\n",
    "    \"noise.pkl\"\n",
    ")\n",
    "\n",
    "train_list = deserialize_graph_matching_dataset(\n",
    "    gm_local_preprocessed_path,\n",
    "    \"train_dataset.pkl\"\n",
    ")\n",
    "val_list = deserialize_graph_matching_dataset(\n",
    "    gm_local_preprocessed_path,\n",
    "    \"valid_dataset.pkl\"\n",
    ")\n",
    "test_list = deserialize_graph_matching_dataset(\n",
    "    gm_local_preprocessed_path,\n",
    "    \"test_dataset.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1,d2,gt = train_list[0]\n",
    "print(d1)\n",
    "print(d2)\n",
    "print(gt)\n",
    "print(gt.shape)\n",
    "plot_two_graphs_with_matching([d1,d2],gt_perm=gt,original_graphs=original_graphs,noise_graphs=noise_graphs,path=os.path.join(models_path, \"train.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = GraphMatchingDataset(train_list)\n",
    "val_dataset = GraphMatchingDataset(val_list)\n",
    "test_dataset = GraphMatchingDataset(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percorsi per salvare i modelli\n",
    "best_val_model_path = os.path.join(models_path, 'best_val_model.pt')\n",
    "final_model_path = os.path.join(models_path, 'final_model.pt')\n",
    "\n",
    "# Loader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_pyg_matching, generator=g)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_pyg_matching)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_pyg_matching)\n",
    "\n",
    "# Load best hyperparameters\n",
    "best_params_path = os.path.join(\"output\", \"room_noise_params.out\")\n",
    "with open(best_params_path, \"r\") as f:\n",
    "    best_params = eval(f.read().strip().split(\"Best hyperparameters: \")[-1])\n",
    "learning_rate = best_params['lr']\n",
    "weight_decay = best_params['weight_decay']\n",
    "hidden_dim = best_params['hidden_dim']\n",
    "out_dim = best_params['out_dim']\n",
    "batch_size = best_params['batch_size']\n",
    "dropout_emb = best_params['dropout_emb']\n",
    "attn_dropout = best_params['attn_dropout']\n",
    "num_layers = best_params['num_layers']\n",
    "heads = best_params['heads']\n",
    "\n",
    "# Modello e ottimizzatore\n",
    "model = MatchingModel_GATv2SinkhornTopK(\n",
    "    in_dim=in_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    out_dim=out_dim,\n",
    "    attention_dropout=attn_dropout,\n",
    "    dropout_emb=dropout_emb,\n",
    "    num_layers=num_layers,\n",
    "    heads=heads\n",
    ").to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# Logger TensorBoard\n",
    "writer = setup_tb_logger(\n",
    "    base_dir=\"tb_logs\",\n",
    "    model_name=model._get_name(),\n",
    "    dataset_name=\"PGM_room_dropout_noise\",\n",
    "    experiment_name=\"exp1\"\n",
    ")\n",
    "\n",
    "#model summary\n",
    "print(model)\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize initial validation embeddings\n",
    "batch = next(iter(val_loader))\n",
    "h1_val, h2_val = batch[0], batch[1]\n",
    "visualize_initial_embeddings(h1_val.x, h2_val.x, os.path.join(models_path, 'initial_room.png'), node_type_filter=\"room\")\n",
    "visualize_initial_embeddings(h1_val.x, h2_val.x, os.path.join(models_path, 'initial_ws.png'), node_type_filter=\"ws\")\n",
    "embedding_type = visualize_initial_embeddings(h1_val.x, h2_val.x, os.path.join(models_path, 'initial_all.png'), node_type_filter=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, val_losses, val_embeddings_history = train_loop(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=num_epochs,\n",
    "    writer=writer,\n",
    "    best_model_path=best_val_model_path,\n",
    "    final_model_path=final_model_path,\n",
    "    patience=patience,\n",
    "    resume=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_embedding_gif_stride(val_embeddings_history, os.path.join(models_path, \"embeddings_evolution.gif\"), embedding_type=embedding_type, fps=0.001, node_type_filter=\"all\")\n",
    "create_embedding_gif_stride(val_embeddings_history, os.path.join(models_path, \"embeddings_evolution_room.gif\"), embedding_type=embedding_type, fps=0.001, node_type_filter=\"room\")\n",
    "create_embedding_gif_stride(val_embeddings_history, os.path.join(models_path, \"embeddings_evolution_ws.gif\"), embedding_type=embedding_type, fps=0.001, node_type_filter=\"ws\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(train_losses, val_losses, os.path.join(models_path, 'losses.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(best_val_model_path, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_acc, test_loss, test_embeddings = evaluate_sinkhorn(model, test_loader)\n",
    "print(f\"Test Accuracy: {test_acc:.4f} | Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "inference_times = []\n",
    "# use the model to predict the matching on a test graph\n",
    "correct = 0\n",
    "total_cols = 0\n",
    "\n",
    "for i, (g1_out, g2_perm, gt_perm) in enumerate(test_list):\n",
    "    start_time = time.time()\n",
    "    result = predict_matching_matrix(model, g1_out, g2_perm, use_hungarian=False)\n",
    "    end_time = time.time()\n",
    "    inference_times.append(end_time - start_time)\n",
    "    errors = (result != gt_perm.to(result.device)).sum().item()\n",
    "    if errors > 0:\n",
    "        print(f\"Graph {i}: Errors found: {errors}\")\n",
    "\n",
    "    # Accuracy calculation after hungarian\n",
    "    pred_idx = result.argmax(dim=0)\n",
    "    target_idx = gt_perm.argmax(dim=0)\n",
    "    correct += (pred_idx == target_idx).sum().item()\n",
    "    total_cols += result.shape[1]\n",
    "\n",
    "accuracy = correct / total_cols if total_cols > 0 else 0.0\n",
    "print(f\"Test Accuracy (after Hungarian): {accuracy:.4f}\")\n",
    "\n",
    "mean_inference_time = np.mean(inference_times)\n",
    "std_inference_time = np.std(inference_times)\n",
    "print(f\"Inference time: {mean_inference_time:.6f} seconds (mean) ± {std_inference_time:.6f} seconds (std)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1_out, g2_perm, gt_perm = test_list[3]\n",
    "result = predict_matching_matrix(model, g1_out, g2_perm, use_hungarian=False)\n",
    "\n",
    "plot_two_graphs_with_matching(\n",
    "    [g1_out, g2_perm],\n",
    "    gt_perm=gt_perm,\n",
    "    pred_perm=result,\n",
    "    original_graphs=original_graphs,\n",
    "    noise_graphs=noise_graphs,\n",
    "    viz_rooms=True,\n",
    "    viz_ws=True,\n",
    "    match_display=\"wrong\",\n",
    "    path=os.path.join(models_path, \"test.png\")\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
